/* Generated by Cython 0.29 */

/* BEGIN: Cython Metadata
{
    "distutils": {
        "depends": [],
        "name": "srctools._tokenizer",
        "sources": [
            "srctools/_tokenizer.pyx"
        ]
    },
    "module_name": "srctools._tokenizer"
}
END: Cython Metadata */

#define PY_SSIZE_T_CLEAN
#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
    #error Cython requires Python 2.6+ or Python 3.3+.
#else
#define CYTHON_ABI "0_29"
#define CYTHON_HEX_VERSION 0x001D00F0
#define CYTHON_FUTURE_DIVISION 1
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#define __PYX_COMMA ,
#ifndef HAVE_LONG_LONG
  #if PY_VERSION_HEX >= 0x02070000
    #define HAVE_LONG_LONG
  #endif
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#ifdef PYPY_VERSION
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #if PY_VERSION_HEX < 0x03050000
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
#elif defined(PYSTON_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYTYPE_LOOKUP
    #define CYTHON_USE_PYTYPE_LOOKUP 0
  #elif !defined(CYTHON_USE_PYTYPE_LOOKUP)
    #define CYTHON_USE_PYTYPE_LOOKUP 1
  #endif
  #if PY_MAJOR_VERSION < 3
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 0
  #elif !defined(CYTHON_USE_PYLONG_INTERNALS)
    #define CYTHON_USE_PYLONG_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if PY_VERSION_HEX < 0x030300F0
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #ifndef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL 1
  #endif
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT (PY_VERSION_HEX >= 0x03050000)
  #endif
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE (PY_VERSION_HEX >= 0x030400a1)
  #endif
  #ifndef CYTHON_USE_DICT_VERSIONS
    #define CYTHON_USE_DICT_VERSIONS (PY_VERSION_HEX >= 0x030600B1)
  #endif
  #ifndef CYTHON_USE_EXC_INFO_STACK
    #define CYTHON_USE_EXC_INFO_STACK (PY_VERSION_HEX >= 0x030700A3)
  #endif
#endif
#if !defined(CYTHON_FAST_PYCCALL)
#define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
#endif
#if CYTHON_USE_PYLONG_INTERNALS
  #include "longintrepr.h"
  #undef SHIFT
  #undef BASE
  #undef MASK
#endif
#ifndef __has_attribute
  #define __has_attribute(x) 0
#endif
#ifndef __has_cpp_attribute
  #define __has_cpp_attribute(x) 0
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_MAYBE_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_MAYBE_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned char     uint8_t;
           typedef unsigned int      uint32_t;
        #else
           typedef unsigned __int8   uint8_t;
           typedef unsigned __int32  uint32_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
#ifndef CYTHON_FALLTHROUGH
  #if defined(__cplusplus) && __cplusplus >= 201103L
    #if __has_cpp_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH [[fallthrough]]
    #elif __has_cpp_attribute(clang::fallthrough)
      #define CYTHON_FALLTHROUGH [[clang::fallthrough]]
    #elif __has_cpp_attribute(gnu::fallthrough)
      #define CYTHON_FALLTHROUGH [[gnu::fallthrough]]
    #endif
  #endif
  #ifndef CYTHON_FALLTHROUGH
    #if __has_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))
    #else
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
  #if defined(__clang__ ) && defined(__apple_build_version__)
    #if __apple_build_version__ < 7000000
      #undef  CYTHON_FALLTHROUGH
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
#endif

#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #elif defined(__GNUC__)
    #define CYTHON_INLINE __inline__
  #elif defined(_MSC_VER)
    #define CYTHON_INLINE __inline
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_INLINE inline
  #else
    #define CYTHON_INLINE
  #endif
#endif

#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x02070600 && !defined(Py_OptimizeFlag)
  #define Py_OptimizeFlag 0
#endif
#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyClass_Type
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyType_Type
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#ifndef METH_STACKLESS
  #define METH_STACKLESS 0
#endif
#if PY_VERSION_HEX <= 0x030700A3 || !defined(METH_FASTCALL)
  #ifndef METH_FASTCALL
     #define METH_FASTCALL 0x80
  #endif
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject *const *args, Py_ssize_t nargs);
  typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject *const *args,
                                                          Py_ssize_t nargs, PyObject *kwnames);
#else
  #define __Pyx_PyCFunctionFast _PyCFunctionFast
  #define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
#endif
#if CYTHON_FAST_PYCCALL
#define __Pyx_PyFastCFunction_Check(func)\
    ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)))))
#else
#define __Pyx_PyFastCFunction_Check(func) 0
#endif
#if CYTHON_USE_DICT_VERSIONS
#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
    (version_var) = __PYX_GET_DICT_VERSION(dict);\
    (cache_var) = (value);
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
        static PY_UINT64_T __pyx_dict_version = 0;\
        static PyObject *__pyx_dict_cached_value = NULL;\
        if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
            (VAR) = __pyx_dict_cached_value;\
        } else {\
            (VAR) = __pyx_dict_cached_value = (LOOKUP);\
            __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
        }\
    }
#else
#define __PYX_GET_DICT_VERSION(dict)  (0)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030400A1
  #define PyMem_RawMalloc(n)           PyMem_Malloc(n)
  #define PyMem_RawRealloc(p, n)       PyMem_Realloc(p, n)
  #define PyMem_RawFree(p)             PyMem_Free(p)
#endif
#if CYTHON_COMPILING_IN_PYSTON
  #define __Pyx_PyCode_HasFreeVars(co)  PyCode_HasFreeVars(co)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno) PyFrame_SetLineNumber(frame, lineno)
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#if !CYTHON_FAST_THREAD_STATE || PY_VERSION_HEX < 0x02070000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#elif PY_VERSION_HEX >= 0x03060000
  #define __Pyx_PyThreadState_Current _PyThreadState_UncheckedGet()
#elif PY_VERSION_HEX >= 0x03000000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#else
  #define __Pyx_PyThreadState_Current _PyThreadState_Current
#endif
#if PY_VERSION_HEX < 0x030700A2 && !defined(PyThread_tss_create) && !defined(Py_tss_NEEDS_INIT)
#include "pythread.h"
#define Py_tss_NEEDS_INIT 0
typedef int Py_tss_t;
static CYTHON_INLINE int PyThread_tss_create(Py_tss_t *key) {
  *key = PyThread_create_key();
  return 0; // PyThread_create_key reports success always
}
static CYTHON_INLINE Py_tss_t * PyThread_tss_alloc(void) {
  Py_tss_t *key = (Py_tss_t *)PyObject_Malloc(sizeof(Py_tss_t));
  *key = Py_tss_NEEDS_INIT;
  return key;
}
static CYTHON_INLINE void PyThread_tss_free(Py_tss_t *key) {
  PyObject_Free(key);
}
static CYTHON_INLINE int PyThread_tss_is_created(Py_tss_t *key) {
  return *key != Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE void PyThread_tss_delete(Py_tss_t *key) {
  PyThread_delete_key(*key);
  *key = Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE int PyThread_tss_set(Py_tss_t *key, void *value) {
  return PyThread_set_key_value(*key, value);
}
static CYTHON_INLINE void * PyThread_tss_get(Py_tss_t *key) {
  return PyThread_get_key_value(*key);
}
#endif // TSS (Thread Specific Storage) API
#if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
#define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
#else
#define __Pyx_PyDict_NewPresized(n)  PyDict_New()
#endif
#if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030500A1 && CYTHON_USE_UNICODE_INTERNALS
#define __Pyx_PyDict_GetItemStr(dict, name)  _PyDict_GetItem_KnownHash(dict, name, ((PyASCIIObject *) name)->hash)
#else
#define __Pyx_PyDict_GetItemStr(dict, name)  PyDict_GetItem(dict, name)
#endif
#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                              0 : _PyUnicode_Ready((PyObject *)(op)))
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
#else
  #define CYTHON_PEP393_ENABLED 0
  #define PyUnicode_1BYTE_KIND  1
  #define PyUnicode_2BYTE_KIND  2
  #define PyUnicode_4BYTE_KIND  4
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((sizeof(Py_UNICODE) == 2) ? 65535 : 1114111)
  #define __Pyx_PyUnicode_KIND(u)         (sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  (((void)(k)), ((Py_UNICODE*)d)[i] = ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_SIZE(u))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyUnicode_Contains)
  #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyByteArray_Check)
  #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Format)
  #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None || (PyString_Check(b) && !PyString_CheckExact(b)))) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None || (PyUnicode_Check(b) && !PyUnicode_CheckExact(b)))) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION < 3 && !defined(PyObject_ASCII)
  #define PyObject_ASCII(o)            PyObject_Repr(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
  #define PyObject_Unicode             PyObject_Str
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
#endif
#if CYTHON_ASSUME_SAFE_MACROS
  #define __Pyx_PySequence_SIZE(seq)  Py_SIZE(seq)
#else
  #define __Pyx_PySequence_SIZE(seq)  PySequence_Size(seq)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyMethod_New(func, self, klass) ((self) ? PyMethod_New(func, self) : (Py_INCREF(func), func))
#else
  #define __Pyx_PyMethod_New(func, self, klass) PyMethod_New(func, self, klass)
#endif
#if CYTHON_USE_ASYNC_SLOTS
  #if PY_VERSION_HEX >= 0x030500B1
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
    #define __Pyx_PyType_AsAsync(obj) (Py_TYPE(obj)->tp_as_async)
  #else
    #define __Pyx_PyType_AsAsync(obj) ((__Pyx_PyAsyncMethodsStruct*) (Py_TYPE(obj)->tp_reserved))
  #endif
#else
  #define __Pyx_PyType_AsAsync(obj) NULL
#endif
#ifndef __Pyx_PyAsyncMethodsStruct
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
    } __Pyx_PyAsyncMethodsStruct;
#endif

#if defined(WIN32) || defined(MS_WINDOWS)
  #define _USE_MATH_DEFINES
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif


#define __PYX_ERR(f_index, lineno, Ln_error) \
{ \
  __pyx_filename = __pyx_f[f_index]; __pyx_lineno = lineno; __pyx_clineno = __LINE__; goto Ln_error; \
}

#ifndef __PYX_EXTERN_C
  #ifdef __cplusplus
    #define __PYX_EXTERN_C extern "C"
  #else
    #define __PYX_EXTERN_C extern
  #endif
#endif

#define __PYX_HAVE__srctools___tokenizer
#define __PYX_HAVE_API__srctools___tokenizer
/* Early includes */
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#if defined(PYREX_WITHOUT_ASSERTIONS) && !defined(CYTHON_WITHOUT_ASSERTIONS)
#define CYTHON_WITHOUT_ASSERTIONS
#endif

typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
static CYTHON_INLINE int __Pyx_is_valid_index(Py_ssize_t i, Py_ssize_t limit) {
    return (size_t) i < (size_t) limit;
}
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER)
    #define __Pyx_sst_abs(value) ((Py_ssize_t)_abs64(value))
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
#define __Pyx_PyByteArray_FromString(s) PyByteArray_FromStringAndSize((const char*)s, strlen((const char*)s))
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyBytes_AsWritableString(s)     ((char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableSString(s)    ((signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableUString(s)    ((unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsString(s)     ((const char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsSString(s)    ((const signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsUString(s)    ((const unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyObject_AsWritableString(s)    ((char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableSString(s)    ((signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableUString(s)    ((unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u) {
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
#define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b);
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
#define __Pyx_PySequence_Tuple(obj)\
    (likely(PyTuple_CheckExact(obj)) ? __Pyx_NewRef(obj) : PySequence_Tuple(obj))
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
#if CYTHON_ASSUME_SAFE_MACROS
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#else
#define __Pyx_PyNumber_Int(x) (PyInt_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Int(x))
#endif
#define __Pyx_PyNumber_Float(x) (PyFloat_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Float(x))
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c) + 1);
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */
static CYTHON_INLINE void __Pyx_pretend_to_initialize(void* ptr) { (void)ptr; }

static PyObject *__pyx_m = NULL;
static PyObject *__pyx_d;
static PyObject *__pyx_b;
static PyObject *__pyx_cython_runtime = NULL;
static PyObject *__pyx_empty_tuple;
static PyObject *__pyx_empty_bytes;
static PyObject *__pyx_empty_unicode;
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm= __FILE__;
static const char *__pyx_filename;


static const char *__pyx_f[] = {
  "srctools\\_tokenizer.pyx",
};

/*--- Type declarations ---*/
struct __pyx_obj_8srctools_10_tokenizer_Tokenizer;
struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter;

/* "srctools/_tokenizer.pyx":60
 * 
 * @cython.final  # No point in inheriting from this.
 * cdef class Tokenizer:             # <<<<<<<<<<<<<<
 *     """Processes text data into groups of tokens.
 * 
 */
struct __pyx_obj_8srctools_10_tokenizer_Tokenizer {
  PyObject_HEAD
  struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *__pyx_vtab;
  PyObject *cur_chunk;
  PyObject *chunk_iter;
  PyObject *error_type;
  PyObject *filename;
  int char_index;
  int line_num;
  int string_bracket;
  int allow_escapes;
  int allow_star_comments;
  PyObject *pushback_tok;
  PyObject *pushback_val;
  Py_ssize_t buf_size;
  unsigned int buf_pos;
  Py_UCS4 *val_buffer;
};


/* "srctools/_tokenizer.pyx":554
 * 
 * 
 * cdef class NewlinesIter:             # <<<<<<<<<<<<<<
 *     """Iterate over the tokens, skipping newlines."""
 *     cdef Tokenizer tok
 */
struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter {
  PyObject_HEAD
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *tok;
};



/* "srctools/_tokenizer.pyx":60
 * 
 * @cython.final  # No point in inheriting from this.
 * cdef class Tokenizer:             # <<<<<<<<<<<<<<
 *     """Processes text data into groups of tokens.
 * 
 */

struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer {
  PyObject *(*_error)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, PyObject *);
  void (*buf_reset)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
  void (*buf_add_char)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, Py_UCS4);
  PyObject *(*buf_get_text)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
  Py_UCS4 (*_next_char)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
  PyObject *(*next_token)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
};
static struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *__pyx_vtabptr_8srctools_10_tokenizer_Tokenizer;
static CYTHON_INLINE PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer__error(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, PyObject *);
static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, Py_UCS4);
static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
static Py_UCS4 __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);

/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, int);
    void (*DECREF)(void*, PyObject*, int);
    void (*GOTREF)(void*, PyObject*, int);
    void (*GIVEREF)(void*, PyObject*, int);
    void* (*SetupContext)(const char*, int, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
#endif
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* KeywordStringCheck.proto */
static int __Pyx_CheckKeywordStrings(PyObject *kwdict, const char* function_name, int kw_allowed);

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject **argnames[],\
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args,\
    const char* function_name);

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = __Pyx_PyThreadState_Current;
#define __Pyx_PyErr_Occurred()  __pyx_tstate->curexc_type
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#define __Pyx_PyErr_Occurred()  PyErr_Occurred()
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_Clear() __Pyx_ErrRestore(NULL, NULL, NULL)
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_PyErr_SetNone(exc) (Py_INCREF(exc), __Pyx_ErrRestore((exc), NULL, NULL))
#else
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#endif
#else
#define __Pyx_PyErr_Clear() PyErr_Clear()
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestoreInState(tstate, type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchInState(tstate, type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* PyCFunctionFastCall.proto */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject *__Pyx_PyCFunction_FastCall(PyObject *func, PyObject **args, Py_ssize_t nargs);
#else
#define __Pyx_PyCFunction_FastCall(func, args, nargs)  (assert(0), NULL)
#endif

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs);
#else
#define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
#endif
#define __Pyx_BUILD_ASSERT_EXPR(cond)\
    (sizeof(char [1 - 2*!(cond)]) - 1)
#ifndef Py_MEMBER_SIZE
#define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
#endif
  static size_t __pyx_pyframe_localsplus_offset = 0;
  #include "frameobject.h"
  #define __Pxy_PyFrame_Initialize_Offsets()\
    ((void)__Pyx_BUILD_ASSERT_EXPR(sizeof(PyFrameObject) == offsetof(PyFrameObject, f_localsplus) + Py_MEMBER_SIZE(PyFrameObject, f_localsplus)),\
     (void)(__pyx_pyframe_localsplus_offset = PyFrame_Type.tp_basicsize - Py_MEMBER_SIZE(PyFrameObject, f_localsplus)))
  #define __Pyx_PyFrame_GetLocalsplus(frame)\
    (assert(__pyx_pyframe_localsplus_offset), (PyObject **)(((char *)(frame)) + __pyx_pyframe_localsplus_offset))
#endif

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* PyObjectCall2Args.proto */
static CYTHON_UNUSED PyObject* __Pyx_PyObject_Call2Args(PyObject* function, PyObject* arg1, PyObject* arg2);

/* GetTopmostException.proto */
#if CYTHON_USE_EXC_INFO_STACK
static _PyErr_StackItem * __Pyx_PyErr_GetTopmostException(PyThreadState *tstate);
#endif

/* SaveResetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSave(type, value, tb)  __Pyx__ExceptionSave(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#define __Pyx_ExceptionReset(type, value, tb)  __Pyx__ExceptionReset(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
#else
#define __Pyx_ExceptionSave(type, value, tb)   PyErr_GetExcInfo(type, value, tb)
#define __Pyx_ExceptionReset(type, value, tb)  PyErr_SetExcInfo(type, value, tb)
#endif

/* PyErrExceptionMatches.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_ExceptionMatches(err) __Pyx_PyErr_ExceptionMatchesInState(__pyx_tstate, err)
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err);
#else
#define __Pyx_PyErr_ExceptionMatches(err)  PyErr_ExceptionMatches(err)
#endif

/* GetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_GetException(type, value, tb)  __Pyx__GetException(__pyx_tstate, type, value, tb)
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* PyObjectFormatSimple.proto */
#if CYTHON_COMPILING_IN_PYPY
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        PyObject_Format(s, f))
#elif PY_MAJOR_VERSION < 3
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        likely(PyString_CheckExact(s)) ? PyUnicode_FromEncodedObject(s, NULL, "strict") :\
        PyObject_Format(s, f))
#elif CYTHON_USE_TYPE_SLOTS
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        likely(PyLong_CheckExact(s)) ? PyLong_Type.tp_str(s) :\
        likely(PyFloat_CheckExact(s)) ? PyFloat_Type.tp_str(s) :\
        PyObject_Format(s, f))
#else
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        PyObject_Format(s, f))
#endif

/* IncludeStringH.proto */
#include <string.h>

/* JoinPyUnicode.proto */
static PyObject* __Pyx_PyUnicode_Join(PyObject* value_tuple, Py_ssize_t value_count, Py_ssize_t result_ulength,
                                      Py_UCS4 max_char);

/* GetItemIntUnicode.proto */
#define __Pyx_GetItemInt_Unicode(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Unicode_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "string index out of range"), (Py_UCS4)-1))
static CYTHON_INLINE Py_UCS4 __Pyx_GetItemInt_Unicode_Fast(PyObject* ustring, Py_ssize_t i,
                                                           int wraparound, int boundscheck);

/* IterNext.proto */
#define __Pyx_PyIter_Next(obj) __Pyx_PyIter_Next2(obj, NULL)
static CYTHON_INLINE PyObject *__Pyx_PyIter_Next2(PyObject *, PyObject *);

/* BuildPyUnicode.proto */
static PyObject* __Pyx_PyUnicode_BuildFromAscii(Py_ssize_t ulength, char* chars, int clength,
                                                int prepend_sign, char padding_char);

/* CIntToPyUnicode.proto */
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_From_int(int value, Py_ssize_t width, char padding_char, char format_char);

/* ArgTypeTest.proto */
#define __Pyx_ArgTypeTest(obj, type, none_allowed, name, exact)\
    ((likely((Py_TYPE(obj) == type) | (none_allowed && (obj == Py_None)))) ? 1 :\
        __Pyx__ArgTypeTest(obj, type, name, exact))
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact);

/* BytesEquals.proto */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals);

/* UnicodeEquals.proto */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals);

/* PyObjectFormatAndDecref.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatSimpleAndDecref(PyObject* s, PyObject* f);
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatAndDecref(PyObject* s, PyObject* f);

/* RaiseTooManyValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);

/* RaiseNeedMoreValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);

/* RaiseNoneIterError.proto */
static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void);

/* SwapException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSwap(type, value, tb)  __Pyx__ExceptionSwap(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* PyObject_GenericGetAttrNoDict.proto */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static CYTHON_INLINE PyObject* __Pyx_PyObject_GenericGetAttrNoDict(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GenericGetAttrNoDict PyObject_GenericGetAttr
#endif

/* SetVTable.proto */
static int __Pyx_SetVtable(PyObject *dict, void *vtable);

/* PyObject_GenericGetAttr.proto */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static PyObject* __Pyx_PyObject_GenericGetAttr(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GenericGetAttr PyObject_GenericGetAttr
#endif

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

/* ImportFrom.proto */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name);

/* GetAttr.proto */
static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *, PyObject *);

/* Globals.proto */
static PyObject* __Pyx_Globals(void);

/* CLineInTraceback.proto */
#ifdef CYTHON_CLINE_IN_TRACEBACK
#define __Pyx_CLineForTraceback(tstate, c_line)  (((CYTHON_CLINE_IN_TRACEBACK)) ? c_line : 0)
#else
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line);
#endif

/* CodeObjectCache.proto */
typedef struct {
    PyCodeObject* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

/* PyUCS4InUnicode.proto */
static CYTHON_INLINE int __Pyx_UnicodeContainsUCS4(PyObject* unicode, Py_UCS4 character);

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE char __Pyx_PyInt_As_char(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

/* FastTypeChecks.proto */
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_TypeCheck(obj, type) __Pyx_IsSubtype(Py_TYPE(obj), (PyTypeObject *)type)
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject *type);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *type1, PyObject *type2);
#else
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_PyErr_GivenExceptionMatches(err, type) PyErr_GivenExceptionMatches(err, type)
#define __Pyx_PyErr_GivenExceptionMatches2(err, type1, type2) (PyErr_GivenExceptionMatches(err, type1) || PyErr_GivenExceptionMatches(err, type2))
#endif
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)

/* CheckBinaryVersion.proto */
static int __Pyx_check_binary_version(void);

/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);

static CYTHON_INLINE PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer__error(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_message); /* proto*/
static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/
static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, Py_UCS4 __pyx_v_uchar); /* proto*/
static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/
static Py_UCS4 __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/
static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/

/* Module declarations from 'cython' */

/* Module declarations from 'cpython.mem' */

/* Module declarations from 'srctools._tokenizer' */
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer_Tokenizer = 0;
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer_NewlinesIter = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer__conv_path = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_Token = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_TokenSyntaxError = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_STRING = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_PAREN_ARGS = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_PROP_FLAG = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_EOF = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_NEWLINE = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_EMPTY_ITER = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_EOF_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_COLON_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_EQUALS_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_PLUS_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP = 0;
#define __Pyx_MODULE_NAME "srctools._tokenizer"
extern int __pyx_module_is_main_srctools___tokenizer;
int __pyx_module_is_main_srctools___tokenizer = 0;

/* Implementation of 'srctools._tokenizer' */
static PyObject *__pyx_builtin_ImportError;
static PyObject *__pyx_builtin_ValueError;
static PyObject *__pyx_builtin_AttributeError;
static PyObject *__pyx_builtin_TypeError;
static PyObject *__pyx_builtin_NotImplementedError;
static PyObject *__pyx_builtin_StopIteration;
static const char __pyx_k_i[] = "i";
static const char __pyx_k__2[] = "";
static const char __pyx_k__3[] = "\"!";
static const char __pyx_k__5[] = "!";
static const char __pyx_k__8[] = ")!";
static const char __pyx_k_os[] = "os";
static const char __pyx_k_EOF[] = "EOF";
static const char __pyx_k__10[] = "\n";
static const char __pyx_k__11[] = "{";
static const char __pyx_k__12[] = "}";
static const char __pyx_k__13[] = "[";
static const char __pyx_k__14[] = "]";
static const char __pyx_k__15[] = ":";
static const char __pyx_k__16[] = "=";
static const char __pyx_k__17[] = "+";
static const char __pyx_k_for[] = ") for ";
static const char __pyx_k_tok[] = "tok";
static const char __pyx_k_PLUS[] = "PLUS";
static const char __pyx_k_data[] = "data";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_name[] = "name";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_text[] = "text";
static const char __pyx_k_COLON[] = "COLON";
static const char __pyx_k_Token[] = "Token";
static const char __pyx_k_error[] = "error";
static const char __pyx_k_token[] = "token";
static const char __pyx_k_value[] = "value";
static const char __pyx_k_EQUALS[] = "EQUALS";
static const char __pyx_k_STRING[] = "STRING";
static const char __pyx_k_format[] = "format";
static const char __pyx_k_fspath[] = "fspath";
static const char __pyx_k_import[] = "__import__";
static const char __pyx_k_letter[] = "letter";
static const char __pyx_k_name_2[] = "__name__";
static const char __pyx_k_NEWLINE[] = "NEWLINE";
static const char __pyx_k_but_got[] = ", but got ";
static const char __pyx_k_message[] = "message";
static const char __pyx_k_Expected[] = "Expected ";
static const char __pyx_k_enc_text[] = "enc_text";
static const char __pyx_k_filename[] = "filename";
static const char __pyx_k_out_buff[] = "out_buff";
static const char __pyx_k_PROP_FLAG[] = "PROP_FLAG";
static const char __pyx_k_Tokenizer[] = "Tokenizer";
static const char __pyx_k_TypeError[] = "TypeError";
static const char __pyx_k_final_len[] = "final_len";
static const char __pyx_k_BRACE_OPEN[] = "BRACE_OPEN";
static const char __pyx_k_BRACK_OPEN[] = "BRACK_OPEN";
static const char __pyx_k_PAREN_ARGS[] = "PAREN_ARGS";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_pyx_vtable[] = "__pyx_vtable__";
static const char __pyx_k_BRACE_CLOSE[] = "BRACE_CLOSE";
static const char __pyx_k_BRACK_CLOSE[] = "BRACK_CLOSE";
static const char __pyx_k_ImportError[] = "ImportError";
static const char __pyx_k_escape_text[] = "escape_text";
static const char __pyx_k_NewlinesIter[] = "NewlinesIter";
static const char __pyx_k_skip_newline[] = "skip_newline";
static const char __pyx_k_StopIteration[] = "StopIteration";
static const char __pyx_k_allow_escapes[] = "allow_escapes";
static const char __pyx_k_AttributeError[] = "AttributeError";
static const char __pyx_k_is_not_a_Token[] = " is not a Token!";
static const char __pyx_k_string_bracket[] = "string_bracket";
static const char __pyx_k_TokenSyntaxError[] = "TokenSyntaxError";
static const char __pyx_k_Unexpected_token[] = "Unexpected token ";
static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
static const char __pyx_k_srctools_tokenizer[] = "srctools.tokenizer";
static const char __pyx_k_NotImplementedError[] = "NotImplementedError";
static const char __pyx_k_Unknown_token_value[] = "Unknown token value!";
static const char __pyx_k_Unterminated_string[] = "Unterminated string!";
static const char __pyx_k_allow_star_comments[] = "allow_star_comments";
static const char __pyx_k_srctools__tokenizer[] = "srctools._tokenizer";
static const char __pyx_k_Cannot_nest_brackets[] = "Cannot nest [] brackets!";
static const char __pyx_k_Unexpected_character[] = "Unexpected character \"";
static const char __pyx_k_Data_was_not_a_string[] = "Data was not a string!";
static const char __pyx_k_No_open_to_close_with[] = "No open [] to close with \"]\"!";
static const char __pyx_k_Cannot_nest_brackets_2[] = "Cannot nest () brackets!";
static const char __pyx_k_Invalid_error_instance[] = "Invalid error instance \"";
static const char __pyx_k_Invalid_value_provided[] = "Invalid value provided (";
static const char __pyx_k_No_open_to_close_with_2[] = "No open () to close with \")\"!";
static const char __pyx_k_srctools__tokenizer_pyx[] = "srctools\\_tokenizer.pyx";
static const char __pyx_k_Cannot_parse_binary_data[] = "Cannot parse binary data!";
static const char __pyx_k_Cannot_pickle_Tokenizers[] = "Cannot pickle Tokenizers!";
static const char __pyx_k_Unterminated_parentheses[] = "Unterminated parentheses!";
static const char __pyx_k_Token_already_pushed_back[] = "Token already pushed back!";
static const char __pyx_k_Cannot_pickle_NewlinesIter[] = "Cannot pickle NewlinesIter!";
static const char __pyx_k_style_comments_are_not_allowed[] = "/**/-style comments are not allowed!";
static const char __pyx_k_Cannot_parse_binary_data_Decode[] = "Cannot parse binary data! Decode to the desired encoding, or wrap in io.TextIOWrapper() to decode gradually.";
static const char __pyx_k_Cython_version_of_the_Tokenizer[] = "Cython version of the Tokenizer class.";
static const char __pyx_k_Reached_end_of_line_without_clos[] = "Reached end of line without closing \"]\"!";
static const char __pyx_k_Single_slash_found_instead_of_tw[] = "Single slash found, instead of two for a comment (// or /* */)!";
static const char __pyx_k_Unclosed_comment_starting_on_lin[] = "Unclosed /* comment (starting on line ";
static const char __pyx_k_Single_slash_found_instead_of_tw_2[] = "Single slash found, instead of two for a comment (//)!";
static PyObject *__pyx_n_s_AttributeError;
static PyObject *__pyx_n_s_BRACE_CLOSE;
static PyObject *__pyx_n_s_BRACE_OPEN;
static PyObject *__pyx_n_s_BRACK_CLOSE;
static PyObject *__pyx_n_s_BRACK_OPEN;
static PyObject *__pyx_n_s_COLON;
static PyObject *__pyx_kp_u_Cannot_nest_brackets;
static PyObject *__pyx_kp_u_Cannot_nest_brackets_2;
static PyObject *__pyx_kp_u_Cannot_parse_binary_data;
static PyObject *__pyx_kp_u_Cannot_parse_binary_data_Decode;
static PyObject *__pyx_kp_u_Cannot_pickle_NewlinesIter;
static PyObject *__pyx_kp_u_Cannot_pickle_Tokenizers;
static PyObject *__pyx_kp_u_Data_was_not_a_string;
static PyObject *__pyx_n_s_EOF;
static PyObject *__pyx_n_s_EQUALS;
static PyObject *__pyx_kp_u_Expected;
static PyObject *__pyx_n_s_ImportError;
static PyObject *__pyx_kp_u_Invalid_error_instance;
static PyObject *__pyx_kp_u_Invalid_value_provided;
static PyObject *__pyx_n_s_NEWLINE;
static PyObject *__pyx_n_s_NewlinesIter;
static PyObject *__pyx_n_u_NewlinesIter;
static PyObject *__pyx_kp_u_No_open_to_close_with;
static PyObject *__pyx_kp_u_No_open_to_close_with_2;
static PyObject *__pyx_n_s_NotImplementedError;
static PyObject *__pyx_n_s_PAREN_ARGS;
static PyObject *__pyx_n_s_PLUS;
static PyObject *__pyx_n_s_PROP_FLAG;
static PyObject *__pyx_kp_u_Reached_end_of_line_without_clos;
static PyObject *__pyx_n_s_STRING;
static PyObject *__pyx_kp_u_Single_slash_found_instead_of_tw;
static PyObject *__pyx_kp_u_Single_slash_found_instead_of_tw_2;
static PyObject *__pyx_n_s_StopIteration;
static PyObject *__pyx_n_s_Token;
static PyObject *__pyx_n_s_TokenSyntaxError;
static PyObject *__pyx_kp_u_Token_already_pushed_back;
static PyObject *__pyx_n_s_Tokenizer;
static PyObject *__pyx_n_s_TypeError;
static PyObject *__pyx_kp_u_Unclosed_comment_starting_on_lin;
static PyObject *__pyx_kp_u_Unexpected_character;
static PyObject *__pyx_kp_u_Unexpected_token;
static PyObject *__pyx_kp_u_Unknown_token_value;
static PyObject *__pyx_kp_u_Unterminated_parentheses;
static PyObject *__pyx_kp_u_Unterminated_string;
static PyObject *__pyx_n_s_ValueError;
static PyObject *__pyx_kp_u__10;
static PyObject *__pyx_kp_u__11;
static PyObject *__pyx_kp_u__12;
static PyObject *__pyx_kp_u__13;
static PyObject *__pyx_kp_u__14;
static PyObject *__pyx_kp_u__15;
static PyObject *__pyx_kp_u__16;
static PyObject *__pyx_kp_u__17;
static PyObject *__pyx_kp_u__2;
static PyObject *__pyx_kp_u__3;
static PyObject *__pyx_kp_u__5;
static PyObject *__pyx_kp_u__8;
static PyObject *__pyx_n_s_allow_escapes;
static PyObject *__pyx_n_s_allow_star_comments;
static PyObject *__pyx_kp_u_but_got;
static PyObject *__pyx_n_s_cline_in_traceback;
static PyObject *__pyx_n_s_data;
static PyObject *__pyx_n_s_enc_text;
static PyObject *__pyx_n_s_error;
static PyObject *__pyx_n_s_escape_text;
static PyObject *__pyx_n_s_filename;
static PyObject *__pyx_n_s_final_len;
static PyObject *__pyx_kp_u_for;
static PyObject *__pyx_n_s_format;
static PyObject *__pyx_n_s_fspath;
static PyObject *__pyx_n_s_i;
static PyObject *__pyx_n_s_import;
static PyObject *__pyx_kp_u_is_not_a_Token;
static PyObject *__pyx_n_s_letter;
static PyObject *__pyx_n_s_main;
static PyObject *__pyx_n_s_message;
static PyObject *__pyx_n_s_name;
static PyObject *__pyx_n_s_name_2;
static PyObject *__pyx_n_s_os;
static PyObject *__pyx_n_s_out_buff;
static PyObject *__pyx_n_s_pyx_vtable;
static PyObject *__pyx_n_s_skip_newline;
static PyObject *__pyx_n_s_srctools__tokenizer;
static PyObject *__pyx_kp_s_srctools__tokenizer_pyx;
static PyObject *__pyx_n_s_srctools_tokenizer;
static PyObject *__pyx_n_s_string_bracket;
static PyObject *__pyx_kp_u_style_comments_are_not_allowed;
static PyObject *__pyx_n_s_test;
static PyObject *__pyx_n_s_text;
static PyObject *__pyx_n_s_tok;
static PyObject *__pyx_n_s_token;
static PyObject *__pyx_n_s_value;
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer___cinit__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static void __pyx_pf_8srctools_10_tokenizer_9Tokenizer_2__dealloc__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_4__init__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_data, PyObject *__pyx_v_filename, PyObject *__pyx_v_error, int __pyx_v_string_bracket, int __pyx_v_allow_escapes, int __pyx_v_allow_star_comments); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_6__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_8error(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_message, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_10__call__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_12__iter__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_14push_back(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_tok, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_16peek(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_18skipping_newlines(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_20expect(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_token, int __pyx_v_skip_newline); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_8filename___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8filename_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8filename_4__del__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_8line_num___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8line_num_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_12NewlinesIter___cinit__(struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *__pyx_v_self, struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_tok); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_12NewlinesIter_2__iter__(struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_12NewlinesIter_4__next__(struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_12NewlinesIter_6__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_escape_text(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_text); /* proto */
static PyObject *__pyx_tp_new_8srctools_10_tokenizer_Tokenizer(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_8srctools_10_tokenizer_NewlinesIter(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tuple_;
static PyObject *__pyx_tuple__4;
static PyObject *__pyx_tuple__6;
static PyObject *__pyx_tuple__7;
static PyObject *__pyx_tuple__9;
static PyObject *__pyx_tuple__18;
static PyObject *__pyx_tuple__19;
static PyObject *__pyx_tuple__20;
static PyObject *__pyx_codeobj__21;
/* Late includes */

/* "srctools/_tokenizer.pyx":95
 *     cdef Py_UCS4* val_buffer
 * 
 *     def __cinit__(self):             # <<<<<<<<<<<<<<
 *         self.val_buffer = <Py_UCS4 *>PyMem_Malloc(32 * sizeof(Py_UCS4))
 *         self.buf_size = 32
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return -1;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__cinit__", 0))) return -1;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer___cinit__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer___cinit__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "srctools/_tokenizer.pyx":96
 * 
 *     def __cinit__(self):
 *         self.val_buffer = <Py_UCS4 *>PyMem_Malloc(32 * sizeof(Py_UCS4))             # <<<<<<<<<<<<<<
 *         self.buf_size = 32
 *         self.buf_pos = 0
 */
  __pyx_v_self->val_buffer = ((Py_UCS4 *)PyMem_Malloc((32 * (sizeof(Py_UCS4)))));

  /* "srctools/_tokenizer.pyx":97
 *     def __cinit__(self):
 *         self.val_buffer = <Py_UCS4 *>PyMem_Malloc(32 * sizeof(Py_UCS4))
 *         self.buf_size = 32             # <<<<<<<<<<<<<<
 *         self.buf_pos = 0
 * 
 */
  __pyx_v_self->buf_size = 32;

  /* "srctools/_tokenizer.pyx":98
 *         self.val_buffer = <Py_UCS4 *>PyMem_Malloc(32 * sizeof(Py_UCS4))
 *         self.buf_size = 32
 *         self.buf_pos = 0             # <<<<<<<<<<<<<<
 * 
 *     def __dealloc__(self):
 */
  __pyx_v_self->buf_pos = 0;

  /* "srctools/_tokenizer.pyx":95
 *     cdef Py_UCS4* val_buffer
 * 
 *     def __cinit__(self):             # <<<<<<<<<<<<<<
 *         self.val_buffer = <Py_UCS4 *>PyMem_Malloc(32 * sizeof(Py_UCS4))
 *         self.buf_size = 32
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":100
 *         self.buf_pos = 0
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         PyMem_Free(self.val_buffer)
 * 
 */

/* Python wrapper */
static void __pyx_pw_8srctools_10_tokenizer_9Tokenizer_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_8srctools_10_tokenizer_9Tokenizer_3__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_8srctools_10_tokenizer_9Tokenizer_2__dealloc__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_8srctools_10_tokenizer_9Tokenizer_2__dealloc__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "srctools/_tokenizer.pyx":101
 * 
 *     def __dealloc__(self):
 *         PyMem_Free(self.val_buffer)             # <<<<<<<<<<<<<<
 * 
 *     def __init__(
 */
  PyMem_Free(__pyx_v_self->val_buffer);

  /* "srctools/_tokenizer.pyx":100
 *         self.buf_pos = 0
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         PyMem_Free(self.val_buffer)
 * 
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "srctools/_tokenizer.pyx":103
 *         PyMem_Free(self.val_buffer)
 * 
 *     def __init__(             # <<<<<<<<<<<<<<
 *         self,
 *         data not None,
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_data = 0;
  PyObject *__pyx_v_filename = 0;
  PyObject *__pyx_v_error = 0;
  int __pyx_v_string_bracket;
  int __pyx_v_allow_escapes;
  int __pyx_v_allow_star_comments;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_data,&__pyx_n_s_filename,&__pyx_n_s_error,&__pyx_n_s_string_bracket,&__pyx_n_s_allow_escapes,&__pyx_n_s_allow_star_comments,0};
    PyObject* values[6] = {0,0,0,0,0,0};

    /* "srctools/_tokenizer.pyx":106
 *         self,
 *         data not None,
 *         object filename=None,             # <<<<<<<<<<<<<<
 *         error=None,
 *         bint string_bracket=False,
 */
    values[1] = ((PyObject *)Py_None);

    /* "srctools/_tokenizer.pyx":107
 *         data not None,
 *         object filename=None,
 *         error=None,             # <<<<<<<<<<<<<<
 *         bint string_bracket=False,
 *         bint allow_escapes=True,
 */
    values[2] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_data)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_filename);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_error);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_string_bracket);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_allow_escapes);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_allow_star_comments);
          if (value) { values[5] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 103, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_data = values[0];
    __pyx_v_filename = values[1];
    __pyx_v_error = values[2];
    if (values[3]) {
      __pyx_v_string_bracket = __Pyx_PyObject_IsTrue(values[3]); if (unlikely((__pyx_v_string_bracket == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 108, __pyx_L3_error)
    } else {

      /* "srctools/_tokenizer.pyx":108
 *         object filename=None,
 *         error=None,
 *         bint string_bracket=False,             # <<<<<<<<<<<<<<
 *         bint allow_escapes=True,
 *         bint allow_star_comments=False,
 */
      __pyx_v_string_bracket = ((int)0);
    }
    if (values[4]) {
      __pyx_v_allow_escapes = __Pyx_PyObject_IsTrue(values[4]); if (unlikely((__pyx_v_allow_escapes == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 109, __pyx_L3_error)
    } else {

      /* "srctools/_tokenizer.pyx":109
 *         error=None,
 *         bint string_bracket=False,
 *         bint allow_escapes=True,             # <<<<<<<<<<<<<<
 *         bint allow_star_comments=False,
 *     ):
 */
      __pyx_v_allow_escapes = ((int)1);
    }
    if (values[5]) {
      __pyx_v_allow_star_comments = __Pyx_PyObject_IsTrue(values[5]); if (unlikely((__pyx_v_allow_star_comments == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 110, __pyx_L3_error)
    } else {

      /* "srctools/_tokenizer.pyx":110
 *         bint string_bracket=False,
 *         bint allow_escapes=True,
 *         bint allow_star_comments=False,             # <<<<<<<<<<<<<<
 *     ):
 *         # Early warning for this particular error.
 */
      __pyx_v_allow_star_comments = ((int)0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 0, 1, 6, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 103, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(((PyObject *)__pyx_v_data) == Py_None)) {
    PyErr_Format(PyExc_TypeError, "Argument '%.200s' must not be None", "data"); __PYX_ERR(0, 105, __pyx_L1_error)
  }
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_4__init__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_data, __pyx_v_filename, __pyx_v_error, __pyx_v_string_bracket, __pyx_v_allow_escapes, __pyx_v_allow_star_comments);

  /* "srctools/_tokenizer.pyx":103
 *         PyMem_Free(self.val_buffer)
 * 
 *     def __init__(             # <<<<<<<<<<<<<<
 *         self,
 *         data not None,
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_4__init__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_data, PyObject *__pyx_v_filename, PyObject *__pyx_v_error, int __pyx_v_string_bracket, int __pyx_v_allow_escapes, int __pyx_v_allow_star_comments) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  Py_ssize_t __pyx_t_11;
  Py_UCS4 __pyx_t_12;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "srctools/_tokenizer.pyx":113
 *     ):
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):             # <<<<<<<<<<<<<<
 *             raise ValueError(
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 */
  __pyx_t_2 = PyBytes_Check(__pyx_v_data); 
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (!__pyx_t_3) {
  } else {
    __pyx_t_1 = __pyx_t_3;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_3 = PyByteArray_Check(__pyx_v_data); 
  __pyx_t_2 = (__pyx_t_3 != 0);
  __pyx_t_1 = __pyx_t_2;
  __pyx_L4_bool_binop_done:;
  if (unlikely(__pyx_t_1)) {

    /* "srctools/_tokenizer.pyx":114
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):
 *             raise ValueError(             # <<<<<<<<<<<<<<
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 *                 'or wrap in io.TextIOWrapper() to decode gradually.'
 */
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple_, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 114, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_4, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 114, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":113
 *     ):
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):             # <<<<<<<<<<<<<<
 *             raise ValueError(
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 */
  }

  /* "srctools/_tokenizer.pyx":121
 *         # For direct strings, we can immediately assign that as our chunk,
 *         # and then set the iterable to an empty iterator.
 *         if isinstance(data, str):             # <<<<<<<<<<<<<<
 *             self.cur_chunk = data
 *             self.chunk_iter = EMPTY_ITER
 */
  __pyx_t_1 = PyUnicode_Check(__pyx_v_data); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":122
 *         # and then set the iterable to an empty iterator.
 *         if isinstance(data, str):
 *             self.cur_chunk = data             # <<<<<<<<<<<<<<
 *             self.chunk_iter = EMPTY_ITER
 *         else:
 */
    if (!(likely(PyUnicode_CheckExact(__pyx_v_data))||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_v_data)->tp_name), 0))) __PYX_ERR(0, 122, __pyx_L1_error)
    __pyx_t_4 = __pyx_v_data;
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __Pyx_GOTREF(__pyx_v_self->cur_chunk);
    __Pyx_DECREF(__pyx_v_self->cur_chunk);
    __pyx_v_self->cur_chunk = ((PyObject*)__pyx_t_4);
    __pyx_t_4 = 0;

    /* "srctools/_tokenizer.pyx":123
 *         if isinstance(data, str):
 *             self.cur_chunk = data
 *             self.chunk_iter = EMPTY_ITER             # <<<<<<<<<<<<<<
 *         else:
 *             # The first next_char() call will pull out a chunk.
 */
    __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_EMPTY_ITER);
    __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_EMPTY_ITER);
    __Pyx_GOTREF(__pyx_v_self->chunk_iter);
    __Pyx_DECREF(__pyx_v_self->chunk_iter);
    __pyx_v_self->chunk_iter = __pyx_v_8srctools_10_tokenizer_EMPTY_ITER;

    /* "srctools/_tokenizer.pyx":121
 *         # For direct strings, we can immediately assign that as our chunk,
 *         # and then set the iterable to an empty iterator.
 *         if isinstance(data, str):             # <<<<<<<<<<<<<<
 *             self.cur_chunk = data
 *             self.chunk_iter = EMPTY_ITER
 */
    goto __pyx_L6;
  }

  /* "srctools/_tokenizer.pyx":126
 *         else:
 *             # The first next_char() call will pull out a chunk.
 *             self.cur_chunk = ''             # <<<<<<<<<<<<<<
 *             # This checks that it is indeed iterable.
 *             self.chunk_iter = iter(data)
 */
  /*else*/ {
    __Pyx_INCREF(__pyx_kp_u__2);
    __Pyx_GIVEREF(__pyx_kp_u__2);
    __Pyx_GOTREF(__pyx_v_self->cur_chunk);
    __Pyx_DECREF(__pyx_v_self->cur_chunk);
    __pyx_v_self->cur_chunk = __pyx_kp_u__2;

    /* "srctools/_tokenizer.pyx":128
 *             self.cur_chunk = ''
 *             # This checks that it is indeed iterable.
 *             self.chunk_iter = iter(data)             # <<<<<<<<<<<<<<
 * 
 *         # We initially add one, so it'll be 0 next.
 */
    __pyx_t_4 = PyObject_GetIter(__pyx_v_data); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 128, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __Pyx_GOTREF(__pyx_v_self->chunk_iter);
    __Pyx_DECREF(__pyx_v_self->chunk_iter);
    __pyx_v_self->chunk_iter = __pyx_t_4;
    __pyx_t_4 = 0;
  }
  __pyx_L6:;

  /* "srctools/_tokenizer.pyx":131
 * 
 *         # We initially add one, so it'll be 0 next.
 *         self.char_index = -1             # <<<<<<<<<<<<<<
 * 
 *         self.buf_reset()
 */
  __pyx_v_self->char_index = -1;

  /* "srctools/_tokenizer.pyx":133
 *         self.char_index = -1
 * 
 *         self.buf_reset()             # <<<<<<<<<<<<<<
 * 
 *         if filename:
 */
  __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

  /* "srctools/_tokenizer.pyx":135
 *         self.buf_reset()
 * 
 *         if filename:             # <<<<<<<<<<<<<<
 *             if _conv_path is None:
 *                 self.filename = str(filename)
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_filename); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 135, __pyx_L1_error)
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":136
 * 
 *         if filename:
 *             if _conv_path is None:             # <<<<<<<<<<<<<<
 *                 self.filename = str(filename)
 *             else:
 */
    __pyx_t_2 = (__pyx_v_8srctools_10_tokenizer__conv_path == Py_None);
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {

      /* "srctools/_tokenizer.pyx":137
 *         if filename:
 *             if _conv_path is None:
 *                 self.filename = str(filename)             # <<<<<<<<<<<<<<
 *             else:
 *                 self.filename = _conv_path(filename)
 */
      __pyx_t_4 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyUnicode_Type)), __pyx_v_filename); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 137, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_4);
      __Pyx_GOTREF(__pyx_v_self->filename);
      __Pyx_DECREF(__pyx_v_self->filename);
      __pyx_v_self->filename = ((PyObject*)__pyx_t_4);
      __pyx_t_4 = 0;

      /* "srctools/_tokenizer.pyx":136
 * 
 *         if filename:
 *             if _conv_path is None:             # <<<<<<<<<<<<<<
 *                 self.filename = str(filename)
 *             else:
 */
      goto __pyx_L8;
    }

    /* "srctools/_tokenizer.pyx":139
 *                 self.filename = str(filename)
 *             else:
 *                 self.filename = _conv_path(filename)             # <<<<<<<<<<<<<<
 *         else:
 *             # If a file-like object, automatically set to the filename.
 */
    /*else*/ {
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer__conv_path);
      __pyx_t_5 = __pyx_v_8srctools_10_tokenizer__conv_path; __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
        }
      }
      __pyx_t_4 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_6, __pyx_v_filename) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_filename);
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 139, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      if (!(likely(PyUnicode_CheckExact(__pyx_t_4))||((__pyx_t_4) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_t_4)->tp_name), 0))) __PYX_ERR(0, 139, __pyx_L1_error)
      __Pyx_GIVEREF(__pyx_t_4);
      __Pyx_GOTREF(__pyx_v_self->filename);
      __Pyx_DECREF(__pyx_v_self->filename);
      __pyx_v_self->filename = ((PyObject*)__pyx_t_4);
      __pyx_t_4 = 0;
    }
    __pyx_L8:;

    /* "srctools/_tokenizer.pyx":135
 *         self.buf_reset()
 * 
 *         if filename:             # <<<<<<<<<<<<<<
 *             if _conv_path is None:
 *                 self.filename = str(filename)
 */
    goto __pyx_L7;
  }

  /* "srctools/_tokenizer.pyx":142
 *         else:
 *             # If a file-like object, automatically set to the filename.
 *             try:             # <<<<<<<<<<<<<<
 *                 self.filename = str(data.name)
 *             except AttributeError:
 */
  /*else*/ {
    {
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
      __Pyx_XGOTREF(__pyx_t_7);
      __Pyx_XGOTREF(__pyx_t_8);
      __Pyx_XGOTREF(__pyx_t_9);
      /*try:*/ {

        /* "srctools/_tokenizer.pyx":143
 *             # If a file-like object, automatically set to the filename.
 *             try:
 *                 self.filename = str(data.name)             # <<<<<<<<<<<<<<
 *             except AttributeError:
 *                 # If not, a Falsey value is excluded by the exception message.
 */
        __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_data, __pyx_n_s_name); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 143, __pyx_L9_error)
        __Pyx_GOTREF(__pyx_t_4);
        __pyx_t_5 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyUnicode_Type)), __pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 143, __pyx_L9_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GIVEREF(__pyx_t_5);
        __Pyx_GOTREF(__pyx_v_self->filename);
        __Pyx_DECREF(__pyx_v_self->filename);
        __pyx_v_self->filename = ((PyObject*)__pyx_t_5);
        __pyx_t_5 = 0;

        /* "srctools/_tokenizer.pyx":142
 *         else:
 *             # If a file-like object, automatically set to the filename.
 *             try:             # <<<<<<<<<<<<<<
 *                 self.filename = str(data.name)
 *             except AttributeError:
 */
      }
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      goto __pyx_L14_try_end;
      __pyx_L9_error:;
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "srctools/_tokenizer.pyx":144
 *             try:
 *                 self.filename = str(data.name)
 *             except AttributeError:             # <<<<<<<<<<<<<<
 *                 # If not, a Falsey value is excluded by the exception message.
 *                 self.filename = ''
 */
      __pyx_t_10 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_AttributeError);
      if (__pyx_t_10) {
        __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
        if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_4, &__pyx_t_6) < 0) __PYX_ERR(0, 144, __pyx_L11_except_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_GOTREF(__pyx_t_6);

        /* "srctools/_tokenizer.pyx":146
 *             except AttributeError:
 *                 # If not, a Falsey value is excluded by the exception message.
 *                 self.filename = ''             # <<<<<<<<<<<<<<
 * 
 *         if error is None:
 */
        __Pyx_INCREF(__pyx_kp_u__2);
        __Pyx_GIVEREF(__pyx_kp_u__2);
        __Pyx_GOTREF(__pyx_v_self->filename);
        __Pyx_DECREF(__pyx_v_self->filename);
        __pyx_v_self->filename = __pyx_kp_u__2;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        goto __pyx_L10_exception_handled;
      }
      goto __pyx_L11_except_error;
      __pyx_L11_except_error:;

      /* "srctools/_tokenizer.pyx":142
 *         else:
 *             # If a file-like object, automatically set to the filename.
 *             try:             # <<<<<<<<<<<<<<
 *                 self.filename = str(data.name)
 *             except AttributeError:
 */
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_XGIVEREF(__pyx_t_8);
      __Pyx_XGIVEREF(__pyx_t_9);
      __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      goto __pyx_L1_error;
      __pyx_L10_exception_handled:;
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_XGIVEREF(__pyx_t_8);
      __Pyx_XGIVEREF(__pyx_t_9);
      __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      __pyx_L14_try_end:;
    }
  }
  __pyx_L7:;

  /* "srctools/_tokenizer.pyx":148
 *                 self.filename = ''
 * 
 *         if error is None:             # <<<<<<<<<<<<<<
 *             self.error_type = TokenSyntaxError
 *         else:
 */
  __pyx_t_1 = (__pyx_v_error == Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":149
 * 
 *         if error is None:
 *             self.error_type = TokenSyntaxError             # <<<<<<<<<<<<<<
 *         else:
 *             if not issubclass(error, TokenSyntaxError):
 */
    __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError);
    __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError);
    __Pyx_GOTREF(__pyx_v_self->error_type);
    __Pyx_DECREF(__pyx_v_self->error_type);
    __pyx_v_self->error_type = __pyx_v_8srctools_10_tokenizer_TokenSyntaxError;

    /* "srctools/_tokenizer.pyx":148
 *                 self.filename = ''
 * 
 *         if error is None:             # <<<<<<<<<<<<<<
 *             self.error_type = TokenSyntaxError
 *         else:
 */
    goto __pyx_L17;
  }

  /* "srctools/_tokenizer.pyx":151
 *             self.error_type = TokenSyntaxError
 *         else:
 *             if not issubclass(error, TokenSyntaxError):             # <<<<<<<<<<<<<<
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"!')
 *             self.error_type = error
 */
  /*else*/ {
    __pyx_t_6 = __pyx_v_8srctools_10_tokenizer_TokenSyntaxError;
    __Pyx_INCREF(__pyx_t_6);
    __pyx_t_2 = PyObject_IsSubclass(__pyx_v_error, __pyx_t_6); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 151, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_1 = ((!(__pyx_t_2 != 0)) != 0);
    if (unlikely(__pyx_t_1)) {

      /* "srctools/_tokenizer.pyx":152
 *         else:
 *             if not issubclass(error, TokenSyntaxError):
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"!')             # <<<<<<<<<<<<<<
 *             self.error_type = error
 *         self.string_bracket = string_bracket
 */
      __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 152, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_11 = 0;
      __pyx_t_12 = 127;
      __Pyx_INCREF(__pyx_kp_u_Invalid_error_instance);
      __pyx_t_11 += 24;
      __Pyx_GIVEREF(__pyx_kp_u_Invalid_error_instance);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_kp_u_Invalid_error_instance);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)Py_TYPE(__pyx_v_error)), __pyx_n_s_name_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 152, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_5 = __Pyx_PyObject_FormatSimple(__pyx_t_4, __pyx_empty_unicode); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 152, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_12 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_5) > __pyx_t_12) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_5) : __pyx_t_12;
      __pyx_t_11 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_5);
      __Pyx_GIVEREF(__pyx_t_5);
      PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_5);
      __pyx_t_5 = 0;
      __Pyx_INCREF(__pyx_kp_u__3);
      __pyx_t_11 += 2;
      __Pyx_GIVEREF(__pyx_kp_u__3);
      PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_kp_u__3);
      __pyx_t_5 = __Pyx_PyUnicode_Join(__pyx_t_6, 3, __pyx_t_11, __pyx_t_12); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 152, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_builtin_TypeError, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 152, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_Raise(__pyx_t_6, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __PYX_ERR(0, 152, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":151
 *             self.error_type = TokenSyntaxError
 *         else:
 *             if not issubclass(error, TokenSyntaxError):             # <<<<<<<<<<<<<<
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"!')
 *             self.error_type = error
 */
    }

    /* "srctools/_tokenizer.pyx":153
 *             if not issubclass(error, TokenSyntaxError):
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"!')
 *             self.error_type = error             # <<<<<<<<<<<<<<
 *         self.string_bracket = string_bracket
 *         self.allow_escapes = allow_escapes
 */
    __Pyx_INCREF(__pyx_v_error);
    __Pyx_GIVEREF(__pyx_v_error);
    __Pyx_GOTREF(__pyx_v_self->error_type);
    __Pyx_DECREF(__pyx_v_self->error_type);
    __pyx_v_self->error_type = __pyx_v_error;
  }
  __pyx_L17:;

  /* "srctools/_tokenizer.pyx":154
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"!')
 *             self.error_type = error
 *         self.string_bracket = string_bracket             # <<<<<<<<<<<<<<
 *         self.allow_escapes = allow_escapes
 *         self.allow_star_comments = allow_star_comments
 */
  __pyx_v_self->string_bracket = __pyx_v_string_bracket;

  /* "srctools/_tokenizer.pyx":155
 *             self.error_type = error
 *         self.string_bracket = string_bracket
 *         self.allow_escapes = allow_escapes             # <<<<<<<<<<<<<<
 *         self.allow_star_comments = allow_star_comments
 * 
 */
  __pyx_v_self->allow_escapes = __pyx_v_allow_escapes;

  /* "srctools/_tokenizer.pyx":156
 *         self.string_bracket = string_bracket
 *         self.allow_escapes = allow_escapes
 *         self.allow_star_comments = allow_star_comments             # <<<<<<<<<<<<<<
 * 
 *         self.pushback_tok = self.pushback_val = None
 */
  __pyx_v_self->allow_star_comments = __pyx_v_allow_star_comments;

  /* "srctools/_tokenizer.pyx":158
 *         self.allow_star_comments = allow_star_comments
 * 
 *         self.pushback_tok = self.pushback_val = None             # <<<<<<<<<<<<<<
 * 
 *         self.line_num = 1
 */
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->pushback_tok);
  __Pyx_DECREF(__pyx_v_self->pushback_tok);
  __pyx_v_self->pushback_tok = Py_None;
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->pushback_val);
  __Pyx_DECREF(__pyx_v_self->pushback_val);
  __pyx_v_self->pushback_val = Py_None;

  /* "srctools/_tokenizer.pyx":160
 *         self.pushback_tok = self.pushback_val = None
 * 
 *         self.line_num = 1             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
  __pyx_v_self->line_num = 1;

  /* "srctools/_tokenizer.pyx":103
 *         PyMem_Free(self.val_buffer)
 * 
 *     def __init__(             # <<<<<<<<<<<<<<
 *         self,
 *         data not None,
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":162
 *         self.line_num = 1
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """Disallow pickling Tokenizers.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_7__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_9Tokenizer_6__reduce__[] = "Tokenizer.__reduce__(self)\nDisallow pickling Tokenizers.\n\n        The files themselves usually are not pickleable, or are very\n        large strings.\n        There is also the issue with recreating the C/Python versions.\n        ";
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_7__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_6__reduce__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_6__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "srctools/_tokenizer.pyx":169
 *         There is also the issue with recreating the C/Python versions.
 *         """
 *         raise NotImplementedError('Cannot pickle Tokenizers!')             # <<<<<<<<<<<<<<
 * 
 *     def error(self, message, *args):
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_NotImplementedError, __pyx_tuple__4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 169, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 169, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":162
 *         self.line_num = 1
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """Disallow pickling Tokenizers.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":171
 *         raise NotImplementedError('Cannot pickle Tokenizers!')
 * 
 *     def error(self, message, *args):             # <<<<<<<<<<<<<<
 *         """Raise a syntax error exception.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_9error(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_9Tokenizer_8error[] = "Tokenizer.error(self, message, *args)\nRaise a syntax error exception.\n\n        This returns the TokenSyntaxError instance, with\n        line number and filename attributes filled in.\n        The message can be a Token to indicate a wrong token,\n        or a string which will be formatted with the positional args.\n        ";
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_9error(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_message = 0;
  PyObject *__pyx_v_args = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("error (wrapper)", 0);
  if (PyTuple_GET_SIZE(__pyx_args) > 1) {
    __pyx_v_args = PyTuple_GetSlice(__pyx_args, 1, PyTuple_GET_SIZE(__pyx_args));
    if (unlikely(!__pyx_v_args)) {
      __Pyx_RefNannyFinishContext();
      return NULL;
    }
    __Pyx_GOTREF(__pyx_v_args);
  } else {
    __pyx_v_args = __pyx_empty_tuple; __Pyx_INCREF(__pyx_empty_tuple);
  }
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_message,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        default:
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_message)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t used_pos_args = (pos_args < 1) ? pos_args : 1;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, used_pos_args, "error") < 0)) __PYX_ERR(0, 171, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) < 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_message = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("error", 0, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 171, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_args); __pyx_v_args = 0;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.error", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8error(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_message, __pyx_v_args);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_8error(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_message, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  Py_UCS4 __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("error", 0);
  __Pyx_INCREF(__pyx_v_message);

  /* "srctools/_tokenizer.pyx":179
 *         or a string which will be formatted with the positional args.
 *         """
 *         if isinstance(message, Token):             # <<<<<<<<<<<<<<
 *             message = f'Unexpected token {message.name}!'
 *         else:
 */
  __pyx_t_1 = __pyx_v_8srctools_10_tokenizer_Token;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = PyObject_IsInstance(__pyx_v_message, __pyx_t_1); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 179, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "srctools/_tokenizer.pyx":180
 *         """
 *         if isinstance(message, Token):
 *             message = f'Unexpected token {message.name}!'             # <<<<<<<<<<<<<<
 *         else:
 *             message = message.format(*args)
 */
    __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 180, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = 0;
    __pyx_t_5 = 127;
    __Pyx_INCREF(__pyx_kp_u_Unexpected_token);
    __pyx_t_4 += 17;
    __Pyx_GIVEREF(__pyx_kp_u_Unexpected_token);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_kp_u_Unexpected_token);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_message, __pyx_n_s_name); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 180, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_PyObject_FormatSimple(__pyx_t_6, __pyx_empty_unicode); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 180, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
    __Pyx_GIVEREF(__pyx_t_7);
    PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_7);
    __pyx_t_7 = 0;
    __Pyx_INCREF(__pyx_kp_u__5);
    __pyx_t_4 += 1;
    __Pyx_GIVEREF(__pyx_kp_u__5);
    PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_kp_u__5);
    __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_1, 3, __pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 180, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF_SET(__pyx_v_message, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "srctools/_tokenizer.pyx":179
 *         or a string which will be formatted with the positional args.
 *         """
 *         if isinstance(message, Token):             # <<<<<<<<<<<<<<
 *             message = f'Unexpected token {message.name}!'
 *         else:
 */
    goto __pyx_L3;
  }

  /* "srctools/_tokenizer.pyx":182
 *             message = f'Unexpected token {message.name}!'
 *         else:
 *             message = message.format(*args)             # <<<<<<<<<<<<<<
 *         return self._error(message)
 * 
 */
  /*else*/ {
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_message, __pyx_n_s_format); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 182, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_v_args, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 182, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF_SET(__pyx_v_message, __pyx_t_1);
    __pyx_t_1 = 0;
  }
  __pyx_L3:;

  /* "srctools/_tokenizer.pyx":183
 *         else:
 *             message = message.format(*args)
 *         return self._error(message)             # <<<<<<<<<<<<<<
 * 
 *     cdef inline _error(self, str message):
 */
  __Pyx_XDECREF(__pyx_r);
  if (!(likely(PyUnicode_CheckExact(__pyx_v_message))||((__pyx_v_message) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_v_message)->tp_name), 0))) __PYX_ERR(0, 183, __pyx_L1_error)
  __pyx_t_1 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, ((PyObject*)__pyx_v_message)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 183, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":171
 *         raise NotImplementedError('Cannot pickle Tokenizers!')
 * 
 *     def error(self, message, *args):             # <<<<<<<<<<<<<<
 *         """Raise a syntax error exception.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.error", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_message);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":185
 *         return self._error(message)
 * 
 *     cdef inline _error(self, str message):             # <<<<<<<<<<<<<<
 *         """C-private self.error()."""
 *         return self.error_type(
 */

static CYTHON_INLINE PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer__error(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_message) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("_error", 0);

  /* "srctools/_tokenizer.pyx":187
 *     cdef inline _error(self, str message):
 *         """C-private self.error()."""
 *         return self.error_type(             # <<<<<<<<<<<<<<
 *             message,
 *             self.filename,
 */
  __Pyx_XDECREF(__pyx_r);

  /* "srctools/_tokenizer.pyx":190
 *             message,
 *             self.filename,
 *             self.line_num,             # <<<<<<<<<<<<<<
 *         )
 * 
 */
  __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_self->line_num); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 190, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_self->error_type);
  __pyx_t_3 = __pyx_v_self->error_type; __pyx_t_4 = NULL;
  __pyx_t_5 = 0;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_5 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_4, __pyx_v_message, __pyx_v_self->filename, __pyx_t_2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_5, 3+__pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 187, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_4, __pyx_v_message, __pyx_v_self->filename, __pyx_t_2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_5, 3+__pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 187, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(3+__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 187, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_message);
    __Pyx_GIVEREF(__pyx_v_message);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_5, __pyx_v_message);
    __Pyx_INCREF(__pyx_v_self->filename);
    __Pyx_GIVEREF(__pyx_v_self->filename);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_5, __pyx_v_self->filename);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_6, 2+__pyx_t_5, __pyx_t_2);
    __pyx_t_2 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 187, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":185
 *         return self._error(message)
 * 
 *     cdef inline _error(self, str message):             # <<<<<<<<<<<<<<
 *         """C-private self.error()."""
 *         return self.error_type(
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer._error", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":193
 *         )
 * 
 *     cdef inline void buf_reset(self):             # <<<<<<<<<<<<<<
 *         """Reset the temporary buffer."""
 *         self.buf_pos = 0
 */

static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("buf_reset", 0);

  /* "srctools/_tokenizer.pyx":195
 *     cdef inline void buf_reset(self):
 *         """Reset the temporary buffer."""
 *         self.buf_pos = 0             # <<<<<<<<<<<<<<
 * 
 *     cdef inline void buf_add_char(self, Py_UCS4 uchar):
 */
  __pyx_v_self->buf_pos = 0;

  /* "srctools/_tokenizer.pyx":193
 *         )
 * 
 *     cdef inline void buf_reset(self):             # <<<<<<<<<<<<<<
 *         """Reset the temporary buffer."""
 *         self.buf_pos = 0
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "srctools/_tokenizer.pyx":197
 *         self.buf_pos = 0
 * 
 *     cdef inline void buf_add_char(self, Py_UCS4 uchar):             # <<<<<<<<<<<<<<
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         if self.buf_pos >= self.buf_size:
 */

static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, Py_UCS4 __pyx_v_uchar) {
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("buf_add_char", 0);

  /* "srctools/_tokenizer.pyx":199
 *     cdef inline void buf_add_char(self, Py_UCS4 uchar):
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         if self.buf_pos >= self.buf_size:             # <<<<<<<<<<<<<<
 *             self.buf_size *= 2
 *             self.val_buffer = <Py_UCS4 *>PyMem_Realloc(
 */
  __pyx_t_1 = ((__pyx_v_self->buf_pos >= __pyx_v_self->buf_size) != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":200
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         if self.buf_pos >= self.buf_size:
 *             self.buf_size *= 2             # <<<<<<<<<<<<<<
 *             self.val_buffer = <Py_UCS4 *>PyMem_Realloc(
 *                 self.val_buffer,
 */
    __pyx_v_self->buf_size = (__pyx_v_self->buf_size * 2);

    /* "srctools/_tokenizer.pyx":201
 *         if self.buf_pos >= self.buf_size:
 *             self.buf_size *= 2
 *             self.val_buffer = <Py_UCS4 *>PyMem_Realloc(             # <<<<<<<<<<<<<<
 *                 self.val_buffer,
 *                 self.buf_size * sizeof(Py_UCS4),
 */
    __pyx_v_self->val_buffer = ((Py_UCS4 *)PyMem_Realloc(__pyx_v_self->val_buffer, (__pyx_v_self->buf_size * (sizeof(Py_UCS4)))));

    /* "srctools/_tokenizer.pyx":199
 *     cdef inline void buf_add_char(self, Py_UCS4 uchar):
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         if self.buf_pos >= self.buf_size:             # <<<<<<<<<<<<<<
 *             self.buf_size *= 2
 *             self.val_buffer = <Py_UCS4 *>PyMem_Realloc(
 */
  }

  /* "srctools/_tokenizer.pyx":205
 *                 self.buf_size * sizeof(Py_UCS4),
 *             )
 *         self.val_buffer[self.buf_pos] = uchar             # <<<<<<<<<<<<<<
 *         self.buf_pos += 1
 * 
 */
  (__pyx_v_self->val_buffer[__pyx_v_self->buf_pos]) = __pyx_v_uchar;

  /* "srctools/_tokenizer.pyx":206
 *             )
 *         self.val_buffer[self.buf_pos] = uchar
 *         self.buf_pos += 1             # <<<<<<<<<<<<<<
 * 
 *     cdef object buf_get_text(self):
 */
  __pyx_v_self->buf_pos = (__pyx_v_self->buf_pos + 1);

  /* "srctools/_tokenizer.pyx":197
 *         self.buf_pos = 0
 * 
 *     cdef inline void buf_add_char(self, Py_UCS4 uchar):             # <<<<<<<<<<<<<<
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         if self.buf_pos >= self.buf_size:
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "srctools/_tokenizer.pyx":208
 *         self.buf_pos += 1
 * 
 *     cdef object buf_get_text(self):             # <<<<<<<<<<<<<<
 *         """Decode the buffer, and return the text."""
 *         cdef int byteorder = 0  # Native order.
 */

static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  CYTHON_UNUSED int __pyx_v_byteorder;
  PyObject *__pyx_v_out = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("buf_get_text", 0);

  /* "srctools/_tokenizer.pyx":210
 *     cdef object buf_get_text(self):
 *         """Decode the buffer, and return the text."""
 *         cdef int byteorder = 0  # Native order.             # <<<<<<<<<<<<<<
 *         # Decode buffer with default ("errors") error handling, native order.
 *         out = PyUnicode_FromKindAndData(4, self.val_buffer, self.buf_pos)
 */
  __pyx_v_byteorder = 0;

  /* "srctools/_tokenizer.pyx":212
 *         cdef int byteorder = 0  # Native order.
 *         # Decode buffer with default ("errors") error handling, native order.
 *         out = PyUnicode_FromKindAndData(4, self.val_buffer, self.buf_pos)             # <<<<<<<<<<<<<<
 *         self.buf_pos = 0
 *         return out
 */
  __pyx_t_1 = PyUnicode_FromKindAndData(4, __pyx_v_self->val_buffer, __pyx_v_self->buf_pos); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 212, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_out = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":213
 *         # Decode buffer with default ("errors") error handling, native order.
 *         out = PyUnicode_FromKindAndData(4, self.val_buffer, self.buf_pos)
 *         self.buf_pos = 0             # <<<<<<<<<<<<<<
 *         return out
 * 
 */
  __pyx_v_self->buf_pos = 0;

  /* "srctools/_tokenizer.pyx":214
 *         out = PyUnicode_FromKindAndData(4, self.val_buffer, self.buf_pos)
 *         self.buf_pos = 0
 *         return out             # <<<<<<<<<<<<<<
 * 
 *     # We check all the getitem[] accesses, so don't have Cython recheck.
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_out);
  __pyx_r = __pyx_v_out;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":208
 *         self.buf_pos += 1
 * 
 *     cdef object buf_get_text(self):             # <<<<<<<<<<<<<<
 *         """Decode the buffer, and return the text."""
 *         cdef int byteorder = 0  # Native order.
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.buf_get_text", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_out);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":219
 *     @cython.boundscheck(False)
 *     @cython.wraparound(False)
 *     cdef Py_UCS4 _next_char(self) except -2:             # <<<<<<<<<<<<<<
 *         """Return the next character, or -1 if no more characters are there."""
 *         cdef str chunk
 */

static Py_UCS4 __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_v_chunk = 0;
  PyObject *__pyx_v_chunk_obj = 0;
  Py_UCS4 __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  int __pyx_t_3;
  Py_UCS4 __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  PyObject *(*__pyx_t_7)(PyObject *);
  Py_ssize_t __pyx_t_8;
  __Pyx_RefNannySetupContext("_next_char", 0);

  /* "srctools/_tokenizer.pyx":224
 *         cdef object chunk_obj
 * 
 *         self.char_index += 1             # <<<<<<<<<<<<<<
 *         if self.char_index < len(self.cur_chunk):
 *             return self.cur_chunk[self.char_index]
 */
  __pyx_v_self->char_index = (__pyx_v_self->char_index + 1);

  /* "srctools/_tokenizer.pyx":225
 * 
 *         self.char_index += 1
 *         if self.char_index < len(self.cur_chunk):             # <<<<<<<<<<<<<<
 *             return self.cur_chunk[self.char_index]
 * 
 */
  __pyx_t_1 = __pyx_v_self->cur_chunk;
  __Pyx_INCREF(__pyx_t_1);
  if (unlikely(__pyx_t_1 == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 225, __pyx_L1_error)
  }
  __pyx_t_2 = __Pyx_PyUnicode_GET_LENGTH(__pyx_t_1); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 225, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = ((__pyx_v_self->char_index < __pyx_t_2) != 0);
  if (__pyx_t_3) {

    /* "srctools/_tokenizer.pyx":226
 *         self.char_index += 1
 *         if self.char_index < len(self.cur_chunk):
 *             return self.cur_chunk[self.char_index]             # <<<<<<<<<<<<<<
 * 
 *         # Retrieve a chunk from the iterable.
 */
    __pyx_t_4 = __Pyx_GetItemInt_Unicode(__pyx_v_self->cur_chunk, __pyx_v_self->char_index, int, 1, __Pyx_PyInt_From_int, 0, 0, 0); if (unlikely(__pyx_t_4 == (Py_UCS4)-1)) __PYX_ERR(0, 226, __pyx_L1_error)
    __pyx_r = __pyx_t_4;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":225
 * 
 *         self.char_index += 1
 *         if self.char_index < len(self.cur_chunk):             # <<<<<<<<<<<<<<
 *             return self.cur_chunk[self.char_index]
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":229
 * 
 *         # Retrieve a chunk from the iterable.
 *         chunk_obj = next(self.chunk_iter, None)             # <<<<<<<<<<<<<<
 *         if chunk_obj is None:
 *             return -1
 */
  __pyx_t_1 = __pyx_v_self->chunk_iter;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyIter_Next2(__pyx_t_1, Py_None); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 229, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_chunk_obj = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "srctools/_tokenizer.pyx":230
 *         # Retrieve a chunk from the iterable.
 *         chunk_obj = next(self.chunk_iter, None)
 *         if chunk_obj is None:             # <<<<<<<<<<<<<<
 *             return -1
 * 
 */
  __pyx_t_3 = (__pyx_v_chunk_obj == Py_None);
  __pyx_t_6 = (__pyx_t_3 != 0);
  if (__pyx_t_6) {

    /* "srctools/_tokenizer.pyx":231
 *         chunk_obj = next(self.chunk_iter, None)
 *         if chunk_obj is None:
 *             return -1             # <<<<<<<<<<<<<<
 * 
 *         if isinstance(chunk_obj, bytes):
 */
    __pyx_r = -1;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":230
 *         # Retrieve a chunk from the iterable.
 *         chunk_obj = next(self.chunk_iter, None)
 *         if chunk_obj is None:             # <<<<<<<<<<<<<<
 *             return -1
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":233
 *             return -1
 * 
 *         if isinstance(chunk_obj, bytes):             # <<<<<<<<<<<<<<
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):
 */
  __pyx_t_6 = PyBytes_Check(__pyx_v_chunk_obj); 
  __pyx_t_3 = (__pyx_t_6 != 0);
  if (unlikely(__pyx_t_3)) {

    /* "srctools/_tokenizer.pyx":234
 * 
 *         if isinstance(chunk_obj, bytes):
 *             raise ValueError('Cannot parse binary data!')             # <<<<<<<<<<<<<<
 *         if not isinstance(chunk_obj, str):
 *             raise ValueError("Data was not a string!")
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 234, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(0, 234, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":233
 *             return -1
 * 
 *         if isinstance(chunk_obj, bytes):             # <<<<<<<<<<<<<<
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):
 */
  }

  /* "srctools/_tokenizer.pyx":235
 *         if isinstance(chunk_obj, bytes):
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):             # <<<<<<<<<<<<<<
 *             raise ValueError("Data was not a string!")
 * 
 */
  __pyx_t_3 = PyUnicode_Check(__pyx_v_chunk_obj); 
  __pyx_t_6 = ((!(__pyx_t_3 != 0)) != 0);
  if (unlikely(__pyx_t_6)) {

    /* "srctools/_tokenizer.pyx":236
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):
 *             raise ValueError("Data was not a string!")             # <<<<<<<<<<<<<<
 * 
 *         self.cur_chunk = chunk = <str>chunk_obj
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__7, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 236, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(0, 236, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":235
 *         if isinstance(chunk_obj, bytes):
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):             # <<<<<<<<<<<<<<
 *             raise ValueError("Data was not a string!")
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":238
 *             raise ValueError("Data was not a string!")
 * 
 *         self.cur_chunk = chunk = <str>chunk_obj             # <<<<<<<<<<<<<<
 *         self.char_index = 0
 * 
 */
  __pyx_t_5 = __pyx_v_chunk_obj;
  __Pyx_INCREF(__pyx_t_5);
  __Pyx_INCREF(__pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_5);
  __Pyx_GOTREF(__pyx_v_self->cur_chunk);
  __Pyx_DECREF(__pyx_v_self->cur_chunk);
  __pyx_v_self->cur_chunk = ((PyObject*)__pyx_t_5);
  __Pyx_INCREF(__pyx_t_5);
  __pyx_v_chunk = ((PyObject*)__pyx_t_5);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "srctools/_tokenizer.pyx":239
 * 
 *         self.cur_chunk = chunk = <str>chunk_obj
 *         self.char_index = 0             # <<<<<<<<<<<<<<
 * 
 *         if len(chunk) > 0:
 */
  __pyx_v_self->char_index = 0;

  /* "srctools/_tokenizer.pyx":241
 *         self.char_index = 0
 * 
 *         if len(chunk) > 0:             # <<<<<<<<<<<<<<
 *             return (<str>chunk)[0]
 * 
 */
  if (unlikely(__pyx_v_chunk == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 241, __pyx_L1_error)
  }
  __pyx_t_2 = __Pyx_PyUnicode_GET_LENGTH(__pyx_v_chunk); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 241, __pyx_L1_error)
  __pyx_t_6 = ((__pyx_t_2 > 0) != 0);
  if (__pyx_t_6) {

    /* "srctools/_tokenizer.pyx":242
 * 
 *         if len(chunk) > 0:
 *             return (<str>chunk)[0]             # <<<<<<<<<<<<<<
 * 
 *         # Skip empty chunks (shouldn't be there.)
 */
    __pyx_t_4 = __Pyx_GetItemInt_Unicode(__pyx_v_chunk, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(__pyx_t_4 == (Py_UCS4)-1)) __PYX_ERR(0, 242, __pyx_L1_error)
    __pyx_r = __pyx_t_4;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":241
 *         self.char_index = 0
 * 
 *         if len(chunk) > 0:             # <<<<<<<<<<<<<<
 *             return (<str>chunk)[0]
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":245
 * 
 *         # Skip empty chunks (shouldn't be there.)
 *         for chunk_obj in self.chunk_iter:             # <<<<<<<<<<<<<<
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')
 */
  if (likely(PyList_CheckExact(__pyx_v_self->chunk_iter)) || PyTuple_CheckExact(__pyx_v_self->chunk_iter)) {
    __pyx_t_5 = __pyx_v_self->chunk_iter; __Pyx_INCREF(__pyx_t_5); __pyx_t_2 = 0;
    __pyx_t_7 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_v_self->chunk_iter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 245, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 245, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_7)) {
      if (likely(PyList_CheckExact(__pyx_t_5))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_2); __Pyx_INCREF(__pyx_t_1); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 245, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_5, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 245, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_2); __Pyx_INCREF(__pyx_t_1); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 245, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_5, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 245, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_7(__pyx_t_5);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 245, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_DECREF_SET(__pyx_v_chunk_obj, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "srctools/_tokenizer.pyx":246
 *         # Skip empty chunks (shouldn't be there.)
 *         for chunk_obj in self.chunk_iter:
 *             if isinstance(chunk_obj, bytes):             # <<<<<<<<<<<<<<
 *                 raise ValueError('Cannot parse binary data!')
 *             if not isinstance(chunk_obj, str):
 */
    __pyx_t_6 = PyBytes_Check(__pyx_v_chunk_obj); 
    __pyx_t_3 = (__pyx_t_6 != 0);
    if (unlikely(__pyx_t_3)) {

      /* "srctools/_tokenizer.pyx":247
 *         for chunk_obj in self.chunk_iter:
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')             # <<<<<<<<<<<<<<
 *             if not isinstance(chunk_obj, str):
 *                 raise ValueError("Data was not a string!")
 */
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 247, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_Raise(__pyx_t_1, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(0, 247, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":246
 *         # Skip empty chunks (shouldn't be there.)
 *         for chunk_obj in self.chunk_iter:
 *             if isinstance(chunk_obj, bytes):             # <<<<<<<<<<<<<<
 *                 raise ValueError('Cannot parse binary data!')
 *             if not isinstance(chunk_obj, str):
 */
    }

    /* "srctools/_tokenizer.pyx":248
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')
 *             if not isinstance(chunk_obj, str):             # <<<<<<<<<<<<<<
 *                 raise ValueError("Data was not a string!")
 * 
 */
    __pyx_t_3 = PyUnicode_Check(__pyx_v_chunk_obj); 
    __pyx_t_6 = ((!(__pyx_t_3 != 0)) != 0);
    if (unlikely(__pyx_t_6)) {

      /* "srctools/_tokenizer.pyx":249
 *                 raise ValueError('Cannot parse binary data!')
 *             if not isinstance(chunk_obj, str):
 *                 raise ValueError("Data was not a string!")             # <<<<<<<<<<<<<<
 * 
 *             chunk = <str>chunk_obj
 */
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 249, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_Raise(__pyx_t_1, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(0, 249, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":248
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')
 *             if not isinstance(chunk_obj, str):             # <<<<<<<<<<<<<<
 *                 raise ValueError("Data was not a string!")
 * 
 */
    }

    /* "srctools/_tokenizer.pyx":251
 *                 raise ValueError("Data was not a string!")
 * 
 *             chunk = <str>chunk_obj             # <<<<<<<<<<<<<<
 * 
 *             if len(chunk) > 0:
 */
    __pyx_t_1 = __pyx_v_chunk_obj;
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_DECREF_SET(__pyx_v_chunk, ((PyObject*)__pyx_t_1));
    __pyx_t_1 = 0;

    /* "srctools/_tokenizer.pyx":253
 *             chunk = <str>chunk_obj
 * 
 *             if len(chunk) > 0:             # <<<<<<<<<<<<<<
 *                 self.cur_chunk = chunk
 *                 return (<str>chunk)[0]
 */
    if (unlikely(__pyx_v_chunk == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
      __PYX_ERR(0, 253, __pyx_L1_error)
    }
    __pyx_t_8 = __Pyx_PyUnicode_GET_LENGTH(__pyx_v_chunk); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 253, __pyx_L1_error)
    __pyx_t_6 = ((__pyx_t_8 > 0) != 0);
    if (__pyx_t_6) {

      /* "srctools/_tokenizer.pyx":254
 * 
 *             if len(chunk) > 0:
 *                 self.cur_chunk = chunk             # <<<<<<<<<<<<<<
 *                 return (<str>chunk)[0]
 *         # Out of characters after empty chunks
 */
      __Pyx_INCREF(__pyx_v_chunk);
      __Pyx_GIVEREF(__pyx_v_chunk);
      __Pyx_GOTREF(__pyx_v_self->cur_chunk);
      __Pyx_DECREF(__pyx_v_self->cur_chunk);
      __pyx_v_self->cur_chunk = __pyx_v_chunk;

      /* "srctools/_tokenizer.pyx":255
 *             if len(chunk) > 0:
 *                 self.cur_chunk = chunk
 *                 return (<str>chunk)[0]             # <<<<<<<<<<<<<<
 *         # Out of characters after empty chunks
 *         return -1
 */
      __pyx_t_4 = __Pyx_GetItemInt_Unicode(__pyx_v_chunk, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(__pyx_t_4 == (Py_UCS4)-1)) __PYX_ERR(0, 255, __pyx_L1_error)
      __pyx_r = __pyx_t_4;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":253
 *             chunk = <str>chunk_obj
 * 
 *             if len(chunk) > 0:             # <<<<<<<<<<<<<<
 *                 self.cur_chunk = chunk
 *                 return (<str>chunk)[0]
 */
    }

    /* "srctools/_tokenizer.pyx":245
 * 
 *         # Skip empty chunks (shouldn't be there.)
 *         for chunk_obj in self.chunk_iter:             # <<<<<<<<<<<<<<
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')
 */
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "srctools/_tokenizer.pyx":257
 *                 return (<str>chunk)[0]
 *         # Out of characters after empty chunks
 *         return -1             # <<<<<<<<<<<<<<
 * 
 *     def __call__(self):
 */
  __pyx_r = -1;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":219
 *     @cython.boundscheck(False)
 *     @cython.wraparound(False)
 *     cdef Py_UCS4 _next_char(self) except -2:             # <<<<<<<<<<<<<<
 *         """Return the next character, or -1 if no more characters are there."""
 *         cdef str chunk
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer._next_char", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -2;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_chunk);
  __Pyx_XDECREF(__pyx_v_chunk_obj);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":259
 *         return -1
 * 
 *     def __call__(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair."""
 *         return self.next_token()
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_11__call__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_9Tokenizer_10__call__[] = "Return the next token, value pair.";
#if CYTHON_COMPILING_IN_CPYTHON
struct wrapperbase __pyx_wrapperbase_8srctools_10_tokenizer_9Tokenizer_10__call__;
#endif
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_11__call__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__call__ (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("__call__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return NULL;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__call__", 0))) return NULL;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_10__call__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_10__call__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__call__", 0);

  /* "srctools/_tokenizer.pyx":261
 *     def __call__(self):
 *         """Return the next token, value pair."""
 *         return self.next_token()             # <<<<<<<<<<<<<<
 * 
 *     cdef next_token(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 261, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":259
 *         return -1
 * 
 *     def __call__(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair."""
 *         return self.next_token()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__call__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":263
 *         return self.next_token()
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair - this is the C version."""
 *         cdef:
 */

static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  Py_UCS4 __pyx_v_next_char;
  Py_UCS4 __pyx_v_escape_char;
  Py_UCS4 __pyx_v_peek_char;
  int __pyx_v_start_line;
  PyObject *__pyx_v_output = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  Py_UCS4 __pyx_t_4;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("next_token", 0);

  /* "srctools/_tokenizer.pyx":271
 *             int start_line
 * 
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 */
  __pyx_t_1 = (__pyx_v_self->pushback_tok != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":272
 * 
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val             # <<<<<<<<<<<<<<
 *             self.pushback_tok = self.pushback_val = None
 *             return output
 */
    __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 272, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_self->pushback_tok);
    __Pyx_GIVEREF(__pyx_v_self->pushback_tok);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_self->pushback_tok);
    __Pyx_INCREF(__pyx_v_self->pushback_val);
    __Pyx_GIVEREF(__pyx_v_self->pushback_val);
    PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_v_self->pushback_val);
    __pyx_v_output = ((PyObject*)__pyx_t_3);
    __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":273
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None             # <<<<<<<<<<<<<<
 *             return output
 * 
 */
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->pushback_tok);
    __Pyx_DECREF(__pyx_v_self->pushback_tok);
    __pyx_v_self->pushback_tok = Py_None;
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->pushback_val);
    __Pyx_DECREF(__pyx_v_self->pushback_val);
    __pyx_v_self->pushback_val = Py_None;

    /* "srctools/_tokenizer.pyx":274
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 *             return output             # <<<<<<<<<<<<<<
 * 
 *         while True:
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_output);
    __pyx_r = __pyx_v_output;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":271
 *             int start_line
 * 
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 */
  }

  /* "srctools/_tokenizer.pyx":276
 *             return output
 * 
 *         while True:             # <<<<<<<<<<<<<<
 *             next_char = self._next_char()
 *             if next_char == -1:
 */
  while (1) {

    /* "srctools/_tokenizer.pyx":277
 * 
 *         while True:
 *             next_char = self._next_char()             # <<<<<<<<<<<<<<
 *             if next_char == -1:
 *                 return EOF_TUP
 */
    __pyx_t_4 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 277, __pyx_L1_error)
    __pyx_v_next_char = __pyx_t_4;

    /* "srctools/_tokenizer.pyx":278
 *         while True:
 *             next_char = self._next_char()
 *             if next_char == -1:             # <<<<<<<<<<<<<<
 *                 return EOF_TUP
 * 
 */
    switch (__pyx_v_next_char) {
      case -1L:

      /* "srctools/_tokenizer.pyx":279
 *             next_char = self._next_char()
 *             if next_char == -1:
 *                 return EOF_TUP             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == '{':
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_EOF_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_EOF_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":278
 *         while True:
 *             next_char = self._next_char()
 *             if next_char == -1:             # <<<<<<<<<<<<<<
 *                 return EOF_TUP
 * 
 */
      break;
      case 0x7B:

      /* "srctools/_tokenizer.pyx":282
 * 
 *             elif next_char == '{':
 *                 return BRACE_OPEN_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == '}':
 *                 return BRACE_CLOSE_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":281
 *                 return EOF_TUP
 * 
 *             elif next_char == '{':             # <<<<<<<<<<<<<<
 *                 return BRACE_OPEN_TUP
 *             elif next_char == '}':
 */
      break;
      case 0x7D:

      /* "srctools/_tokenizer.pyx":284
 *                 return BRACE_OPEN_TUP
 *             elif next_char == '}':
 *                 return BRACE_CLOSE_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == ':':
 *                 return COLON_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":283
 *             elif next_char == '{':
 *                 return BRACE_OPEN_TUP
 *             elif next_char == '}':             # <<<<<<<<<<<<<<
 *                 return BRACE_CLOSE_TUP
 *             elif next_char == ':':
 */
      break;
      case 58:

      /* "srctools/_tokenizer.pyx":286
 *                 return BRACE_CLOSE_TUP
 *             elif next_char == ':':
 *                 return COLON_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == '+':
 *                 return PLUS_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_COLON_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_COLON_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":285
 *             elif next_char == '}':
 *                 return BRACE_CLOSE_TUP
 *             elif next_char == ':':             # <<<<<<<<<<<<<<
 *                 return COLON_TUP
 *             elif next_char == '+':
 */
      break;
      case 43:

      /* "srctools/_tokenizer.pyx":288
 *                 return COLON_TUP
 *             elif next_char == '+':
 *                 return PLUS_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == '=':
 *                 return EQUALS_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_PLUS_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_PLUS_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":287
 *             elif next_char == ':':
 *                 return COLON_TUP
 *             elif next_char == '+':             # <<<<<<<<<<<<<<
 *                 return PLUS_TUP
 *             elif next_char == '=':
 */
      break;
      case 61:

      /* "srctools/_tokenizer.pyx":290
 *                 return PLUS_TUP
 *             elif next_char == '=':
 *                 return EQUALS_TUP             # <<<<<<<<<<<<<<
 *             # First try simple operators & EOF.
 * 
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_EQUALS_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_EQUALS_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":289
 *             elif next_char == '+':
 *                 return PLUS_TUP
 *             elif next_char == '=':             # <<<<<<<<<<<<<<
 *                 return EQUALS_TUP
 *             # First try simple operators & EOF.
 */
      break;
      case 10:

      /* "srctools/_tokenizer.pyx":294
 * 
 *             elif next_char == '\n':
 *                 self.line_num += 1             # <<<<<<<<<<<<<<
 *                 return NEWLINE_TUP
 * 
 */
      __pyx_v_self->line_num = (__pyx_v_self->line_num + 1);

      /* "srctools/_tokenizer.pyx":295
 *             elif next_char == '\n':
 *                 self.line_num += 1
 *                 return NEWLINE_TUP             # <<<<<<<<<<<<<<
 * 
 *             elif next_char in ' \t':
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_NEWLINE_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":293
 *             # First try simple operators & EOF.
 * 
 *             elif next_char == '\n':             # <<<<<<<<<<<<<<
 *                 self.line_num += 1
 *                 return NEWLINE_TUP
 */
      break;
      case 9:

      /* "srctools/_tokenizer.pyx":297
 *                 return NEWLINE_TUP
 * 
 *             elif next_char in ' \t':             # <<<<<<<<<<<<<<
 *                 # Ignore whitespace..
 *                 continue
 */
      case 32:

      /* "srctools/_tokenizer.pyx":299
 *             elif next_char in ' \t':
 *                 # Ignore whitespace..
 *                 continue             # <<<<<<<<<<<<<<
 * 
 *             # Comments
 */
      goto __pyx_L4_continue;

      /* "srctools/_tokenizer.pyx":297
 *                 return NEWLINE_TUP
 * 
 *             elif next_char in ' \t':             # <<<<<<<<<<<<<<
 *                 # Ignore whitespace..
 *                 continue
 */
      break;
      case 47:

      /* "srctools/_tokenizer.pyx":304
 *             elif next_char == '/':
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.allow_star_comments:
 */
      __pyx_t_4 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 304, __pyx_L1_error)
      __pyx_v_next_char = __pyx_t_4;

      /* "srctools/_tokenizer.pyx":305
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.             # <<<<<<<<<<<<<<
 *                     if self.allow_star_comments:
 *                         start_line = self.line_num
 */
      switch (__pyx_v_next_char) {
        case 42:

        /* "srctools/_tokenizer.pyx":306
 *                 next_char = self._next_char()
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.allow_star_comments:             # <<<<<<<<<<<<<<
 *                         start_line = self.line_num
 *                         while True:
 */
        __pyx_t_2 = (__pyx_v_self->allow_star_comments != 0);
        if (likely(__pyx_t_2)) {

          /* "srctools/_tokenizer.pyx":307
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.allow_star_comments:
 *                         start_line = self.line_num             # <<<<<<<<<<<<<<
 *                         while True:
 *                             next_char = self._next_char()
 */
          __pyx_t_5 = __pyx_v_self->line_num;
          __pyx_v_start_line = __pyx_t_5;

          /* "srctools/_tokenizer.pyx":308
 *                     if self.allow_star_comments:
 *                         start_line = self.line_num
 *                         while True:             # <<<<<<<<<<<<<<
 *                             next_char = self._next_char()
 *                             if next_char == -1:
 */
          while (1) {

            /* "srctools/_tokenizer.pyx":309
 *                         start_line = self.line_num
 *                         while True:
 *                             next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                             if next_char == -1:
 *                                 raise self._error(
 */
            __pyx_t_4 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 309, __pyx_L1_error)
            __pyx_v_next_char = __pyx_t_4;

            /* "srctools/_tokenizer.pyx":310
 *                         while True:
 *                             next_char = self._next_char()
 *                             if next_char == -1:             # <<<<<<<<<<<<<<
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
            switch (__pyx_v_next_char) {
              case -1L:

              /* "srctools/_tokenizer.pyx":312
 *                             if next_char == -1:
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                     f'(starting on line {start_line})!',
 *                                 )
 */
              __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 312, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_3);
              __pyx_t_6 = 0;
              __pyx_t_4 = 127;
              __Pyx_INCREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
              __pyx_t_6 += 38;
              __Pyx_GIVEREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
              PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Unclosed_comment_starting_on_lin);

              /* "srctools/_tokenizer.pyx":313
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                     f'(starting on line {start_line})!',             # <<<<<<<<<<<<<<
 *                                 )
 *                             elif next_char == '\n':
 */
              __pyx_t_7 = __Pyx_PyUnicode_From_int(__pyx_v_start_line, 0, ' ', 'd'); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 313, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_7);
              __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
              __Pyx_GIVEREF(__pyx_t_7);
              PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
              __pyx_t_7 = 0;
              __Pyx_INCREF(__pyx_kp_u__8);
              __pyx_t_6 += 2;
              __Pyx_GIVEREF(__pyx_kp_u__8);
              PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u__8);

              /* "srctools/_tokenizer.pyx":312
 *                             if next_char == -1:
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                     f'(starting on line {start_line})!',
 *                                 )
 */
              __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_3, 3, __pyx_t_6, __pyx_t_4); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 312, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_7);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

              /* "srctools/_tokenizer.pyx":311
 *                             next_char = self._next_char()
 *                             if next_char == -1:
 *                                 raise self._error(             # <<<<<<<<<<<<<<
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                     f'(starting on line {start_line})!',
 */
              __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, ((PyObject*)__pyx_t_7)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 311, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_3);
              __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
              __Pyx_Raise(__pyx_t_3, 0, 0, 0);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
              __PYX_ERR(0, 311, __pyx_L1_error)

              /* "srctools/_tokenizer.pyx":310
 *                         while True:
 *                             next_char = self._next_char()
 *                             if next_char == -1:             # <<<<<<<<<<<<<<
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
              break;
              case 10:

              /* "srctools/_tokenizer.pyx":316
 *                                 )
 *                             elif next_char == '\n':
 *                                 self.line_num += 1             # <<<<<<<<<<<<<<
 *                             elif next_char == '*':
 *                                 # Check next next character!
 */
              __pyx_v_self->line_num = (__pyx_v_self->line_num + 1);

              /* "srctools/_tokenizer.pyx":315
 *                                     f'(starting on line {start_line})!',
 *                                 )
 *                             elif next_char == '\n':             # <<<<<<<<<<<<<<
 *                                 self.line_num += 1
 *                             elif next_char == '*':
 */
              break;
              case 42:

              /* "srctools/_tokenizer.pyx":319
 *                             elif next_char == '*':
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()             # <<<<<<<<<<<<<<
 *                                 if peek_char == -1:
 *                                     raise self._error(
 */
              __pyx_t_4 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 319, __pyx_L1_error)
              __pyx_v_peek_char = __pyx_t_4;

              /* "srctools/_tokenizer.pyx":320
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()
 *                                 if peek_char == -1:             # <<<<<<<<<<<<<<
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
              switch (__pyx_v_peek_char) {
                case -1L:

                /* "srctools/_tokenizer.pyx":322
 *                                 if peek_char == -1:
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                         f'(starting on line {start_line})!',
 *                                     )
 */
                __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 322, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_3);
                __pyx_t_6 = 0;
                __pyx_t_4 = 127;
                __Pyx_INCREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
                __pyx_t_6 += 38;
                __Pyx_GIVEREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
                PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Unclosed_comment_starting_on_lin);

                /* "srctools/_tokenizer.pyx":323
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                         f'(starting on line {start_line})!',             # <<<<<<<<<<<<<<
 *                                     )
 *                                 elif peek_char == '/':
 */
                __pyx_t_7 = __Pyx_PyUnicode_From_int(__pyx_v_start_line, 0, ' ', 'd'); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 323, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_7);
                __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
                __Pyx_GIVEREF(__pyx_t_7);
                PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
                __pyx_t_7 = 0;
                __Pyx_INCREF(__pyx_kp_u__8);
                __pyx_t_6 += 2;
                __Pyx_GIVEREF(__pyx_kp_u__8);
                PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u__8);

                /* "srctools/_tokenizer.pyx":322
 *                                 if peek_char == -1:
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                         f'(starting on line {start_line})!',
 *                                     )
 */
                __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_3, 3, __pyx_t_6, __pyx_t_4); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 322, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_7);
                __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

                /* "srctools/_tokenizer.pyx":321
 *                                 peek_char = self._next_char()
 *                                 if peek_char == -1:
 *                                     raise self._error(             # <<<<<<<<<<<<<<
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                         f'(starting on line {start_line})!',
 */
                __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, ((PyObject*)__pyx_t_7)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 321, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_3);
                __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
                __Pyx_Raise(__pyx_t_3, 0, 0, 0);
                __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
                __PYX_ERR(0, 321, __pyx_L1_error)

                /* "srctools/_tokenizer.pyx":320
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()
 *                                 if peek_char == -1:             # <<<<<<<<<<<<<<
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
                break;
                case 47:

                /* "srctools/_tokenizer.pyx":326
 *                                     )
 *                                 elif peek_char == '/':
 *                                     break             # <<<<<<<<<<<<<<
 *                                 else:
 *                                     # We need to reparse this, to ensure
 */
                goto __pyx_L8_break;

                /* "srctools/_tokenizer.pyx":325
 *                                         f'(starting on line {start_line})!',
 *                                     )
 *                                 elif peek_char == '/':             # <<<<<<<<<<<<<<
 *                                     break
 *                                 else:
 */
                break;
                default:

                /* "srctools/_tokenizer.pyx":330
 *                                     # We need to reparse this, to ensure
 *                                     # "**[inserted by cython to avoid comment closer]/" parses correctly!
 *                                     self.char_index -= 1             # <<<<<<<<<<<<<<
 *                     else:
 *                         raise self._error(
 */
                __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);
                break;
              }

              /* "srctools/_tokenizer.pyx":317
 *                             elif next_char == '\n':
 *                                 self.line_num += 1
 *                             elif next_char == '*':             # <<<<<<<<<<<<<<
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()
 */
              break;
              default: break;
            }
          }
          __pyx_L8_break:;

          /* "srctools/_tokenizer.pyx":306
 *                 next_char = self._next_char()
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.allow_star_comments:             # <<<<<<<<<<<<<<
 *                         start_line = self.line_num
 *                         while True:
 */
          goto __pyx_L6;
        }

        /* "srctools/_tokenizer.pyx":332
 *                                     self.char_index -= 1
 *                     else:
 *                         raise self._error(             # <<<<<<<<<<<<<<
 *                             '/[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/-style comments are not allowed!'
 *                         )
 */
        /*else*/ {
          __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, __pyx_kp_u_style_comments_are_not_allowed); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 332, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_Raise(__pyx_t_3, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __PYX_ERR(0, 332, __pyx_L1_error)
        }
        __pyx_L6:;

        /* "srctools/_tokenizer.pyx":305
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.             # <<<<<<<<<<<<<<
 *                     if self.allow_star_comments:
 *                         start_line = self.line_num
 */
        break;
        case 47:

        /* "srctools/_tokenizer.pyx":337
 *                 elif next_char == '/':
 *                     # Skip to end of line
 *                     while True:             # <<<<<<<<<<<<<<
 *                         next_char = self._next_char()
 *                         if next_char == -1 or next_char == '\n':
 */
        while (1) {

          /* "srctools/_tokenizer.pyx":338
 *                     # Skip to end of line
 *                     while True:
 *                         next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                         if next_char == -1 or next_char == '\n':
 *                             break
 */
          __pyx_t_4 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 338, __pyx_L1_error)
          __pyx_v_next_char = __pyx_t_4;

          /* "srctools/_tokenizer.pyx":339
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == -1 or next_char == '\n':             # <<<<<<<<<<<<<<
 *                             break
 * 
 */
          switch (__pyx_v_next_char) {
            case -1L:
            case 10:

            /* "srctools/_tokenizer.pyx":340
 *                         next_char = self._next_char()
 *                         if next_char == -1 or next_char == '\n':
 *                             break             # <<<<<<<<<<<<<<
 * 
 *                     # We want to produce the token for the end character -
 */
            goto __pyx_L10_break;

            /* "srctools/_tokenizer.pyx":339
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == -1 or next_char == '\n':             # <<<<<<<<<<<<<<
 *                             break
 * 
 */
            break;
            default: break;
          }
        }
        __pyx_L10_break:;

        /* "srctools/_tokenizer.pyx":344
 *                     # We want to produce the token for the end character -
 *                     # EOF or NEWLINE.
 *                     self.char_index -= 1             # <<<<<<<<<<<<<<
 *                 else:
 *                     raise self._error(
 */
        __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);

        /* "srctools/_tokenizer.pyx":335
 *                             '/[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/-style comments are not allowed!'
 *                         )
 *                 elif next_char == '/':             # <<<<<<<<<<<<<<
 *                     # Skip to end of line
 *                     while True:
 */
        break;
        default:

        /* "srctools/_tokenizer.pyx":349
 *                         'Single slash found, '
 *                         'instead of two for a comment (// or /[inserted by cython to avoid comment start]* *[inserted by cython to avoid comment closer]/)!'
 *                         if self.allow_star_comments else             # <<<<<<<<<<<<<<
 *                         'Single slash found, '
 *                         'instead of two for a comment (//)!'
 */
        if ((__pyx_v_self->allow_star_comments != 0)) {
          __Pyx_INCREF(__pyx_kp_u_Single_slash_found_instead_of_tw);
          __pyx_t_3 = __pyx_kp_u_Single_slash_found_instead_of_tw;
        } else {
          __Pyx_INCREF(__pyx_kp_u_Single_slash_found_instead_of_tw_2);
          __pyx_t_3 = __pyx_kp_u_Single_slash_found_instead_of_tw_2;
        }

        /* "srctools/_tokenizer.pyx":346
 *                     self.char_index -= 1
 *                 else:
 *                     raise self._error(             # <<<<<<<<<<<<<<
 *                         'Single slash found, '
 *                         'instead of two for a comment (// or /[inserted by cython to avoid comment start]* *[inserted by cython to avoid comment closer]/)!'
 */
        __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, ((PyObject*)__pyx_t_3)); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 346, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_Raise(__pyx_t_7, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __PYX_ERR(0, 346, __pyx_L1_error)
        break;
      }

      /* "srctools/_tokenizer.pyx":302
 * 
 *             # Comments
 *             elif next_char == '/':             # <<<<<<<<<<<<<<
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()
 */
      break;
      case 34:

      /* "srctools/_tokenizer.pyx":356
 *             # Strings
 *             elif next_char == '"':
 *                 self.buf_reset()             # <<<<<<<<<<<<<<
 *                 while True:
 *                     next_char = self._next_char()
 */
      __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

      /* "srctools/_tokenizer.pyx":357
 *             elif next_char == '"':
 *                 self.buf_reset()
 *                 while True:             # <<<<<<<<<<<<<<
 *                     next_char = self._next_char()
 *                     if next_char == -1:
 */
      while (1) {

        /* "srctools/_tokenizer.pyx":358
 *                 self.buf_reset()
 *                 while True:
 *                     next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                     if next_char == -1:
 *                         raise self._error('Unterminated string!')
 */
        __pyx_t_4 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 358, __pyx_L1_error)
        __pyx_v_next_char = __pyx_t_4;

        /* "srctools/_tokenizer.pyx":359
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == '"':
 */
        __pyx_t_2 = ((__pyx_v_next_char == -1L) != 0);
        if (unlikely(__pyx_t_2)) {

          /* "srctools/_tokenizer.pyx":360
 *                     next_char = self._next_char()
 *                     if next_char == -1:
 *                         raise self._error('Unterminated string!')             # <<<<<<<<<<<<<<
 *                     elif next_char == '"':
 *                         return STRING, self.buf_get_text()
 */
          __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, __pyx_kp_u_Unterminated_string); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 360, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_Raise(__pyx_t_7, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          __PYX_ERR(0, 360, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":359
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == '"':
 */
        }

        /* "srctools/_tokenizer.pyx":361
 *                     if next_char == -1:
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == '"':             # <<<<<<<<<<<<<<
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == '\n':
 */
        __pyx_t_2 = ((__pyx_v_next_char == 34) != 0);
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":362
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == '"':
 *                         return STRING, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                     elif next_char == '\n':
 *                         self.line_num += 1
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 362, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 362, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_STRING);
          __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_STRING);
          PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_8srctools_10_tokenizer_STRING);
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_r = __pyx_t_3;
          __pyx_t_3 = 0;
          goto __pyx_L0;

          /* "srctools/_tokenizer.pyx":361
 *                     if next_char == -1:
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == '"':             # <<<<<<<<<<<<<<
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == '\n':
 */
        }

        /* "srctools/_tokenizer.pyx":363
 *                     elif next_char == '"':
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == '\n':             # <<<<<<<<<<<<<<
 *                         self.line_num += 1
 *                     elif next_char == '\\' and self.allow_escapes:
 */
        __pyx_t_2 = ((__pyx_v_next_char == 10) != 0);
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":364
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == '\n':
 *                         self.line_num += 1             # <<<<<<<<<<<<<<
 *                     elif next_char == '\\' and self.allow_escapes:
 *                         # Escape text
 */
          __pyx_v_self->line_num = (__pyx_v_self->line_num + 1);

          /* "srctools/_tokenizer.pyx":363
 *                     elif next_char == '"':
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == '\n':             # <<<<<<<<<<<<<<
 *                         self.line_num += 1
 *                     elif next_char == '\\' and self.allow_escapes:
 */
          goto __pyx_L13;
        }

        /* "srctools/_tokenizer.pyx":365
 *                     elif next_char == '\n':
 *                         self.line_num += 1
 *                     elif next_char == '\\' and self.allow_escapes:             # <<<<<<<<<<<<<<
 *                         # Escape text
 *                         escape_char = self._next_char()
 */
        __pyx_t_1 = ((__pyx_v_next_char == 92) != 0);
        if (__pyx_t_1) {
        } else {
          __pyx_t_2 = __pyx_t_1;
          goto __pyx_L14_bool_binop_done;
        }
        __pyx_t_1 = (__pyx_v_self->allow_escapes != 0);
        __pyx_t_2 = __pyx_t_1;
        __pyx_L14_bool_binop_done:;
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":367
 *                     elif next_char == '\\' and self.allow_escapes:
 *                         # Escape text
 *                         escape_char = self._next_char()             # <<<<<<<<<<<<<<
 *                         if escape_char == -1:
 *                             raise self._error('Unterminated string!')
 */
          __pyx_t_4 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 367, __pyx_L1_error)
          __pyx_v_escape_char = __pyx_t_4;

          /* "srctools/_tokenizer.pyx":368
 *                         # Escape text
 *                         escape_char = self._next_char()
 *                         if escape_char == -1:             # <<<<<<<<<<<<<<
 *                             raise self._error('Unterminated string!')
 * 
 */
          __pyx_t_2 = ((__pyx_v_escape_char == -1L) != 0);
          if (unlikely(__pyx_t_2)) {

            /* "srctools/_tokenizer.pyx":369
 *                         escape_char = self._next_char()
 *                         if escape_char == -1:
 *                             raise self._error('Unterminated string!')             # <<<<<<<<<<<<<<
 * 
 *                         if escape_char == 'n':
 */
            __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, __pyx_kp_u_Unterminated_string); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 369, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_Raise(__pyx_t_3, 0, 0, 0);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            __PYX_ERR(0, 369, __pyx_L1_error)

            /* "srctools/_tokenizer.pyx":368
 *                         # Escape text
 *                         escape_char = self._next_char()
 *                         if escape_char == -1:             # <<<<<<<<<<<<<<
 *                             raise self._error('Unterminated string!')
 * 
 */
          }

          /* "srctools/_tokenizer.pyx":371
 *                             raise self._error('Unterminated string!')
 * 
 *                         if escape_char == 'n':             # <<<<<<<<<<<<<<
 *                             next_char = '\n'
 *                         elif escape_char == 't':
 */
          switch (__pyx_v_escape_char) {
            case 0x6E:

            /* "srctools/_tokenizer.pyx":372
 * 
 *                         if escape_char == 'n':
 *                             next_char = '\n'             # <<<<<<<<<<<<<<
 *                         elif escape_char == 't':
 *                             next_char = '\t'
 */
            __pyx_v_next_char = 10;

            /* "srctools/_tokenizer.pyx":371
 *                             raise self._error('Unterminated string!')
 * 
 *                         if escape_char == 'n':             # <<<<<<<<<<<<<<
 *                             next_char = '\n'
 *                         elif escape_char == 't':
 */
            break;
            case 0x74:

            /* "srctools/_tokenizer.pyx":374
 *                             next_char = '\n'
 *                         elif escape_char == 't':
 *                             next_char = '\t'             # <<<<<<<<<<<<<<
 *                         elif escape_char == '\n':
 *                             # \ at end of line ignores the newline.
 */
            __pyx_v_next_char = 9;

            /* "srctools/_tokenizer.pyx":373
 *                         if escape_char == 'n':
 *                             next_char = '\n'
 *                         elif escape_char == 't':             # <<<<<<<<<<<<<<
 *                             next_char = '\t'
 *                         elif escape_char == '\n':
 */
            break;
            case 10:

            /* "srctools/_tokenizer.pyx":377
 *                         elif escape_char == '\n':
 *                             # \ at end of line ignores the newline.
 *                             continue             # <<<<<<<<<<<<<<
 *                         elif escape_char in ('"', '\\', '/'):
 *                             # For these, we escape to give the literal value.
 */
            goto __pyx_L11_continue;

            /* "srctools/_tokenizer.pyx":375
 *                         elif escape_char == 't':
 *                             next_char = '\t'
 *                         elif escape_char == '\n':             # <<<<<<<<<<<<<<
 *                             # \ at end of line ignores the newline.
 *                             continue
 */
            break;
            case 34:

            /* "srctools/_tokenizer.pyx":378
 *                             # \ at end of line ignores the newline.
 *                             continue
 *                         elif escape_char in ('"', '\\', '/'):             # <<<<<<<<<<<<<<
 *                             # For these, we escape to give the literal value.
 *                             next_char = escape_char
 */
            case 92:
            case 47:

            /* "srctools/_tokenizer.pyx":380
 *                         elif escape_char in ('"', '\\', '/'):
 *                             # For these, we escape to give the literal value.
 *                             next_char = escape_char             # <<<<<<<<<<<<<<
 *                         else:
 *                             # For unknown escape_chars, escape the \ automatically.
 */
            __pyx_v_next_char = __pyx_v_escape_char;

            /* "srctools/_tokenizer.pyx":378
 *                             # \ at end of line ignores the newline.
 *                             continue
 *                         elif escape_char in ('"', '\\', '/'):             # <<<<<<<<<<<<<<
 *                             # For these, we escape to give the literal value.
 *                             next_char = escape_char
 */
            break;
            default:

            /* "srctools/_tokenizer.pyx":383
 *                         else:
 *                             # For unknown escape_chars, escape the \ automatically.
 *                             self.buf_add_char('\\')             # <<<<<<<<<<<<<<
 *                             self.buf_add_char(escape_char)
 *                             continue
 */
            __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, 92);

            /* "srctools/_tokenizer.pyx":384
 *                             # For unknown escape_chars, escape the \ automatically.
 *                             self.buf_add_char('\\')
 *                             self.buf_add_char(escape_char)             # <<<<<<<<<<<<<<
 *                             continue
 *                             # raise self.error('Unknown escape_char "\\{}" in {}!', escape_char, self.cur_chunk)
 */
            __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_escape_char);

            /* "srctools/_tokenizer.pyx":385
 *                             self.buf_add_char('\\')
 *                             self.buf_add_char(escape_char)
 *                             continue             # <<<<<<<<<<<<<<
 *                             # raise self.error('Unknown escape_char "\\{}" in {}!', escape_char, self.cur_chunk)
 *                     self.buf_add_char(next_char)
 */
            goto __pyx_L11_continue;
            break;
          }

          /* "srctools/_tokenizer.pyx":365
 *                     elif next_char == '\n':
 *                         self.line_num += 1
 *                     elif next_char == '\\' and self.allow_escapes:             # <<<<<<<<<<<<<<
 *                         # Escape text
 *                         escape_char = self._next_char()
 */
        }
        __pyx_L13:;

        /* "srctools/_tokenizer.pyx":387
 *                             continue
 *                             # raise self.error('Unknown escape_char "\\{}" in {}!', escape_char, self.cur_chunk)
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == '[':
 */
        __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char);
        __pyx_L11_continue:;
      }

      /* "srctools/_tokenizer.pyx":355
 * 
 *             # Strings
 *             elif next_char == '"':             # <<<<<<<<<<<<<<
 *                 self.buf_reset()
 *                 while True:
 */
      break;
      case 91:

      /* "srctools/_tokenizer.pyx":391
 *             elif next_char == '[':
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.string_bracket:             # <<<<<<<<<<<<<<
 *                     return BRACK_OPEN_TUP
 * 
 */
      __pyx_t_2 = ((!(__pyx_v_self->string_bracket != 0)) != 0);
      if (__pyx_t_2) {

        /* "srctools/_tokenizer.pyx":392
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.string_bracket:
 *                     return BRACK_OPEN_TUP             # <<<<<<<<<<<<<<
 * 
 *                 self.buf_reset()
 */
        __Pyx_XDECREF(__pyx_r);
        __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP);
        __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP;
        goto __pyx_L0;

        /* "srctools/_tokenizer.pyx":391
 *             elif next_char == '[':
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.string_bracket:             # <<<<<<<<<<<<<<
 *                     return BRACK_OPEN_TUP
 * 
 */
      }

      /* "srctools/_tokenizer.pyx":394
 *                     return BRACK_OPEN_TUP
 * 
 *                 self.buf_reset()             # <<<<<<<<<<<<<<
 *                 while True:
 *                     next_char = self._next_char()
 */
      __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

      /* "srctools/_tokenizer.pyx":395
 * 
 *                 self.buf_reset()
 *                 while True:             # <<<<<<<<<<<<<<
 *                     next_char = self._next_char()
 *                     if next_char == '[':
 */
      while (1) {

        /* "srctools/_tokenizer.pyx":396
 *                 self.buf_reset()
 *                 while True:
 *                     next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                     if next_char == '[':
 *                         # Don't allow nesting, that's bad.
 */
        __pyx_t_4 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 396, __pyx_L1_error)
        __pyx_v_next_char = __pyx_t_4;

        /* "srctools/_tokenizer.pyx":397
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == '[':             # <<<<<<<<<<<<<<
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')
 */
        switch (__pyx_v_next_char) {
          case 91:

          /* "srctools/_tokenizer.pyx":399
 *                     if next_char == '[':
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')             # <<<<<<<<<<<<<<
 *                     elif next_char == ']':
 *                         return PROP_FLAG, self.buf_get_text()
 */
          __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, __pyx_kp_u_Cannot_nest_brackets); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 399, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_Raise(__pyx_t_3, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __PYX_ERR(0, 399, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":397
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == '[':             # <<<<<<<<<<<<<<
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')
 */
          break;
          case 93:

          /* "srctools/_tokenizer.pyx":401
 *                         raise self._error('Cannot nest [] brackets!')
 *                     elif next_char == ']':
 *                         return PROP_FLAG, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                     # Must be one line!
 *                     elif next_char == '\n' or next_char == -1:
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 401, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 401, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_PROP_FLAG);
          __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_PROP_FLAG);
          PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_8srctools_10_tokenizer_PROP_FLAG);
          __Pyx_GIVEREF(__pyx_t_3);
          PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_3);
          __pyx_t_3 = 0;
          __pyx_r = __pyx_t_7;
          __pyx_t_7 = 0;
          goto __pyx_L0;

          /* "srctools/_tokenizer.pyx":400
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')
 *                     elif next_char == ']':             # <<<<<<<<<<<<<<
 *                         return PROP_FLAG, self.buf_get_text()
 *                     # Must be one line!
 */
          break;
          case 10:

          /* "srctools/_tokenizer.pyx":403
 *                         return PROP_FLAG, self.buf_get_text()
 *                     # Must be one line!
 *                     elif next_char == '\n' or next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error(
 *                             'Reached end of line '
 */
          case -1L:

          /* "srctools/_tokenizer.pyx":404
 *                     # Must be one line!
 *                     elif next_char == '\n' or next_char == -1:
 *                         raise self._error(             # <<<<<<<<<<<<<<
 *                             'Reached end of line '
 *                             'without closing "]"!'
 */
          __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, __pyx_kp_u_Reached_end_of_line_without_clos); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 404, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_Raise(__pyx_t_7, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          __PYX_ERR(0, 404, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":403
 *                         return PROP_FLAG, self.buf_get_text()
 *                     # Must be one line!
 *                     elif next_char == '\n' or next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error(
 *                             'Reached end of line '
 */
          break;
          default: break;
        }

        /* "srctools/_tokenizer.pyx":408
 *                             'without closing "]"!'
 *                         )
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == ']':
 */
        __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char);
      }

      /* "srctools/_tokenizer.pyx":389
 *                     self.buf_add_char(next_char)
 * 
 *             elif next_char == '[':             # <<<<<<<<<<<<<<
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.string_bracket:
 */
      break;
      case 93:

      /* "srctools/_tokenizer.pyx":411
 * 
 *             elif next_char == ']':
 *                 if self.string_bracket:             # <<<<<<<<<<<<<<
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 *                     # syntax error - we don't have an open one to close!
 */
      __pyx_t_2 = (__pyx_v_self->string_bracket != 0);
      if (unlikely(__pyx_t_2)) {

        /* "srctools/_tokenizer.pyx":414
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 *                     # syntax error - we don't have an open one to close!
 *                     raise self._error('No open [] to close with "]"!')             # <<<<<<<<<<<<<<
 *                 return BRACK_CLOSE_TUP
 * 
 */
        __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, __pyx_kp_u_No_open_to_close_with); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 414, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_Raise(__pyx_t_7, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __PYX_ERR(0, 414, __pyx_L1_error)

        /* "srctools/_tokenizer.pyx":411
 * 
 *             elif next_char == ']':
 *                 if self.string_bracket:             # <<<<<<<<<<<<<<
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 *                     # syntax error - we don't have an open one to close!
 */
      }

      /* "srctools/_tokenizer.pyx":415
 *                     # syntax error - we don't have an open one to close!
 *                     raise self._error('No open [] to close with "]"!')
 *                 return BRACK_CLOSE_TUP             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == '(':
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":410
 *                     self.buf_add_char(next_char)
 * 
 *             elif next_char == ']':             # <<<<<<<<<<<<<<
 *                 if self.string_bracket:
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 */
      break;
      case 40:

      /* "srctools/_tokenizer.pyx":419
 *             elif next_char == '(':
 *                 # Parentheses around text...
 *                 self.buf_reset()             # <<<<<<<<<<<<<<
 *                 while True:
 *                     next_char = self._next_char()
 */
      __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

      /* "srctools/_tokenizer.pyx":420
 *                 # Parentheses around text...
 *                 self.buf_reset()
 *                 while True:             # <<<<<<<<<<<<<<
 *                     next_char = self._next_char()
 *                     if next_char == -1:
 */
      while (1) {

        /* "srctools/_tokenizer.pyx":421
 *                 self.buf_reset()
 *                 while True:
 *                     next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                     if next_char == -1:
 *                         raise self._error('Unterminated parentheses!')
 */
        __pyx_t_4 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 421, __pyx_L1_error)
        __pyx_v_next_char = __pyx_t_4;

        /* "srctools/_tokenizer.pyx":422
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == '(':
 */
        switch (__pyx_v_next_char) {
          case -1L:

          /* "srctools/_tokenizer.pyx":423
 *                     next_char = self._next_char()
 *                     if next_char == -1:
 *                         raise self._error('Unterminated parentheses!')             # <<<<<<<<<<<<<<
 *                     elif next_char == '(':
 *                         raise self._error('Cannot nest () brackets!')
 */
          __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, __pyx_kp_u_Unterminated_parentheses); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 423, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_Raise(__pyx_t_7, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          __PYX_ERR(0, 423, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":422
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == '(':
 */
          break;
          case 40:

          /* "srctools/_tokenizer.pyx":425
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == '(':
 *                         raise self._error('Cannot nest () brackets!')             # <<<<<<<<<<<<<<
 *                     elif next_char == ')':
 *                         return PAREN_ARGS, self.buf_get_text()
 */
          __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, __pyx_kp_u_Cannot_nest_brackets_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 425, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_Raise(__pyx_t_7, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          __PYX_ERR(0, 425, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":424
 *                     if next_char == -1:
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == '(':             # <<<<<<<<<<<<<<
 *                         raise self._error('Cannot nest () brackets!')
 *                     elif next_char == ')':
 */
          break;
          case 41:

          /* "srctools/_tokenizer.pyx":427
 *                         raise self._error('Cannot nest () brackets!')
 *                     elif next_char == ')':
 *                         return PAREN_ARGS, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                     elif next_char == '\n':
 *                         self.line_num += 1
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 427, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 427, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
          __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
          PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_r = __pyx_t_3;
          __pyx_t_3 = 0;
          goto __pyx_L0;

          /* "srctools/_tokenizer.pyx":426
 *                     elif next_char == '(':
 *                         raise self._error('Cannot nest () brackets!')
 *                     elif next_char == ')':             # <<<<<<<<<<<<<<
 *                         return PAREN_ARGS, self.buf_get_text()
 *                     elif next_char == '\n':
 */
          break;
          case 10:

          /* "srctools/_tokenizer.pyx":429
 *                         return PAREN_ARGS, self.buf_get_text()
 *                     elif next_char == '\n':
 *                         self.line_num += 1             # <<<<<<<<<<<<<<
 *                     self.buf_add_char(next_char)
 * 
 */
          __pyx_v_self->line_num = (__pyx_v_self->line_num + 1);

          /* "srctools/_tokenizer.pyx":428
 *                     elif next_char == ')':
 *                         return PAREN_ARGS, self.buf_get_text()
 *                     elif next_char == '\n':             # <<<<<<<<<<<<<<
 *                         self.line_num += 1
 *                     self.buf_add_char(next_char)
 */
          break;
          default: break;
        }

        /* "srctools/_tokenizer.pyx":430
 *                     elif next_char == '\n':
 *                         self.line_num += 1
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == ')':
 */
        __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char);
      }

      /* "srctools/_tokenizer.pyx":417
 *                 return BRACK_CLOSE_TUP
 * 
 *             elif next_char == '(':             # <<<<<<<<<<<<<<
 *                 # Parentheses around text...
 *                 self.buf_reset()
 */
      break;
      case 41:

      /* "srctools/_tokenizer.pyx":433
 * 
 *             elif next_char == ')':
 *                 raise self._error('No open () to close with ")"!')             # <<<<<<<<<<<<<<
 * 
 *             # Ignore Unicode Byte Order Mark on first lines
 */
      __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, __pyx_kp_u_No_open_to_close_with_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 433, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(0, 433, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":432
 *                     self.buf_add_char(next_char)
 * 
 *             elif next_char == ')':             # <<<<<<<<<<<<<<
 *                 raise self._error('No open () to close with ")"!')
 * 
 */
      break;
      case 0xFEFF:

      /* "srctools/_tokenizer.pyx":437
 *             # Ignore Unicode Byte Order Mark on first lines
 *             elif next_char == '\uFEFF':
 *                 if self.line_num == 1:             # <<<<<<<<<<<<<<
 *                     continue
 *                 # else, we fall out of the if, and get an unexpected char
 */
      __pyx_t_2 = ((__pyx_v_self->line_num == 1) != 0);
      if (__pyx_t_2) {

        /* "srctools/_tokenizer.pyx":438
 *             elif next_char == '\uFEFF':
 *                 if self.line_num == 1:
 *                     continue             # <<<<<<<<<<<<<<
 *                 # else, we fall out of the if, and get an unexpected char
 *                 # error.
 */
        goto __pyx_L4_continue;

        /* "srctools/_tokenizer.pyx":437
 *             # Ignore Unicode Byte Order Mark on first lines
 *             elif next_char == '\uFEFF':
 *                 if self.line_num == 1:             # <<<<<<<<<<<<<<
 *                     continue
 *                 # else, we fall out of the if, and get an unexpected char
 */
      }

      /* "srctools/_tokenizer.pyx":436
 * 
 *             # Ignore Unicode Byte Order Mark on first lines
 *             elif next_char == '\uFEFF':             # <<<<<<<<<<<<<<
 *                 if self.line_num == 1:
 *                     continue
 */
      break;
      default:

      /* "srctools/_tokenizer.pyx":444
 *             else: # Not-in can't be in a switch, so we need to nest this.
 *                 # Bare names
 *                 if next_char not in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)
 */
      switch (__pyx_v_next_char) {
        case 34:
        case 39:
        case 0x7B:
        case 0x7D:
        case 59:
        case 58:
        case 91:
        case 93:
        case 40:
        case 41:
        case 10:
        case 9:
        case 32:
        __pyx_t_2 = 0;
        break;
        default:
        __pyx_t_2 = 1;
        break;
      }
      __pyx_t_1 = (__pyx_t_2 != 0);
      if (likely(__pyx_t_1)) {

        /* "srctools/_tokenizer.pyx":445
 *                 # Bare names
 *                 if next_char not in BARE_DISALLOWED:
 *                     self.buf_reset()             # <<<<<<<<<<<<<<
 *                     self.buf_add_char(next_char)
 *                     while True:
 */
        __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

        /* "srctools/_tokenizer.pyx":446
 *                 if next_char not in BARE_DISALLOWED:
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 *                     while True:
 *                         next_char = self._next_char()
 */
        __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char);

        /* "srctools/_tokenizer.pyx":447
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)
 *                     while True:             # <<<<<<<<<<<<<<
 *                         next_char = self._next_char()
 *                         if next_char == -1:
 */
        while (1) {

          /* "srctools/_tokenizer.pyx":448
 *                     self.buf_add_char(next_char)
 *                     while True:
 *                         next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                         if next_char == -1:
 *                             # Bare names at the end are actually fine.
 */
          __pyx_t_4 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 448, __pyx_L1_error)
          __pyx_v_next_char = __pyx_t_4;

          /* "srctools/_tokenizer.pyx":449
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == -1:             # <<<<<<<<<<<<<<
 *                             # Bare names at the end are actually fine.
 *                             # It could be a value for the last prop.
 */
          switch (__pyx_v_next_char) {
            case -1L:

            /* "srctools/_tokenizer.pyx":452
 *                             # Bare names at the end are actually fine.
 *                             # It could be a value for the last prop.
 *                             return STRING, self.buf_get_text()             # <<<<<<<<<<<<<<
 * 
 *                         elif next_char in BARE_DISALLOWED:
 */
            __Pyx_XDECREF(__pyx_r);
            __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 452, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 452, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_7);
            __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_STRING);
            __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_STRING);
            PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_8srctools_10_tokenizer_STRING);
            __Pyx_GIVEREF(__pyx_t_3);
            PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_3);
            __pyx_t_3 = 0;
            __pyx_r = __pyx_t_7;
            __pyx_t_7 = 0;
            goto __pyx_L0;

            /* "srctools/_tokenizer.pyx":449
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == -1:             # <<<<<<<<<<<<<<
 *                             # Bare names at the end are actually fine.
 *                             # It could be a value for the last prop.
 */
            break;
            case 34:

            /* "srctools/_tokenizer.pyx":454
 *                             return STRING, self.buf_get_text()
 * 
 *                         elif next_char in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                             # We need to repeat this so we return the ending
 *                             # char next. If it's not allowed, that'll error on
 */
            case 39:
            case 0x7B:
            case 0x7D:
            case 59:
            case 58:
            case 91:
            case 93:
            case 40:
            case 41:
            case 10:
            case 9:
            case 32:

            /* "srctools/_tokenizer.pyx":459
 *                             # next call.
 *                             # We need to repeat this so we return the newline.
 *                             self.char_index -= 1             # <<<<<<<<<<<<<<
 *                             return STRING, self.buf_get_text()
 *                         else:
 */
            __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);

            /* "srctools/_tokenizer.pyx":460
 *                             # We need to repeat this so we return the newline.
 *                             self.char_index -= 1
 *                             return STRING, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                         else:
 *                             self.buf_add_char(next_char)
 */
            __Pyx_XDECREF(__pyx_r);
            __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 460, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_7);
            __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 460, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_STRING);
            __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_STRING);
            PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_8srctools_10_tokenizer_STRING);
            __Pyx_GIVEREF(__pyx_t_7);
            PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
            __pyx_t_7 = 0;
            __pyx_r = __pyx_t_3;
            __pyx_t_3 = 0;
            goto __pyx_L0;

            /* "srctools/_tokenizer.pyx":454
 *                             return STRING, self.buf_get_text()
 * 
 *                         elif next_char in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                             # We need to repeat this so we return the ending
 *                             # char next. If it's not allowed, that'll error on
 */
            break;
            default:

            /* "srctools/_tokenizer.pyx":462
 *                             return STRING, self.buf_get_text()
 *                         else:
 *                             self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 *                 else:
 *                     raise self._error(f'Unexpected character "{next_char}"!')
 */
            __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char);
            break;
          }
        }

        /* "srctools/_tokenizer.pyx":444
 *             else: # Not-in can't be in a switch, so we need to nest this.
 *                 # Bare names
 *                 if next_char not in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)
 */
        goto __pyx_L24;
      }

      /* "srctools/_tokenizer.pyx":464
 *                             self.buf_add_char(next_char)
 *                 else:
 *                     raise self._error(f'Unexpected character "{next_char}"!')             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
      /*else*/ {
        __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 464, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_6 = 0;
        __pyx_t_4 = 127;
        __Pyx_INCREF(__pyx_kp_u_Unexpected_character);
        __pyx_t_6 += 22;
        __Pyx_GIVEREF(__pyx_kp_u_Unexpected_character);
        PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Unexpected_character);
        __pyx_t_7 = PyUnicode_FromOrdinal(__pyx_v_next_char); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 464, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __pyx_t_4 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) > __pyx_t_4) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) : __pyx_t_4;
        __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
        __Pyx_GIVEREF(__pyx_t_7);
        PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
        __pyx_t_7 = 0;
        __Pyx_INCREF(__pyx_kp_u__3);
        __pyx_t_6 += 2;
        __Pyx_GIVEREF(__pyx_kp_u__3);
        PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u__3);
        __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_3, 3, __pyx_t_6, __pyx_t_4); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 464, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, ((PyObject*)__pyx_t_7)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 464, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_Raise(__pyx_t_3, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __PYX_ERR(0, 464, __pyx_L1_error)
      }
      __pyx_L24:;
      break;
    }
    __pyx_L4_continue:;
  }

  /* "srctools/_tokenizer.pyx":263
 *         return self.next_token()
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair - this is the C version."""
 *         cdef:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.next_token", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_output);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":466
 *                     raise self._error(f'Unexpected character "{next_char}"!')
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         # Call ourselves until EOF is returned
 *         return iter(self, EOF_TUP)
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_13__iter__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_13__iter__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_12__iter__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_12__iter__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__iter__", 0);

  /* "srctools/_tokenizer.pyx":468
 *     def __iter__(self):
 *         # Call ourselves until EOF is returned
 *         return iter(self, EOF_TUP)             # <<<<<<<<<<<<<<
 * 
 *     def push_back(self, object tok not None, str value=None):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_v_8srctools_10_tokenizer_EOF_TUP;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = PyCallIter_New(((PyObject *)__pyx_v_self), __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 468, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":466
 *                     raise self._error(f'Unexpected character "{next_char}"!')
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         # Call ourselves until EOF is returned
 *         return iter(self, EOF_TUP)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__iter__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":470
 *         return iter(self, EOF_TUP)
 * 
 *     def push_back(self, object tok not None, str value=None):             # <<<<<<<<<<<<<<
 *         """Return a token, so it will be reproduced when called again.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_15push_back(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_9Tokenizer_14push_back[] = "Tokenizer.push_back(self, tok, unicode value=None)\nReturn a token, so it will be reproduced when called again.\n\n        Only one token can be pushed back at once.\n        The value should be the original value, or None\n        ";
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_15push_back(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_tok = 0;
  PyObject *__pyx_v_value = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("push_back (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_tok,&__pyx_n_s_value,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject*)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_tok)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_value);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "push_back") < 0)) __PYX_ERR(0, 470, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_tok = values[0];
    __pyx_v_value = ((PyObject*)values[1]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("push_back", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 470, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.push_back", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(((PyObject *)__pyx_v_tok) == Py_None)) {
    PyErr_Format(PyExc_TypeError, "Argument '%.200s' must not be None", "tok"); __PYX_ERR(0, 470, __pyx_L1_error)
  }
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_value), (&PyUnicode_Type), 1, "value", 1))) __PYX_ERR(0, 470, __pyx_L1_error)
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14push_back(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_tok, __pyx_v_value);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_14push_back(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_tok, PyObject *__pyx_v_value) {
  int __pyx_v_tok_val;
  PyObject *__pyx_v_real_value = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  Py_UCS4 __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("push_back", 0);
  __Pyx_INCREF(__pyx_v_value);

  /* "srctools/_tokenizer.pyx":476
 *         The value should be the original value, or None
 *         """
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):
 */
  __pyx_t_1 = (__pyx_v_self->pushback_tok != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (unlikely(__pyx_t_2)) {

    /* "srctools/_tokenizer.pyx":477
 *         """
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')             # <<<<<<<<<<<<<<
 *         if not isinstance(tok, Token):
 *             raise ValueError(repr(tok) + ' is not a Token!')
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__9, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 477, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 477, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":476
 *         The value should be the original value, or None
 *         """
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):
 */
  }

  /* "srctools/_tokenizer.pyx":478
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):             # <<<<<<<<<<<<<<
 *             raise ValueError(repr(tok) + ' is not a Token!')
 * 
 */
  __pyx_t_3 = __pyx_v_8srctools_10_tokenizer_Token;
  __Pyx_INCREF(__pyx_t_3);
  __pyx_t_2 = PyObject_IsInstance(__pyx_v_tok, __pyx_t_3); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 478, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_1 = ((!(__pyx_t_2 != 0)) != 0);
  if (unlikely(__pyx_t_1)) {

    /* "srctools/_tokenizer.pyx":479
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):
 *             raise ValueError(repr(tok) + ' is not a Token!')             # <<<<<<<<<<<<<<
 * 
 *         cdef int tok_val = tok.value
 */
    __pyx_t_3 = PyObject_Repr(__pyx_v_tok); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 479, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyUnicode_ConcatSafe(__pyx_t_3, __pyx_kp_u_is_not_a_Token); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 479, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 479, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 479, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":478
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):             # <<<<<<<<<<<<<<
 *             raise ValueError(repr(tok) + ' is not a Token!')
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":481
 *             raise ValueError(repr(tok) + ' is not a Token!')
 * 
 *         cdef int tok_val = tok.value             # <<<<<<<<<<<<<<
 *         cdef str real_value
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_tok, __pyx_n_s_value); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 481, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 481, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_tok_val = __pyx_t_5;

  /* "srctools/_tokenizer.pyx":484
 *         cdef str real_value
 * 
 *         if tok_val == 0: # EOF             # <<<<<<<<<<<<<<
 *             real_value = None
 *         elif tok_val in (1, 3, 10):  # STRING, PAREN_ARGS, PROP_FLAG
 */
  switch (__pyx_v_tok_val) {
    case 0:

    /* "srctools/_tokenizer.pyx":485
 * 
 *         if tok_val == 0: # EOF
 *             real_value = None             # <<<<<<<<<<<<<<
 *         elif tok_val in (1, 3, 10):  # STRING, PAREN_ARGS, PROP_FLAG
 *             real_value = ''
 */
    __Pyx_INCREF(Py_None);
    __pyx_v_real_value = ((PyObject*)Py_None);

    /* "srctools/_tokenizer.pyx":484
 *         cdef str real_value
 * 
 *         if tok_val == 0: # EOF             # <<<<<<<<<<<<<<
 *             real_value = None
 *         elif tok_val in (1, 3, 10):  # STRING, PAREN_ARGS, PROP_FLAG
 */
    break;
    case 1:

    /* "srctools/_tokenizer.pyx":486
 *         if tok_val == 0: # EOF
 *             real_value = None
 *         elif tok_val in (1, 3, 10):  # STRING, PAREN_ARGS, PROP_FLAG             # <<<<<<<<<<<<<<
 *             real_value = ''
 *         elif tok_val == 2:  # NEWLINE
 */
    case 3:
    case 10:

    /* "srctools/_tokenizer.pyx":487
 *             real_value = None
 *         elif tok_val in (1, 3, 10):  # STRING, PAREN_ARGS, PROP_FLAG
 *             real_value = ''             # <<<<<<<<<<<<<<
 *         elif tok_val == 2:  # NEWLINE
 *             real_value = '\n'
 */
    __Pyx_INCREF(__pyx_kp_u__2);
    __pyx_v_real_value = __pyx_kp_u__2;

    /* "srctools/_tokenizer.pyx":486
 *         if tok_val == 0: # EOF
 *             real_value = None
 *         elif tok_val in (1, 3, 10):  # STRING, PAREN_ARGS, PROP_FLAG             # <<<<<<<<<<<<<<
 *             real_value = ''
 *         elif tok_val == 2:  # NEWLINE
 */
    break;
    case 2:

    /* "srctools/_tokenizer.pyx":489
 *             real_value = ''
 *         elif tok_val == 2:  # NEWLINE
 *             real_value = '\n'             # <<<<<<<<<<<<<<
 *         elif tok_val == 5:  # BRACE_OPEN
 *             real_value = '{'
 */
    __Pyx_INCREF(__pyx_kp_u__10);
    __pyx_v_real_value = __pyx_kp_u__10;

    /* "srctools/_tokenizer.pyx":488
 *         elif tok_val in (1, 3, 10):  # STRING, PAREN_ARGS, PROP_FLAG
 *             real_value = ''
 *         elif tok_val == 2:  # NEWLINE             # <<<<<<<<<<<<<<
 *             real_value = '\n'
 *         elif tok_val == 5:  # BRACE_OPEN
 */
    break;
    case 5:

    /* "srctools/_tokenizer.pyx":491
 *             real_value = '\n'
 *         elif tok_val == 5:  # BRACE_OPEN
 *             real_value = '{'             # <<<<<<<<<<<<<<
 *         elif tok_val == 6:  # BRACE_CLOSE
 *             real_value = '}'
 */
    __Pyx_INCREF(__pyx_kp_u__11);
    __pyx_v_real_value = __pyx_kp_u__11;

    /* "srctools/_tokenizer.pyx":490
 *         elif tok_val == 2:  # NEWLINE
 *             real_value = '\n'
 *         elif tok_val == 5:  # BRACE_OPEN             # <<<<<<<<<<<<<<
 *             real_value = '{'
 *         elif tok_val == 6:  # BRACE_CLOSE
 */
    break;
    case 6:

    /* "srctools/_tokenizer.pyx":493
 *             real_value = '{'
 *         elif tok_val == 6:  # BRACE_CLOSE
 *             real_value = '}'             # <<<<<<<<<<<<<<
 *         elif tok_val == 11:  # BRACK_OPEN
 *             real_value = '['
 */
    __Pyx_INCREF(__pyx_kp_u__12);
    __pyx_v_real_value = __pyx_kp_u__12;

    /* "srctools/_tokenizer.pyx":492
 *         elif tok_val == 5:  # BRACE_OPEN
 *             real_value = '{'
 *         elif tok_val == 6:  # BRACE_CLOSE             # <<<<<<<<<<<<<<
 *             real_value = '}'
 *         elif tok_val == 11:  # BRACK_OPEN
 */
    break;
    case 11:

    /* "srctools/_tokenizer.pyx":495
 *             real_value = '}'
 *         elif tok_val == 11:  # BRACK_OPEN
 *             real_value = '['             # <<<<<<<<<<<<<<
 *         elif tok_val == 12:  # BRACK_CLOSE
 *             real_value = ']'
 */
    __Pyx_INCREF(__pyx_kp_u__13);
    __pyx_v_real_value = __pyx_kp_u__13;

    /* "srctools/_tokenizer.pyx":494
 *         elif tok_val == 6:  # BRACE_CLOSE
 *             real_value = '}'
 *         elif tok_val == 11:  # BRACK_OPEN             # <<<<<<<<<<<<<<
 *             real_value = '['
 *         elif tok_val == 12:  # BRACK_CLOSE
 */
    break;
    case 12:

    /* "srctools/_tokenizer.pyx":497
 *             real_value = '['
 *         elif tok_val == 12:  # BRACK_CLOSE
 *             real_value = ']'             # <<<<<<<<<<<<<<
 *         elif tok_val == 13:  # COLON
 *             real_value = ':'
 */
    __Pyx_INCREF(__pyx_kp_u__14);
    __pyx_v_real_value = __pyx_kp_u__14;

    /* "srctools/_tokenizer.pyx":496
 *         elif tok_val == 11:  # BRACK_OPEN
 *             real_value = '['
 *         elif tok_val == 12:  # BRACK_CLOSE             # <<<<<<<<<<<<<<
 *             real_value = ']'
 *         elif tok_val == 13:  # COLON
 */
    break;
    case 13:

    /* "srctools/_tokenizer.pyx":499
 *             real_value = ']'
 *         elif tok_val == 13:  # COLON
 *             real_value = ':'             # <<<<<<<<<<<<<<
 *         elif tok_val == 14:  # EQUALS
 *             real_value = '='
 */
    __Pyx_INCREF(__pyx_kp_u__15);
    __pyx_v_real_value = __pyx_kp_u__15;

    /* "srctools/_tokenizer.pyx":498
 *         elif tok_val == 12:  # BRACK_CLOSE
 *             real_value = ']'
 *         elif tok_val == 13:  # COLON             # <<<<<<<<<<<<<<
 *             real_value = ':'
 *         elif tok_val == 14:  # EQUALS
 */
    break;
    case 14:

    /* "srctools/_tokenizer.pyx":501
 *             real_value = ':'
 *         elif tok_val == 14:  # EQUALS
 *             real_value = '='             # <<<<<<<<<<<<<<
 *         elif tok_val == 15:  # PLUS
 *             real_value = '+'
 */
    __Pyx_INCREF(__pyx_kp_u__16);
    __pyx_v_real_value = __pyx_kp_u__16;

    /* "srctools/_tokenizer.pyx":500
 *         elif tok_val == 13:  # COLON
 *             real_value = ':'
 *         elif tok_val == 14:  # EQUALS             # <<<<<<<<<<<<<<
 *             real_value = '='
 *         elif tok_val == 15:  # PLUS
 */
    break;
    case 15:

    /* "srctools/_tokenizer.pyx":503
 *             real_value = '='
 *         elif tok_val == 15:  # PLUS
 *             real_value = '+'             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError('Unknown token value!')
 */
    __Pyx_INCREF(__pyx_kp_u__17);
    __pyx_v_real_value = __pyx_kp_u__17;

    /* "srctools/_tokenizer.pyx":502
 *         elif tok_val == 14:  # EQUALS
 *             real_value = '='
 *         elif tok_val == 15:  # PLUS             # <<<<<<<<<<<<<<
 *             real_value = '+'
 *         else:
 */
    break;
    default:

    /* "srctools/_tokenizer.pyx":505
 *             real_value = '+'
 *         else:
 *             raise ValueError('Unknown token value!')             # <<<<<<<<<<<<<<
 * 
 *         # If no value provided, use the default (operators)
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__18, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 505, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 505, __pyx_L1_error)
    break;
  }

  /* "srctools/_tokenizer.pyx":508
 * 
 *         # If no value provided, use the default (operators)
 *         if value is None:             # <<<<<<<<<<<<<<
 *             value = real_value
 *         # A type which needs a value provided...
 */
  __pyx_t_1 = (__pyx_v_value == ((PyObject*)Py_None));
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":509
 *         # If no value provided, use the default (operators)
 *         if value is None:
 *             value = real_value             # <<<<<<<<<<<<<<
 *         # A type which needs a value provided...
 *         elif real_value == '':
 */
    __Pyx_INCREF(__pyx_v_real_value);
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_v_real_value);

    /* "srctools/_tokenizer.pyx":508
 * 
 *         # If no value provided, use the default (operators)
 *         if value is None:             # <<<<<<<<<<<<<<
 *             value = real_value
 *         # A type which needs a value provided...
 */
    goto __pyx_L5;
  }

  /* "srctools/_tokenizer.pyx":511
 *             value = real_value
 *         # A type which needs a value provided...
 *         elif real_value == '':             # <<<<<<<<<<<<<<
 *             value = '' if value is None else value
 *         elif not isinstance(value, str):
 */
  __pyx_t_2 = (__Pyx_PyUnicode_Equals(__pyx_v_real_value, __pyx_kp_u__2, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 511, __pyx_L1_error)
  __pyx_t_1 = (__pyx_t_2 != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":512
 *         # A type which needs a value provided...
 *         elif real_value == '':
 *             value = '' if value is None else value             # <<<<<<<<<<<<<<
 *         elif not isinstance(value, str):
 *             raise ValueError(
 */
    __pyx_t_1 = (__pyx_v_value == ((PyObject*)Py_None));
    if ((__pyx_t_1 != 0)) {
      __Pyx_INCREF(__pyx_kp_u__2);
      __pyx_t_3 = __pyx_kp_u__2;
    } else {
      __Pyx_INCREF(__pyx_v_value);
      __pyx_t_3 = __pyx_v_value;
    }
    __Pyx_DECREF_SET(__pyx_v_value, ((PyObject*)__pyx_t_3));
    __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":511
 *             value = real_value
 *         # A type which needs a value provided...
 *         elif real_value == '':             # <<<<<<<<<<<<<<
 *             value = '' if value is None else value
 *         elif not isinstance(value, str):
 */
    goto __pyx_L5;
  }

  /* "srctools/_tokenizer.pyx":513
 *         elif real_value == '':
 *             value = '' if value is None else value
 *         elif not isinstance(value, str):             # <<<<<<<<<<<<<<
 *             raise ValueError(
 *                 f'Invalid value provided ({value!r}) for {tok.name}!'
 */
  __pyx_t_1 = PyUnicode_Check(__pyx_v_value); 
  __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
  if (unlikely(__pyx_t_2)) {

    /* "srctools/_tokenizer.pyx":515
 *         elif not isinstance(value, str):
 *             raise ValueError(
 *                 f'Invalid value provided ({value!r}) for {tok.name}!'             # <<<<<<<<<<<<<<
 *             ) from None
 * 
 */
    __pyx_t_3 = PyTuple_New(5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 515, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = 0;
    __pyx_t_7 = 127;
    __Pyx_INCREF(__pyx_kp_u_Invalid_value_provided);
    __pyx_t_6 += 24;
    __Pyx_GIVEREF(__pyx_kp_u_Invalid_value_provided);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Invalid_value_provided);
    __pyx_t_4 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_value), __pyx_empty_unicode); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 515, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_7 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_4) > __pyx_t_7) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_4) : __pyx_t_7;
    __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_4);
    __pyx_t_4 = 0;
    __Pyx_INCREF(__pyx_kp_u_for);
    __pyx_t_6 += 6;
    __Pyx_GIVEREF(__pyx_kp_u_for);
    PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u_for);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_tok, __pyx_n_s_name); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 515, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_8 = __Pyx_PyObject_FormatSimple(__pyx_t_4, __pyx_empty_unicode); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 515, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_7 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_8) > __pyx_t_7) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_8) : __pyx_t_7;
    __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_8);
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_3, 3, __pyx_t_8);
    __pyx_t_8 = 0;
    __Pyx_INCREF(__pyx_kp_u__5);
    __pyx_t_6 += 1;
    __Pyx_GIVEREF(__pyx_kp_u__5);
    PyTuple_SET_ITEM(__pyx_t_3, 4, __pyx_kp_u__5);
    __pyx_t_8 = __Pyx_PyUnicode_Join(__pyx_t_3, 5, __pyx_t_6, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 515, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":514
 *             value = '' if value is None else value
 *         elif not isinstance(value, str):
 *             raise ValueError(             # <<<<<<<<<<<<<<
 *                 f'Invalid value provided ({value!r}) for {tok.name}!'
 *             ) from None
 */
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 514, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "srctools/_tokenizer.pyx":516
 *             raise ValueError(
 *                 f'Invalid value provided ({value!r}) for {tok.name}!'
 *             ) from None             # <<<<<<<<<<<<<<
 * 
 *         self.pushback_tok = tok
 */
    __Pyx_Raise(__pyx_t_3, 0, 0, Py_None);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 514, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":513
 *         elif real_value == '':
 *             value = '' if value is None else value
 *         elif not isinstance(value, str):             # <<<<<<<<<<<<<<
 *             raise ValueError(
 *                 f'Invalid value provided ({value!r}) for {tok.name}!'
 */
  }
  __pyx_L5:;

  /* "srctools/_tokenizer.pyx":518
 *             ) from None
 * 
 *         self.pushback_tok = tok             # <<<<<<<<<<<<<<
 *         self.pushback_val = value
 * 
 */
  __Pyx_INCREF(__pyx_v_tok);
  __Pyx_GIVEREF(__pyx_v_tok);
  __Pyx_GOTREF(__pyx_v_self->pushback_tok);
  __Pyx_DECREF(__pyx_v_self->pushback_tok);
  __pyx_v_self->pushback_tok = __pyx_v_tok;

  /* "srctools/_tokenizer.pyx":519
 * 
 *         self.pushback_tok = tok
 *         self.pushback_val = value             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_INCREF(__pyx_v_value);
  __Pyx_GIVEREF(__pyx_v_value);
  __Pyx_GOTREF(__pyx_v_self->pushback_val);
  __Pyx_DECREF(__pyx_v_self->pushback_val);
  __pyx_v_self->pushback_val = __pyx_v_value;

  /* "srctools/_tokenizer.pyx":470
 *         return iter(self, EOF_TUP)
 * 
 *     def push_back(self, object tok not None, str value=None):             # <<<<<<<<<<<<<<
 *         """Return a token, so it will be reproduced when called again.
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.push_back", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_real_value);
  __Pyx_XDECREF(__pyx_v_value);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":522
 * 
 * 
 *     def peek(self):             # <<<<<<<<<<<<<<
 *         """Peek at the next token, without removing it from the stream."""
 *         # We know this is a valid pushback value, and any existing value was
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_17peek(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_9Tokenizer_16peek[] = "Tokenizer.peek(self)\nPeek at the next token, without removing it from the stream.";
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_17peek(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("peek (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_16peek(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_16peek(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_v_tok_and_val = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("peek", 0);

  /* "srctools/_tokenizer.pyx":526
 *         # We know this is a valid pushback value, and any existing value was
 *         # just removed. So unconditionally assign.
 *         self.pushback_tok, self.pushback_val = tok_and_val = <tuple>self.next_token()             # <<<<<<<<<<<<<<
 * 
 *         return tok_and_val
 */
  __pyx_t_1 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 526, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __pyx_t_1;
  __Pyx_INCREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (likely(__pyx_t_2 != Py_None)) {
    PyObject* sequence = __pyx_t_2;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 526, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
    __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 526, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 526, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
  } else {
    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(0, 526, __pyx_L1_error)
  }
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->pushback_tok);
  __Pyx_DECREF(__pyx_v_self->pushback_tok);
  __pyx_v_self->pushback_tok = __pyx_t_1;
  __pyx_t_1 = 0;
  __Pyx_GIVEREF(__pyx_t_3);
  __Pyx_GOTREF(__pyx_v_self->pushback_val);
  __Pyx_DECREF(__pyx_v_self->pushback_val);
  __pyx_v_self->pushback_val = __pyx_t_3;
  __pyx_t_3 = 0;
  __Pyx_INCREF(__pyx_t_2);
  __pyx_v_tok_and_val = ((PyObject*)__pyx_t_2);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":528
 *         self.pushback_tok, self.pushback_val = tok_and_val = <tuple>self.next_token()
 * 
 *         return tok_and_val             # <<<<<<<<<<<<<<
 * 
 *     def skipping_newlines(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_tok_and_val);
  __pyx_r = __pyx_v_tok_and_val;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":522
 * 
 * 
 *     def peek(self):             # <<<<<<<<<<<<<<
 *         """Peek at the next token, without removing it from the stream."""
 *         # We know this is a valid pushback value, and any existing value was
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.peek", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tok_and_val);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":530
 *         return tok_and_val
 * 
 *     def skipping_newlines(self):             # <<<<<<<<<<<<<<
 *         """Iterate over the tokens, skipping newlines."""
 *         return NewlinesIter.__new__(NewlinesIter, self)
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_19skipping_newlines(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_9Tokenizer_18skipping_newlines[] = "Tokenizer.skipping_newlines(self)\nIterate over the tokens, skipping newlines.";
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_19skipping_newlines(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("skipping_newlines (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_18skipping_newlines(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_18skipping_newlines(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("skipping_newlines", 0);

  /* "srctools/_tokenizer.pyx":532
 *     def skipping_newlines(self):
 *         """Iterate over the tokens, skipping newlines."""
 *         return NewlinesIter.__new__(NewlinesIter, self)             # <<<<<<<<<<<<<<
 * 
 *     def expect(self, object token, bint skip_newline=True):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 532, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
  PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)__pyx_v_self));
  __pyx_t_2 = ((PyObject *)__pyx_tp_new_8srctools_10_tokenizer_NewlinesIter(((PyTypeObject *)__pyx_ptype_8srctools_10_tokenizer_NewlinesIter), __pyx_t_1, NULL)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 532, __pyx_L1_error)
  __Pyx_GOTREF(((PyObject *)__pyx_t_2));
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = ((PyObject *)__pyx_t_2);
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":530
 *         return tok_and_val
 * 
 *     def skipping_newlines(self):             # <<<<<<<<<<<<<<
 *         """Iterate over the tokens, skipping newlines."""
 *         return NewlinesIter.__new__(NewlinesIter, self)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.skipping_newlines", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":534
 *         return NewlinesIter.__new__(NewlinesIter, self)
 * 
 *     def expect(self, object token, bint skip_newline=True):             # <<<<<<<<<<<<<<
 *         """Consume the next token, which should be the given type.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_21expect(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_9Tokenizer_20expect[] = "Tokenizer.expect(self, token, bool skip_newline=True)\nConsume the next token, which should be the given type.\n\n        If it is not, this raises an error.\n        If skip_newline is true, newlines will be skipped over. This\n        does not apply if the desired token is newline.\n        ";
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_21expect(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_token = 0;
  int __pyx_v_skip_newline;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("expect (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_token,&__pyx_n_s_skip_newline,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_token)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_skip_newline);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "expect") < 0)) __PYX_ERR(0, 534, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_token = values[0];
    if (values[1]) {
      __pyx_v_skip_newline = __Pyx_PyObject_IsTrue(values[1]); if (unlikely((__pyx_v_skip_newline == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 534, __pyx_L3_error)
    } else {
      __pyx_v_skip_newline = ((int)1);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("expect", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 534, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.expect", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_20expect(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_token, __pyx_v_skip_newline);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_20expect(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_token, int __pyx_v_skip_newline) {
  PyObject *__pyx_v_next_token = NULL;
  PyObject *__pyx_v_value = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  Py_ssize_t __pyx_t_7;
  Py_UCS4 __pyx_t_8;
  __Pyx_RefNannySetupContext("expect", 0);

  /* "srctools/_tokenizer.pyx":541
 *         does not apply if the desired token is newline.
 *         """
 *         if token is NEWLINE:             # <<<<<<<<<<<<<<
 *             skip_newline = False
 * 
 */
  __pyx_t_1 = (__pyx_v_token == __pyx_v_8srctools_10_tokenizer_NEWLINE);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":542
 *         """
 *         if token is NEWLINE:
 *             skip_newline = False             # <<<<<<<<<<<<<<
 * 
 *         next_token, value = <tuple>self.next_token()
 */
    __pyx_v_skip_newline = 0;

    /* "srctools/_tokenizer.pyx":541
 *         does not apply if the desired token is newline.
 *         """
 *         if token is NEWLINE:             # <<<<<<<<<<<<<<
 *             skip_newline = False
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":544
 *             skip_newline = False
 * 
 *         next_token, value = <tuple>self.next_token()             # <<<<<<<<<<<<<<
 * 
 *         while skip_newline and next_token is NEWLINE:
 */
  __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 544, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __pyx_t_3;
  __Pyx_INCREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (likely(__pyx_t_4 != Py_None)) {
    PyObject* sequence = __pyx_t_4;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 544, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
    __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_5);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 544, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 544, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    #endif
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  } else {
    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(0, 544, __pyx_L1_error)
  }
  __pyx_v_next_token = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_value = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "srctools/_tokenizer.pyx":546
 *         next_token, value = <tuple>self.next_token()
 * 
 *         while skip_newline and next_token is NEWLINE:             # <<<<<<<<<<<<<<
 *             next_token, value = <tuple>self.next_token()
 * 
 */
  while (1) {
    __pyx_t_1 = (__pyx_v_skip_newline != 0);
    if (__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_1 = (__pyx_v_next_token == __pyx_v_8srctools_10_tokenizer_NEWLINE);
    __pyx_t_6 = (__pyx_t_1 != 0);
    __pyx_t_2 = __pyx_t_6;
    __pyx_L6_bool_binop_done:;
    if (!__pyx_t_2) break;

    /* "srctools/_tokenizer.pyx":547
 * 
 *         while skip_newline and next_token is NEWLINE:
 *             next_token, value = <tuple>self.next_token()             # <<<<<<<<<<<<<<
 * 
 *         if next_token is not token:
 */
    __pyx_t_4 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(__pyx_v_self); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 547, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __pyx_t_4;
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (likely(__pyx_t_5 != Py_None)) {
      PyObject* sequence = __pyx_t_5;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 547, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_3);
      #else
      __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 547, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 547, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      #endif
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else {
      __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(0, 547, __pyx_L1_error)
    }
    __Pyx_DECREF_SET(__pyx_v_next_token, __pyx_t_4);
    __pyx_t_4 = 0;
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_t_3);
    __pyx_t_3 = 0;
  }

  /* "srctools/_tokenizer.pyx":549
 *             next_token, value = <tuple>self.next_token()
 * 
 *         if next_token is not token:             # <<<<<<<<<<<<<<
 *             raise self._error(f'Expected {token}, but got {next_token}!')
 *         return value
 */
  __pyx_t_2 = (__pyx_v_next_token != __pyx_v_token);
  __pyx_t_6 = (__pyx_t_2 != 0);
  if (unlikely(__pyx_t_6)) {

    /* "srctools/_tokenizer.pyx":550
 * 
 *         if next_token is not token:
 *             raise self._error(f'Expected {token}, but got {next_token}!')             # <<<<<<<<<<<<<<
 *         return value
 * 
 */
    __pyx_t_5 = PyTuple_New(5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 550, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = 0;
    __pyx_t_8 = 127;
    __Pyx_INCREF(__pyx_kp_u_Expected);
    __pyx_t_7 += 9;
    __Pyx_GIVEREF(__pyx_kp_u_Expected);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_kp_u_Expected);
    __pyx_t_3 = __Pyx_PyObject_FormatSimple(__pyx_v_token, __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 550, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_8) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_8;
    __pyx_t_7 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u_but_got);
    __pyx_t_7 += 10;
    __Pyx_GIVEREF(__pyx_kp_u_but_got);
    PyTuple_SET_ITEM(__pyx_t_5, 2, __pyx_kp_u_but_got);
    __pyx_t_3 = __Pyx_PyObject_FormatSimple(__pyx_v_next_token, __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 550, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_8) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_8;
    __pyx_t_7 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_5, 3, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u__5);
    __pyx_t_7 += 1;
    __Pyx_GIVEREF(__pyx_kp_u__5);
    PyTuple_SET_ITEM(__pyx_t_5, 4, __pyx_kp_u__5);
    __pyx_t_3 = __Pyx_PyUnicode_Join(__pyx_t_5, 5, __pyx_t_7, __pyx_t_8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 550, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_9Tokenizer__error(__pyx_v_self, ((PyObject*)__pyx_t_3)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 550, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(0, 550, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":549
 *             next_token, value = <tuple>self.next_token()
 * 
 *         if next_token is not token:             # <<<<<<<<<<<<<<
 *             raise self._error(f'Expected {token}, but got {next_token}!')
 *         return value
 */
  }

  /* "srctools/_tokenizer.pyx":551
 *         if next_token is not token:
 *             raise self._error(f'Expected {token}, but got {next_token}!')
 *         return value             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_value);
  __pyx_r = __pyx_v_value;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":534
 *         return NewlinesIter.__new__(NewlinesIter, self)
 * 
 *     def expect(self, object token, bint skip_newline=True):             # <<<<<<<<<<<<<<
 *         """Consume the next token, which should be the given type.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.expect", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_next_token);
  __Pyx_XDECREF(__pyx_v_value);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":78
 *     cdef object error_type
 * 
 *     cdef public str filename             # <<<<<<<<<<<<<<
 * 
 *     cdef int char_index # Position inside cur_chunk
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_8filename_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_8filename_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8filename___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_8filename___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->filename);
  __pyx_r = __pyx_v_self->filename;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_8filename_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_8filename_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8filename_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8filename_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__set__", 0);
  if (!(likely(PyUnicode_CheckExact(__pyx_v_value))||((__pyx_v_value) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_v_value)->tp_name), 0))) __PYX_ERR(0, 78, __pyx_L1_error)
  __pyx_t_1 = __pyx_v_value;
  __Pyx_INCREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->filename);
  __Pyx_DECREF(__pyx_v_self->filename);
  __pyx_v_self->filename = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.filename.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_8filename_5__del__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_8filename_5__del__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8filename_4__del__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8filename_4__del__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__", 0);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->filename);
  __Pyx_DECREF(__pyx_v_self->filename);
  __pyx_v_self->filename = ((PyObject*)Py_None);

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":82
 *     cdef int char_index # Position inside cur_chunk
 * 
 *     cdef public int line_num             # <<<<<<<<<<<<<<
 *     cdef public bint string_bracket
 *     cdef public bint allow_escapes
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_8line_num_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_8line_num_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8line_num___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_8line_num___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->line_num); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 82, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.line_num.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_8line_num_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_8line_num_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8line_num_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_8line_num_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyInt_As_int(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 82, __pyx_L1_error)
  __pyx_v_self->line_num = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.line_num.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":83
 * 
 *     cdef public int line_num
 *     cdef public bint string_bracket             # <<<<<<<<<<<<<<
 *     cdef public bint allow_escapes
 *     cdef public bint allow_star_comments
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_v_self->string_bracket); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 83, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.string_bracket.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 83, __pyx_L1_error)
  __pyx_v_self->string_bracket = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.string_bracket.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":84
 *     cdef public int line_num
 *     cdef public bint string_bracket
 *     cdef public bint allow_escapes             # <<<<<<<<<<<<<<
 *     cdef public bint allow_star_comments
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_v_self->allow_escapes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_escapes.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 84, __pyx_L1_error)
  __pyx_v_self->allow_escapes = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_escapes.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":85
 *     cdef public bint string_bracket
 *     cdef public bint allow_escapes
 *     cdef public bint allow_star_comments             # <<<<<<<<<<<<<<
 * 
 *     cdef object pushback_tok
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_v_self->allow_star_comments); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 85, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_star_comments.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 85, __pyx_L1_error)
  __pyx_v_self->allow_star_comments = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_star_comments.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":558
 *     cdef Tokenizer tok
 * 
 *     def __cinit__(self, Tokenizer tok not None):             # <<<<<<<<<<<<<<
 *         self.tok = tok
 * 
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_12NewlinesIter_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_12NewlinesIter_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_tok = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_tok,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_tok)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__cinit__") < 0)) __PYX_ERR(0, 558, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_tok = ((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)values[0]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 558, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.NewlinesIter.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_tok), __pyx_ptype_8srctools_10_tokenizer_Tokenizer, 0, "tok", 0))) __PYX_ERR(0, 558, __pyx_L1_error)
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_12NewlinesIter___cinit__(((struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *)__pyx_v_self), __pyx_v_tok);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_12NewlinesIter___cinit__(struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *__pyx_v_self, struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_tok) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "srctools/_tokenizer.pyx":559
 * 
 *     def __cinit__(self, Tokenizer tok not None):
 *         self.tok = tok             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_tok));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_tok));
  __Pyx_GOTREF(__pyx_v_self->tok);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->tok));
  __pyx_v_self->tok = __pyx_v_tok;

  /* "srctools/_tokenizer.pyx":558
 *     cdef Tokenizer tok
 * 
 *     def __cinit__(self, Tokenizer tok not None):             # <<<<<<<<<<<<<<
 *         self.tok = tok
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":561
 *         self.tok = tok
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_12NewlinesIter_3__iter__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_12NewlinesIter_3__iter__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_12NewlinesIter_2__iter__(((struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_12NewlinesIter_2__iter__(struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__", 0);

  /* "srctools/_tokenizer.pyx":562
 * 
 *     def __iter__(self):
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __next__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":561
 *         self.tok = tok
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":564
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         while True:
 *             tok_and_val = self.tok.next_token()
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_12NewlinesIter_5__next__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_12NewlinesIter_5__next__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__next__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_12NewlinesIter_4__next__(((struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_12NewlinesIter_4__next__(struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *__pyx_v_self) {
  PyObject *__pyx_v_tok_and_val = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  __Pyx_RefNannySetupContext("__next__", 0);

  /* "srctools/_tokenizer.pyx":565
 * 
 *     def __next__(self):
 *         while True:             # <<<<<<<<<<<<<<
 *             tok_and_val = self.tok.next_token()
 * 
 */
  while (1) {

    /* "srctools/_tokenizer.pyx":566
 *     def __next__(self):
 *         while True:
 *             tok_and_val = self.tok.next_token()             # <<<<<<<<<<<<<<
 * 
 *             if tok_and_val is EOF_TUP:
 */
    __pyx_t_1 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(__pyx_v_self->tok); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 566, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_XDECREF_SET(__pyx_v_tok_and_val, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "srctools/_tokenizer.pyx":568
 *             tok_and_val = self.tok.next_token()
 * 
 *             if tok_and_val is EOF_TUP:             # <<<<<<<<<<<<<<
 *                 raise StopIteration
 *             elif tok_and_val is not NEWLINE_TUP:
 */
    __pyx_t_2 = (__pyx_v_tok_and_val == __pyx_v_8srctools_10_tokenizer_EOF_TUP);
    __pyx_t_3 = (__pyx_t_2 != 0);
    if (unlikely(__pyx_t_3)) {

      /* "srctools/_tokenizer.pyx":569
 * 
 *             if tok_and_val is EOF_TUP:
 *                 raise StopIteration             # <<<<<<<<<<<<<<
 *             elif tok_and_val is not NEWLINE_TUP:
 *                 return tok_and_val
 */
      __Pyx_Raise(__pyx_builtin_StopIteration, 0, 0, 0);
      __PYX_ERR(0, 569, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":568
 *             tok_and_val = self.tok.next_token()
 * 
 *             if tok_and_val is EOF_TUP:             # <<<<<<<<<<<<<<
 *                 raise StopIteration
 *             elif tok_and_val is not NEWLINE_TUP:
 */
    }

    /* "srctools/_tokenizer.pyx":570
 *             if tok_and_val is EOF_TUP:
 *                 raise StopIteration
 *             elif tok_and_val is not NEWLINE_TUP:             # <<<<<<<<<<<<<<
 *                 return tok_and_val
 * 
 */
    __pyx_t_3 = (__pyx_v_tok_and_val != __pyx_v_8srctools_10_tokenizer_NEWLINE_TUP);
    __pyx_t_2 = (__pyx_t_3 != 0);
    if (__pyx_t_2) {

      /* "srctools/_tokenizer.pyx":571
 *                 raise StopIteration
 *             elif tok_and_val is not NEWLINE_TUP:
 *                 return tok_and_val             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_tok_and_val);
      __pyx_r = __pyx_v_tok_and_val;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":570
 *             if tok_and_val is EOF_TUP:
 *                 raise StopIteration
 *             elif tok_and_val is not NEWLINE_TUP:             # <<<<<<<<<<<<<<
 *                 return tok_and_val
 * 
 */
    }
  }

  /* "srctools/_tokenizer.pyx":564
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         while True:
 *             tok_and_val = self.tok.next_token()
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.NewlinesIter.__next__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tok_and_val);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":573
 *                 return tok_and_val
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle NewlinesIter!')
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_12NewlinesIter_7__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_12NewlinesIter_6__reduce__[] = "NewlinesIter.__reduce__(self)\nThis cannot be pickled - the Python version does not have this class.";
static PyObject *__pyx_pw_8srctools_10_tokenizer_12NewlinesIter_7__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_12NewlinesIter_6__reduce__(((struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_12NewlinesIter_6__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "srctools/_tokenizer.pyx":575
 *     def __reduce__(self):
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle NewlinesIter!')             # <<<<<<<<<<<<<<
 * 
 * # Remove this class from the module, so it's not directly exposed.
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_NotImplementedError, __pyx_tuple__19, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 575, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 575, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":573
 *                 return tok_and_val
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle NewlinesIter!')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.NewlinesIter.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":582
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None):             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_1escape_text(PyObject *__pyx_self, PyObject *__pyx_v_text); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_escape_text[] = "escape_text(unicode text)\nEscape special characters and backslashes, so tokenising reproduces them.\n\n    Specifically, \\, \", tab, and newline.\n    ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_1escape_text = {"escape_text", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_1escape_text, METH_O, __pyx_doc_8srctools_10_tokenizer_escape_text};
static PyObject *__pyx_pw_8srctools_10_tokenizer_1escape_text(PyObject *__pyx_self, PyObject *__pyx_v_text) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("escape_text (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_text), (&PyUnicode_Type), 0, "text", 1))) __PYX_ERR(0, 582, __pyx_L1_error)
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_escape_text(__pyx_self, ((PyObject*)__pyx_v_text));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_escape_text(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_text) {
  PyObject *__pyx_v_enc_text = 0;
  Py_ssize_t __pyx_v_final_len;
  char __pyx_v_letter;
  char *__pyx_v_out_buff;
  int __pyx_v_i;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  char *__pyx_t_4;
  char *__pyx_t_5;
  char *__pyx_t_6;
  char *__pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  char const *__pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  __Pyx_RefNannySetupContext("escape_text", 0);

  /* "srctools/_tokenizer.pyx":588
 *     """
 *     # UTF8 = ASCII for those chars, so we can replace in that form.
 *     cdef bytes enc_text = text.encode('utf8')             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t final_len = len(enc_text)
 *     cdef char letter
 */
  __pyx_t_1 = PyUnicode_AsUTF8String(__pyx_v_text); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 588, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_enc_text = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":589
 *     # UTF8 = ASCII for those chars, so we can replace in that form.
 *     cdef bytes enc_text = text.encode('utf8')
 *     cdef Py_ssize_t final_len = len(enc_text)             # <<<<<<<<<<<<<<
 *     cdef char letter
 *     for letter in enc_text:
 */
  if (unlikely(__pyx_v_enc_text == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 589, __pyx_L1_error)
  }
  __pyx_t_2 = PyBytes_GET_SIZE(__pyx_v_enc_text); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 589, __pyx_L1_error)
  __pyx_v_final_len = __pyx_t_2;

  /* "srctools/_tokenizer.pyx":591
 *     cdef Py_ssize_t final_len = len(enc_text)
 *     cdef char letter
 *     for letter in enc_text:             # <<<<<<<<<<<<<<
 *         if letter in (b'\\', b'"', b'\t', b'\n'):
 *             final_len += 1
 */
  if (unlikely(__pyx_v_enc_text == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' is not iterable");
    __PYX_ERR(0, 591, __pyx_L1_error)
  }
  __Pyx_INCREF(__pyx_v_enc_text);
  __pyx_t_3 = __pyx_v_enc_text;
  __pyx_t_5 = PyBytes_AS_STRING(__pyx_t_3);
  __pyx_t_6 = (__pyx_t_5 + PyBytes_GET_SIZE(__pyx_t_3));
  for (__pyx_t_7 = __pyx_t_5; __pyx_t_7 < __pyx_t_6; __pyx_t_7++) {
    __pyx_t_4 = __pyx_t_7;
    __pyx_v_letter = (__pyx_t_4[0]);

    /* "srctools/_tokenizer.pyx":592
 *     cdef char letter
 *     for letter in enc_text:
 *         if letter in (b'\\', b'"', b'\t', b'\n'):             # <<<<<<<<<<<<<<
 *             final_len += 1
 * 
 */
    switch (__pyx_v_letter) {
      case '\\':
      case '"':
      case '\t':
      case '\n':

      /* "srctools/_tokenizer.pyx":593
 *     for letter in enc_text:
 *         if letter in (b'\\', b'"', b'\t', b'\n'):
 *             final_len += 1             # <<<<<<<<<<<<<<
 * 
 *     cdef char * out_buff
 */
      __pyx_v_final_len = (__pyx_v_final_len + 1);

      /* "srctools/_tokenizer.pyx":592
 *     cdef char letter
 *     for letter in enc_text:
 *         if letter in (b'\\', b'"', b'\t', b'\n'):             # <<<<<<<<<<<<<<
 *             final_len += 1
 * 
 */
      break;
      default: break;
    }
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "srctools/_tokenizer.pyx":596
 * 
 *     cdef char * out_buff
 *     cdef int i = 0             # <<<<<<<<<<<<<<
 *     try:
 *         out_buff = <char *>PyMem_Malloc(final_len+1)
 */
  __pyx_v_i = 0;

  /* "srctools/_tokenizer.pyx":597
 *     cdef char * out_buff
 *     cdef int i = 0
 *     try:             # <<<<<<<<<<<<<<
 *         out_buff = <char *>PyMem_Malloc(final_len+1)
 *         for letter in enc_text:
 */
  /*try:*/ {

    /* "srctools/_tokenizer.pyx":598
 *     cdef int i = 0
 *     try:
 *         out_buff = <char *>PyMem_Malloc(final_len+1)             # <<<<<<<<<<<<<<
 *         for letter in enc_text:
 *             if letter == b'\\':
 */
    __pyx_v_out_buff = ((char *)PyMem_Malloc((__pyx_v_final_len + 1)));

    /* "srctools/_tokenizer.pyx":599
 *     try:
 *         out_buff = <char *>PyMem_Malloc(final_len+1)
 *         for letter in enc_text:             # <<<<<<<<<<<<<<
 *             if letter == b'\\':
 *                 out_buff[i] = b'\\'
 */
    if (unlikely(__pyx_v_enc_text == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' is not iterable");
      __PYX_ERR(0, 599, __pyx_L6_error)
    }
    __Pyx_INCREF(__pyx_v_enc_text);
    __pyx_t_3 = __pyx_v_enc_text;
    __pyx_t_6 = PyBytes_AS_STRING(__pyx_t_3);
    __pyx_t_5 = (__pyx_t_6 + PyBytes_GET_SIZE(__pyx_t_3));
    for (__pyx_t_7 = __pyx_t_6; __pyx_t_7 < __pyx_t_5; __pyx_t_7++) {
      __pyx_t_4 = __pyx_t_7;
      __pyx_v_letter = (__pyx_t_4[0]);

      /* "srctools/_tokenizer.pyx":600
 *         out_buff = <char *>PyMem_Malloc(final_len+1)
 *         for letter in enc_text:
 *             if letter == b'\\':             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *                 i += 1
 */
      switch (__pyx_v_letter) {
        case '\\':

        /* "srctools/_tokenizer.pyx":601
 *         for letter in enc_text:
 *             if letter == b'\\':
 *                 out_buff[i] = b'\\'             # <<<<<<<<<<<<<<
 *                 i += 1
 *                 out_buff[i] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '\\';

        /* "srctools/_tokenizer.pyx":602
 *             if letter == b'\\':
 *                 out_buff[i] = b'\\'
 *                 i += 1             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *             elif letter == b'"':
 */
        __pyx_v_i = (__pyx_v_i + 1);

        /* "srctools/_tokenizer.pyx":603
 *                 out_buff[i] = b'\\'
 *                 i += 1
 *                 out_buff[i] = b'\\'             # <<<<<<<<<<<<<<
 *             elif letter == b'"':
 *                 out_buff[i] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '\\';

        /* "srctools/_tokenizer.pyx":600
 *         out_buff = <char *>PyMem_Malloc(final_len+1)
 *         for letter in enc_text:
 *             if letter == b'\\':             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *                 i += 1
 */
        break;
        case '"':

        /* "srctools/_tokenizer.pyx":605
 *                 out_buff[i] = b'\\'
 *             elif letter == b'"':
 *                 out_buff[i] = b'\\'             # <<<<<<<<<<<<<<
 *                 i += 1
 *                 out_buff[i] = b'"'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '\\';

        /* "srctools/_tokenizer.pyx":606
 *             elif letter == b'"':
 *                 out_buff[i] = b'\\'
 *                 i += 1             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'"'
 *             elif letter == b'\t':
 */
        __pyx_v_i = (__pyx_v_i + 1);

        /* "srctools/_tokenizer.pyx":607
 *                 out_buff[i] = b'\\'
 *                 i += 1
 *                 out_buff[i] = b'"'             # <<<<<<<<<<<<<<
 *             elif letter == b'\t':
 *                 out_buff[i] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '"';

        /* "srctools/_tokenizer.pyx":604
 *                 i += 1
 *                 out_buff[i] = b'\\'
 *             elif letter == b'"':             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *                 i += 1
 */
        break;
        case '\t':

        /* "srctools/_tokenizer.pyx":609
 *                 out_buff[i] = b'"'
 *             elif letter == b'\t':
 *                 out_buff[i] = b'\\'             # <<<<<<<<<<<<<<
 *                 i += 1
 *                 out_buff[i] = b't'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '\\';

        /* "srctools/_tokenizer.pyx":610
 *             elif letter == b'\t':
 *                 out_buff[i] = b'\\'
 *                 i += 1             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b't'
 *             elif letter == b'\n':
 */
        __pyx_v_i = (__pyx_v_i + 1);

        /* "srctools/_tokenizer.pyx":611
 *                 out_buff[i] = b'\\'
 *                 i += 1
 *                 out_buff[i] = b't'             # <<<<<<<<<<<<<<
 *             elif letter == b'\n':
 *                 out_buff[i] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = 't';

        /* "srctools/_tokenizer.pyx":608
 *                 i += 1
 *                 out_buff[i] = b'"'
 *             elif letter == b'\t':             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *                 i += 1
 */
        break;
        case '\n':

        /* "srctools/_tokenizer.pyx":613
 *                 out_buff[i] = b't'
 *             elif letter == b'\n':
 *                 out_buff[i] = b'\\'             # <<<<<<<<<<<<<<
 *                 i += 1
 *                 out_buff[i] = b'n'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '\\';

        /* "srctools/_tokenizer.pyx":614
 *             elif letter == b'\n':
 *                 out_buff[i] = b'\\'
 *                 i += 1             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'n'
 *             else:
 */
        __pyx_v_i = (__pyx_v_i + 1);

        /* "srctools/_tokenizer.pyx":615
 *                 out_buff[i] = b'\\'
 *                 i += 1
 *                 out_buff[i] = b'n'             # <<<<<<<<<<<<<<
 *             else:
 *                 out_buff[i] = letter
 */
        (__pyx_v_out_buff[__pyx_v_i]) = 'n';

        /* "srctools/_tokenizer.pyx":612
 *                 i += 1
 *                 out_buff[i] = b't'
 *             elif letter == b'\n':             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *                 i += 1
 */
        break;
        default:

        /* "srctools/_tokenizer.pyx":617
 *                 out_buff[i] = b'n'
 *             else:
 *                 out_buff[i] = letter             # <<<<<<<<<<<<<<
 *             i += 1
 *         out_buff[final_len] = b'\0'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = __pyx_v_letter;
        break;
      }

      /* "srctools/_tokenizer.pyx":618
 *             else:
 *                 out_buff[i] = letter
 *             i += 1             # <<<<<<<<<<<<<<
 *         out_buff[final_len] = b'\0'
 *         return PyUnicode_FromStringAndSize(out_buff, final_len)
 */
      __pyx_v_i = (__pyx_v_i + 1);
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":619
 *                 out_buff[i] = letter
 *             i += 1
 *         out_buff[final_len] = b'\0'             # <<<<<<<<<<<<<<
 *         return PyUnicode_FromStringAndSize(out_buff, final_len)
 *     finally:
 */
    (__pyx_v_out_buff[__pyx_v_final_len]) = '\x00';

    /* "srctools/_tokenizer.pyx":620
 *             i += 1
 *         out_buff[final_len] = b'\0'
 *         return PyUnicode_FromStringAndSize(out_buff, final_len)             # <<<<<<<<<<<<<<
 *     finally:
 *         PyMem_Free(out_buff)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_1 = PyUnicode_FromStringAndSize(__pyx_v_out_buff, __pyx_v_final_len); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 620, __pyx_L6_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    goto __pyx_L5_return;
  }

  /* "srctools/_tokenizer.pyx":622
 *         return PyUnicode_FromStringAndSize(out_buff, final_len)
 *     finally:
 *         PyMem_Free(out_buff)             # <<<<<<<<<<<<<<
 */
  /*finally:*/ {
    __pyx_L6_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0;
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_11, &__pyx_t_12, &__pyx_t_13) < 0)) __Pyx_ErrFetch(&__pyx_t_11, &__pyx_t_12, &__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_11);
      __Pyx_XGOTREF(__pyx_t_12);
      __Pyx_XGOTREF(__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_14);
      __Pyx_XGOTREF(__pyx_t_15);
      __Pyx_XGOTREF(__pyx_t_16);
      __pyx_t_8 = __pyx_lineno; __pyx_t_9 = __pyx_clineno; __pyx_t_10 = __pyx_filename;
      {
        PyMem_Free(__pyx_v_out_buff);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_14);
        __Pyx_XGIVEREF(__pyx_t_15);
        __Pyx_XGIVEREF(__pyx_t_16);
        __Pyx_ExceptionReset(__pyx_t_14, __pyx_t_15, __pyx_t_16);
      }
      __Pyx_XGIVEREF(__pyx_t_11);
      __Pyx_XGIVEREF(__pyx_t_12);
      __Pyx_XGIVEREF(__pyx_t_13);
      __Pyx_ErrRestore(__pyx_t_11, __pyx_t_12, __pyx_t_13);
      __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0;
      __pyx_lineno = __pyx_t_8; __pyx_clineno = __pyx_t_9; __pyx_filename = __pyx_t_10;
      goto __pyx_L1_error;
    }
    __pyx_L5_return: {
      __pyx_t_16 = __pyx_r;
      __pyx_r = 0;
      PyMem_Free(__pyx_v_out_buff);
      __pyx_r = __pyx_t_16;
      __pyx_t_16 = 0;
      goto __pyx_L0;
    }
  }

  /* "srctools/_tokenizer.pyx":582
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None):             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("srctools._tokenizer.escape_text", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_enc_text);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer __pyx_vtable_8srctools_10_tokenizer_Tokenizer;

static PyObject *__pyx_tp_new_8srctools_10_tokenizer_Tokenizer(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p;
  PyObject *o;
  o = (*t->tp_alloc)(t, 0);
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o);
  p->__pyx_vtab = __pyx_vtabptr_8srctools_10_tokenizer_Tokenizer;
  p->cur_chunk = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->chunk_iter = Py_None; Py_INCREF(Py_None);
  p->error_type = Py_None; Py_INCREF(Py_None);
  p->filename = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->pushback_tok = Py_None; Py_INCREF(Py_None);
  p->pushback_val = Py_None; Py_INCREF(Py_None);
  if (unlikely(__pyx_pw_8srctools_10_tokenizer_9Tokenizer_1__cinit__(o, __pyx_empty_tuple, NULL) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer_Tokenizer(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o;
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_pw_8srctools_10_tokenizer_9Tokenizer_3__dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  Py_CLEAR(p->cur_chunk);
  Py_CLEAR(p->chunk_iter);
  Py_CLEAR(p->error_type);
  Py_CLEAR(p->filename);
  Py_CLEAR(p->pushback_tok);
  Py_CLEAR(p->pushback_val);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer_Tokenizer(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o;
  if (p->chunk_iter) {
    e = (*v)(p->chunk_iter, a); if (e) return e;
  }
  if (p->error_type) {
    e = (*v)(p->error_type, a); if (e) return e;
  }
  if (p->pushback_tok) {
    e = (*v)(p->pushback_tok, a); if (e) return e;
  }
  if (p->pushback_val) {
    e = (*v)(p->pushback_val, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer_Tokenizer(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o;
  tmp = ((PyObject*)p->chunk_iter);
  p->chunk_iter = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->error_type);
  p->error_type = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->pushback_tok);
  p->pushback_tok = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->pushback_val);
  p->pushback_val = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_filename(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_8filename_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_filename(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_8filename_3__set__(o, v);
  }
  else {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_8filename_5__del__(o);
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_line_num(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_8line_num_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_line_num(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_8line_num_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_string_bracket(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_string_bracket(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer_Tokenizer[] = {
  {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_9Tokenizer_7__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_9Tokenizer_6__reduce__},
  {"error", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_9Tokenizer_9error, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_9Tokenizer_8error},
  {"push_back", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_9Tokenizer_15push_back, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_9Tokenizer_14push_back},
  {"peek", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_9Tokenizer_17peek, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_9Tokenizer_16peek},
  {"skipping_newlines", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_9Tokenizer_19skipping_newlines, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_9Tokenizer_18skipping_newlines},
  {"expect", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_9Tokenizer_21expect, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_9Tokenizer_20expect},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_8srctools_10_tokenizer_Tokenizer[] = {
  {(char *)"filename", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_filename, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_filename, (char *)"filename: unicode", 0},
  {(char *)"line_num", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_line_num, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_line_num, (char *)"line_num: 'int'", 0},
  {(char *)"string_bracket", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_string_bracket, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_string_bracket, (char *)"string_bracket: 'bool'", 0},
  {(char *)"allow_escapes", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes, (char *)"allow_escapes: 'bool'", 0},
  {(char *)"allow_star_comments", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments, (char *)"allow_star_comments: 'bool'", 0},
  {0, 0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer_Tokenizer = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer.Tokenizer", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer_Tokenizer, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  __pyx_pw_8srctools_10_tokenizer_9Tokenizer_11__call__, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "Tokenizer(data, filename=None, error=None, bool string_bracket=False, bool allow_escapes=True, bool allow_star_comments=False)\nProcesses text data into groups of tokens.\n\n    This mainly groups strings and removes comments.\n\n    Due to many inconsistencies in Valve's parsing of files,\n    several options are available to control whether different\n    syntaxes are accepted:\n        * string_bracket parses [bracket] blocks as a single string-like block.\n          If disabled these are parsed as BRACK_OPEN, STRING, BRACK_CLOSE.\n        * allow_escapes controls whether \\n-style escapes are expanded.\n        * allow_star_comments if enabled allows /* */ comments.\n    ", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer_Tokenizer, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer_Tokenizer, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13__iter__, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_8srctools_10_tokenizer_Tokenizer, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_8srctools_10_tokenizer_Tokenizer, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_8srctools_10_tokenizer_9Tokenizer_5__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer_Tokenizer, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static PyObject *__pyx_tp_new_8srctools_10_tokenizer_NewlinesIter(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *)o);
  p->tok = ((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)Py_None); Py_INCREF(Py_None);
  if (unlikely(__pyx_pw_8srctools_10_tokenizer_12NewlinesIter_1__cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer_NewlinesIter(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *p = (struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->tok);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer_NewlinesIter(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *p = (struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *)o;
  if (p->tok) {
    e = (*v)(((PyObject *)p->tok), a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer_NewlinesIter(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *p = (struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter *)o;
  tmp = ((PyObject*)p->tok);
  p->tok = ((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_12NewlinesIter_5__next__(PyObject *self, CYTHON_UNUSED PyObject *arg) {return __pyx_pw_8srctools_10_tokenizer_12NewlinesIter_5__next__(self);}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer_NewlinesIter[] = {
  {"__next__", (PyCFunction)__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_12NewlinesIter_5__next__, METH_NOARGS|METH_COEXIST, 0},
  {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_12NewlinesIter_7__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_12NewlinesIter_6__reduce__},
  {0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer_NewlinesIter = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer.NewlinesIter", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer_NewlinesIter), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer_NewlinesIter, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "Iterate over the tokens, skipping newlines.", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer_NewlinesIter, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer_NewlinesIter, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  __pyx_pw_8srctools_10_tokenizer_12NewlinesIter_3__iter__, /*tp_iter*/
  __pyx_pw_8srctools_10_tokenizer_12NewlinesIter_5__next__, /*tp_iternext*/
  __pyx_methods_8srctools_10_tokenizer_NewlinesIter, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer_NewlinesIter, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static PyMethodDef __pyx_methods[] = {
  {0, 0, 0, 0}
};

#if PY_MAJOR_VERSION >= 3
#if CYTHON_PEP489_MULTI_PHASE_INIT
static PyObject* __pyx_pymod_create(PyObject *spec, PyModuleDef *def); /*proto*/
static int __pyx_pymod_exec__tokenizer(PyObject* module); /*proto*/
static PyModuleDef_Slot __pyx_moduledef_slots[] = {
  {Py_mod_create, (void*)__pyx_pymod_create},
  {Py_mod_exec, (void*)__pyx_pymod_exec__tokenizer},
  {0, NULL}
};
#endif

static struct PyModuleDef __pyx_moduledef = {
    PyModuleDef_HEAD_INIT,
    "_tokenizer",
    __pyx_k_Cython_version_of_the_Tokenizer, /* m_doc */
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    0, /* m_size */
  #else
    -1, /* m_size */
  #endif
    __pyx_methods /* m_methods */,
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    __pyx_moduledef_slots, /* m_slots */
  #else
    NULL, /* m_reload */
  #endif
    NULL, /* m_traverse */
    NULL, /* m_clear */
    NULL /* m_free */
};
#endif
#ifndef CYTHON_SMALL_CODE
#if defined(__clang__)
    #define CYTHON_SMALL_CODE
#elif defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 3))
    #define CYTHON_SMALL_CODE __attribute__((cold))
#else
    #define CYTHON_SMALL_CODE
#endif
#endif

static __Pyx_StringTabEntry __pyx_string_tab[] = {
  {&__pyx_n_s_AttributeError, __pyx_k_AttributeError, sizeof(__pyx_k_AttributeError), 0, 0, 1, 1},
  {&__pyx_n_s_BRACE_CLOSE, __pyx_k_BRACE_CLOSE, sizeof(__pyx_k_BRACE_CLOSE), 0, 0, 1, 1},
  {&__pyx_n_s_BRACE_OPEN, __pyx_k_BRACE_OPEN, sizeof(__pyx_k_BRACE_OPEN), 0, 0, 1, 1},
  {&__pyx_n_s_BRACK_CLOSE, __pyx_k_BRACK_CLOSE, sizeof(__pyx_k_BRACK_CLOSE), 0, 0, 1, 1},
  {&__pyx_n_s_BRACK_OPEN, __pyx_k_BRACK_OPEN, sizeof(__pyx_k_BRACK_OPEN), 0, 0, 1, 1},
  {&__pyx_n_s_COLON, __pyx_k_COLON, sizeof(__pyx_k_COLON), 0, 0, 1, 1},
  {&__pyx_kp_u_Cannot_nest_brackets, __pyx_k_Cannot_nest_brackets, sizeof(__pyx_k_Cannot_nest_brackets), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_nest_brackets_2, __pyx_k_Cannot_nest_brackets_2, sizeof(__pyx_k_Cannot_nest_brackets_2), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_parse_binary_data, __pyx_k_Cannot_parse_binary_data, sizeof(__pyx_k_Cannot_parse_binary_data), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_parse_binary_data_Decode, __pyx_k_Cannot_parse_binary_data_Decode, sizeof(__pyx_k_Cannot_parse_binary_data_Decode), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_pickle_NewlinesIter, __pyx_k_Cannot_pickle_NewlinesIter, sizeof(__pyx_k_Cannot_pickle_NewlinesIter), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_pickle_Tokenizers, __pyx_k_Cannot_pickle_Tokenizers, sizeof(__pyx_k_Cannot_pickle_Tokenizers), 0, 1, 0, 0},
  {&__pyx_kp_u_Data_was_not_a_string, __pyx_k_Data_was_not_a_string, sizeof(__pyx_k_Data_was_not_a_string), 0, 1, 0, 0},
  {&__pyx_n_s_EOF, __pyx_k_EOF, sizeof(__pyx_k_EOF), 0, 0, 1, 1},
  {&__pyx_n_s_EQUALS, __pyx_k_EQUALS, sizeof(__pyx_k_EQUALS), 0, 0, 1, 1},
  {&__pyx_kp_u_Expected, __pyx_k_Expected, sizeof(__pyx_k_Expected), 0, 1, 0, 0},
  {&__pyx_n_s_ImportError, __pyx_k_ImportError, sizeof(__pyx_k_ImportError), 0, 0, 1, 1},
  {&__pyx_kp_u_Invalid_error_instance, __pyx_k_Invalid_error_instance, sizeof(__pyx_k_Invalid_error_instance), 0, 1, 0, 0},
  {&__pyx_kp_u_Invalid_value_provided, __pyx_k_Invalid_value_provided, sizeof(__pyx_k_Invalid_value_provided), 0, 1, 0, 0},
  {&__pyx_n_s_NEWLINE, __pyx_k_NEWLINE, sizeof(__pyx_k_NEWLINE), 0, 0, 1, 1},
  {&__pyx_n_s_NewlinesIter, __pyx_k_NewlinesIter, sizeof(__pyx_k_NewlinesIter), 0, 0, 1, 1},
  {&__pyx_n_u_NewlinesIter, __pyx_k_NewlinesIter, sizeof(__pyx_k_NewlinesIter), 0, 1, 0, 1},
  {&__pyx_kp_u_No_open_to_close_with, __pyx_k_No_open_to_close_with, sizeof(__pyx_k_No_open_to_close_with), 0, 1, 0, 0},
  {&__pyx_kp_u_No_open_to_close_with_2, __pyx_k_No_open_to_close_with_2, sizeof(__pyx_k_No_open_to_close_with_2), 0, 1, 0, 0},
  {&__pyx_n_s_NotImplementedError, __pyx_k_NotImplementedError, sizeof(__pyx_k_NotImplementedError), 0, 0, 1, 1},
  {&__pyx_n_s_PAREN_ARGS, __pyx_k_PAREN_ARGS, sizeof(__pyx_k_PAREN_ARGS), 0, 0, 1, 1},
  {&__pyx_n_s_PLUS, __pyx_k_PLUS, sizeof(__pyx_k_PLUS), 0, 0, 1, 1},
  {&__pyx_n_s_PROP_FLAG, __pyx_k_PROP_FLAG, sizeof(__pyx_k_PROP_FLAG), 0, 0, 1, 1},
  {&__pyx_kp_u_Reached_end_of_line_without_clos, __pyx_k_Reached_end_of_line_without_clos, sizeof(__pyx_k_Reached_end_of_line_without_clos), 0, 1, 0, 0},
  {&__pyx_n_s_STRING, __pyx_k_STRING, sizeof(__pyx_k_STRING), 0, 0, 1, 1},
  {&__pyx_kp_u_Single_slash_found_instead_of_tw, __pyx_k_Single_slash_found_instead_of_tw, sizeof(__pyx_k_Single_slash_found_instead_of_tw), 0, 1, 0, 0},
  {&__pyx_kp_u_Single_slash_found_instead_of_tw_2, __pyx_k_Single_slash_found_instead_of_tw_2, sizeof(__pyx_k_Single_slash_found_instead_of_tw_2), 0, 1, 0, 0},
  {&__pyx_n_s_StopIteration, __pyx_k_StopIteration, sizeof(__pyx_k_StopIteration), 0, 0, 1, 1},
  {&__pyx_n_s_Token, __pyx_k_Token, sizeof(__pyx_k_Token), 0, 0, 1, 1},
  {&__pyx_n_s_TokenSyntaxError, __pyx_k_TokenSyntaxError, sizeof(__pyx_k_TokenSyntaxError), 0, 0, 1, 1},
  {&__pyx_kp_u_Token_already_pushed_back, __pyx_k_Token_already_pushed_back, sizeof(__pyx_k_Token_already_pushed_back), 0, 1, 0, 0},
  {&__pyx_n_s_Tokenizer, __pyx_k_Tokenizer, sizeof(__pyx_k_Tokenizer), 0, 0, 1, 1},
  {&__pyx_n_s_TypeError, __pyx_k_TypeError, sizeof(__pyx_k_TypeError), 0, 0, 1, 1},
  {&__pyx_kp_u_Unclosed_comment_starting_on_lin, __pyx_k_Unclosed_comment_starting_on_lin, sizeof(__pyx_k_Unclosed_comment_starting_on_lin), 0, 1, 0, 0},
  {&__pyx_kp_u_Unexpected_character, __pyx_k_Unexpected_character, sizeof(__pyx_k_Unexpected_character), 0, 1, 0, 0},
  {&__pyx_kp_u_Unexpected_token, __pyx_k_Unexpected_token, sizeof(__pyx_k_Unexpected_token), 0, 1, 0, 0},
  {&__pyx_kp_u_Unknown_token_value, __pyx_k_Unknown_token_value, sizeof(__pyx_k_Unknown_token_value), 0, 1, 0, 0},
  {&__pyx_kp_u_Unterminated_parentheses, __pyx_k_Unterminated_parentheses, sizeof(__pyx_k_Unterminated_parentheses), 0, 1, 0, 0},
  {&__pyx_kp_u_Unterminated_string, __pyx_k_Unterminated_string, sizeof(__pyx_k_Unterminated_string), 0, 1, 0, 0},
  {&__pyx_n_s_ValueError, __pyx_k_ValueError, sizeof(__pyx_k_ValueError), 0, 0, 1, 1},
  {&__pyx_kp_u__10, __pyx_k__10, sizeof(__pyx_k__10), 0, 1, 0, 0},
  {&__pyx_kp_u__11, __pyx_k__11, sizeof(__pyx_k__11), 0, 1, 0, 0},
  {&__pyx_kp_u__12, __pyx_k__12, sizeof(__pyx_k__12), 0, 1, 0, 0},
  {&__pyx_kp_u__13, __pyx_k__13, sizeof(__pyx_k__13), 0, 1, 0, 0},
  {&__pyx_kp_u__14, __pyx_k__14, sizeof(__pyx_k__14), 0, 1, 0, 0},
  {&__pyx_kp_u__15, __pyx_k__15, sizeof(__pyx_k__15), 0, 1, 0, 0},
  {&__pyx_kp_u__16, __pyx_k__16, sizeof(__pyx_k__16), 0, 1, 0, 0},
  {&__pyx_kp_u__17, __pyx_k__17, sizeof(__pyx_k__17), 0, 1, 0, 0},
  {&__pyx_kp_u__2, __pyx_k__2, sizeof(__pyx_k__2), 0, 1, 0, 0},
  {&__pyx_kp_u__3, __pyx_k__3, sizeof(__pyx_k__3), 0, 1, 0, 0},
  {&__pyx_kp_u__5, __pyx_k__5, sizeof(__pyx_k__5), 0, 1, 0, 0},
  {&__pyx_kp_u__8, __pyx_k__8, sizeof(__pyx_k__8), 0, 1, 0, 0},
  {&__pyx_n_s_allow_escapes, __pyx_k_allow_escapes, sizeof(__pyx_k_allow_escapes), 0, 0, 1, 1},
  {&__pyx_n_s_allow_star_comments, __pyx_k_allow_star_comments, sizeof(__pyx_k_allow_star_comments), 0, 0, 1, 1},
  {&__pyx_kp_u_but_got, __pyx_k_but_got, sizeof(__pyx_k_but_got), 0, 1, 0, 0},
  {&__pyx_n_s_cline_in_traceback, __pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 0, 1, 1},
  {&__pyx_n_s_data, __pyx_k_data, sizeof(__pyx_k_data), 0, 0, 1, 1},
  {&__pyx_n_s_enc_text, __pyx_k_enc_text, sizeof(__pyx_k_enc_text), 0, 0, 1, 1},
  {&__pyx_n_s_error, __pyx_k_error, sizeof(__pyx_k_error), 0, 0, 1, 1},
  {&__pyx_n_s_escape_text, __pyx_k_escape_text, sizeof(__pyx_k_escape_text), 0, 0, 1, 1},
  {&__pyx_n_s_filename, __pyx_k_filename, sizeof(__pyx_k_filename), 0, 0, 1, 1},
  {&__pyx_n_s_final_len, __pyx_k_final_len, sizeof(__pyx_k_final_len), 0, 0, 1, 1},
  {&__pyx_kp_u_for, __pyx_k_for, sizeof(__pyx_k_for), 0, 1, 0, 0},
  {&__pyx_n_s_format, __pyx_k_format, sizeof(__pyx_k_format), 0, 0, 1, 1},
  {&__pyx_n_s_fspath, __pyx_k_fspath, sizeof(__pyx_k_fspath), 0, 0, 1, 1},
  {&__pyx_n_s_i, __pyx_k_i, sizeof(__pyx_k_i), 0, 0, 1, 1},
  {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
  {&__pyx_kp_u_is_not_a_Token, __pyx_k_is_not_a_Token, sizeof(__pyx_k_is_not_a_Token), 0, 1, 0, 0},
  {&__pyx_n_s_letter, __pyx_k_letter, sizeof(__pyx_k_letter), 0, 0, 1, 1},
  {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
  {&__pyx_n_s_message, __pyx_k_message, sizeof(__pyx_k_message), 0, 0, 1, 1},
  {&__pyx_n_s_name, __pyx_k_name, sizeof(__pyx_k_name), 0, 0, 1, 1},
  {&__pyx_n_s_name_2, __pyx_k_name_2, sizeof(__pyx_k_name_2), 0, 0, 1, 1},
  {&__pyx_n_s_os, __pyx_k_os, sizeof(__pyx_k_os), 0, 0, 1, 1},
  {&__pyx_n_s_out_buff, __pyx_k_out_buff, sizeof(__pyx_k_out_buff), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_vtable, __pyx_k_pyx_vtable, sizeof(__pyx_k_pyx_vtable), 0, 0, 1, 1},
  {&__pyx_n_s_skip_newline, __pyx_k_skip_newline, sizeof(__pyx_k_skip_newline), 0, 0, 1, 1},
  {&__pyx_n_s_srctools__tokenizer, __pyx_k_srctools__tokenizer, sizeof(__pyx_k_srctools__tokenizer), 0, 0, 1, 1},
  {&__pyx_kp_s_srctools__tokenizer_pyx, __pyx_k_srctools__tokenizer_pyx, sizeof(__pyx_k_srctools__tokenizer_pyx), 0, 0, 1, 0},
  {&__pyx_n_s_srctools_tokenizer, __pyx_k_srctools_tokenizer, sizeof(__pyx_k_srctools_tokenizer), 0, 0, 1, 1},
  {&__pyx_n_s_string_bracket, __pyx_k_string_bracket, sizeof(__pyx_k_string_bracket), 0, 0, 1, 1},
  {&__pyx_kp_u_style_comments_are_not_allowed, __pyx_k_style_comments_are_not_allowed, sizeof(__pyx_k_style_comments_are_not_allowed), 0, 1, 0, 0},
  {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
  {&__pyx_n_s_text, __pyx_k_text, sizeof(__pyx_k_text), 0, 0, 1, 1},
  {&__pyx_n_s_tok, __pyx_k_tok, sizeof(__pyx_k_tok), 0, 0, 1, 1},
  {&__pyx_n_s_token, __pyx_k_token, sizeof(__pyx_k_token), 0, 0, 1, 1},
  {&__pyx_n_s_value, __pyx_k_value, sizeof(__pyx_k_value), 0, 0, 1, 1},
  {0, 0, 0, 0, 0, 0, 0}
};
static CYTHON_SMALL_CODE int __Pyx_InitCachedBuiltins(void) {
  __pyx_builtin_ImportError = __Pyx_GetBuiltinName(__pyx_n_s_ImportError); if (!__pyx_builtin_ImportError) __PYX_ERR(0, 14, __pyx_L1_error)
  __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(0, 114, __pyx_L1_error)
  __pyx_builtin_AttributeError = __Pyx_GetBuiltinName(__pyx_n_s_AttributeError); if (!__pyx_builtin_AttributeError) __PYX_ERR(0, 144, __pyx_L1_error)
  __pyx_builtin_TypeError = __Pyx_GetBuiltinName(__pyx_n_s_TypeError); if (!__pyx_builtin_TypeError) __PYX_ERR(0, 152, __pyx_L1_error)
  __pyx_builtin_NotImplementedError = __Pyx_GetBuiltinName(__pyx_n_s_NotImplementedError); if (!__pyx_builtin_NotImplementedError) __PYX_ERR(0, 169, __pyx_L1_error)
  __pyx_builtin_StopIteration = __Pyx_GetBuiltinName(__pyx_n_s_StopIteration); if (!__pyx_builtin_StopIteration) __PYX_ERR(0, 569, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_InitCachedConstants(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "srctools/_tokenizer.pyx":114
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):
 *             raise ValueError(             # <<<<<<<<<<<<<<
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 *                 'or wrap in io.TextIOWrapper() to decode gradually.'
 */
  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_u_Cannot_parse_binary_data_Decode); if (unlikely(!__pyx_tuple_)) __PYX_ERR(0, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple_);
  __Pyx_GIVEREF(__pyx_tuple_);

  /* "srctools/_tokenizer.pyx":169
 *         There is also the issue with recreating the C/Python versions.
 *         """
 *         raise NotImplementedError('Cannot pickle Tokenizers!')             # <<<<<<<<<<<<<<
 * 
 *     def error(self, message, *args):
 */
  __pyx_tuple__4 = PyTuple_Pack(1, __pyx_kp_u_Cannot_pickle_Tokenizers); if (unlikely(!__pyx_tuple__4)) __PYX_ERR(0, 169, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__4);
  __Pyx_GIVEREF(__pyx_tuple__4);

  /* "srctools/_tokenizer.pyx":234
 * 
 *         if isinstance(chunk_obj, bytes):
 *             raise ValueError('Cannot parse binary data!')             # <<<<<<<<<<<<<<
 *         if not isinstance(chunk_obj, str):
 *             raise ValueError("Data was not a string!")
 */
  __pyx_tuple__6 = PyTuple_Pack(1, __pyx_kp_u_Cannot_parse_binary_data); if (unlikely(!__pyx_tuple__6)) __PYX_ERR(0, 234, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__6);
  __Pyx_GIVEREF(__pyx_tuple__6);

  /* "srctools/_tokenizer.pyx":236
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):
 *             raise ValueError("Data was not a string!")             # <<<<<<<<<<<<<<
 * 
 *         self.cur_chunk = chunk = <str>chunk_obj
 */
  __pyx_tuple__7 = PyTuple_Pack(1, __pyx_kp_u_Data_was_not_a_string); if (unlikely(!__pyx_tuple__7)) __PYX_ERR(0, 236, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__7);
  __Pyx_GIVEREF(__pyx_tuple__7);

  /* "srctools/_tokenizer.pyx":247
 *         for chunk_obj in self.chunk_iter:
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')             # <<<<<<<<<<<<<<
 *             if not isinstance(chunk_obj, str):
 *                 raise ValueError("Data was not a string!")
 */
  __pyx_tuple__6 = PyTuple_Pack(1, __pyx_kp_u_Cannot_parse_binary_data); if (unlikely(!__pyx_tuple__6)) __PYX_ERR(0, 247, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__6);
  __Pyx_GIVEREF(__pyx_tuple__6);

  /* "srctools/_tokenizer.pyx":249
 *                 raise ValueError('Cannot parse binary data!')
 *             if not isinstance(chunk_obj, str):
 *                 raise ValueError("Data was not a string!")             # <<<<<<<<<<<<<<
 * 
 *             chunk = <str>chunk_obj
 */
  __pyx_tuple__7 = PyTuple_Pack(1, __pyx_kp_u_Data_was_not_a_string); if (unlikely(!__pyx_tuple__7)) __PYX_ERR(0, 249, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__7);
  __Pyx_GIVEREF(__pyx_tuple__7);

  /* "srctools/_tokenizer.pyx":477
 *         """
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')             # <<<<<<<<<<<<<<
 *         if not isinstance(tok, Token):
 *             raise ValueError(repr(tok) + ' is not a Token!')
 */
  __pyx_tuple__9 = PyTuple_Pack(1, __pyx_kp_u_Token_already_pushed_back); if (unlikely(!__pyx_tuple__9)) __PYX_ERR(0, 477, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__9);
  __Pyx_GIVEREF(__pyx_tuple__9);

  /* "srctools/_tokenizer.pyx":505
 *             real_value = '+'
 *         else:
 *             raise ValueError('Unknown token value!')             # <<<<<<<<<<<<<<
 * 
 *         # If no value provided, use the default (operators)
 */
  __pyx_tuple__18 = PyTuple_Pack(1, __pyx_kp_u_Unknown_token_value); if (unlikely(!__pyx_tuple__18)) __PYX_ERR(0, 505, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__18);
  __Pyx_GIVEREF(__pyx_tuple__18);

  /* "srctools/_tokenizer.pyx":575
 *     def __reduce__(self):
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle NewlinesIter!')             # <<<<<<<<<<<<<<
 * 
 * # Remove this class from the module, so it's not directly exposed.
 */
  __pyx_tuple__19 = PyTuple_Pack(1, __pyx_kp_u_Cannot_pickle_NewlinesIter); if (unlikely(!__pyx_tuple__19)) __PYX_ERR(0, 575, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__19);
  __Pyx_GIVEREF(__pyx_tuple__19);

  /* "srctools/_tokenizer.pyx":582
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None):             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */
  __pyx_tuple__20 = PyTuple_Pack(6, __pyx_n_s_text, __pyx_n_s_enc_text, __pyx_n_s_final_len, __pyx_n_s_letter, __pyx_n_s_out_buff, __pyx_n_s_i); if (unlikely(!__pyx_tuple__20)) __PYX_ERR(0, 582, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__20);
  __Pyx_GIVEREF(__pyx_tuple__20);
  __pyx_codeobj__21 = (PyObject*)__Pyx_PyCode_New(1, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__20, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_escape_text, 582, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__21)) __PYX_ERR(0, 582, __pyx_L1_error)
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_InitGlobals(void) {
  if (__Pyx_InitStrings(__pyx_string_tab) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  return 0;
  __pyx_L1_error:;
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_modinit_global_init_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_export_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_export_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_init_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_import_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_import_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_import_code(void); /*proto*/

static int __Pyx_modinit_global_init_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_global_init_code", 0);
  /*--- Global init code ---*/
  __pyx_v_8srctools_10_tokenizer__conv_path = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_Token = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_TokenSyntaxError = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_STRING = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_PAREN_ARGS = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_PROP_FLAG = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_EOF = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_NEWLINE = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_EMPTY_ITER = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_EOF_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_NEWLINE_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_COLON_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_EQUALS_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_PLUS_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_variable_export_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_export_code", 0);
  /*--- Variable export code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_export_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_export_code", 0);
  /*--- Function export code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_type_init_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_init_code", 0);
  /*--- Type init code ---*/
  __pyx_vtabptr_8srctools_10_tokenizer_Tokenizer = &__pyx_vtable_8srctools_10_tokenizer_Tokenizer;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer._error = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, PyObject *))__pyx_f_8srctools_10_tokenizer_9Tokenizer__error;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.buf_reset = (void (*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.buf_add_char = (void (*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, Py_UCS4))__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.buf_get_text = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer._next_char = (Py_UCS4 (*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.next_token = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer_Tokenizer) < 0) __PYX_ERR(0, 60, __pyx_L1_error)
  __pyx_type_8srctools_10_tokenizer_Tokenizer.tp_print = 0;
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer_Tokenizer.tp_dictoffset && __pyx_type_8srctools_10_tokenizer_Tokenizer.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer_Tokenizer.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
  }
  #if CYTHON_COMPILING_IN_CPYTHON
  {
    PyObject *wrapper = PyObject_GetAttrString((PyObject *)&__pyx_type_8srctools_10_tokenizer_Tokenizer, "__call__"); if (unlikely(!wrapper)) __PYX_ERR(0, 60, __pyx_L1_error)
    if (Py_TYPE(wrapper) == &PyWrapperDescr_Type) {
      __pyx_wrapperbase_8srctools_10_tokenizer_9Tokenizer_10__call__ = *((PyWrapperDescrObject *)wrapper)->d_base;
      __pyx_wrapperbase_8srctools_10_tokenizer_9Tokenizer_10__call__.doc = __pyx_doc_8srctools_10_tokenizer_9Tokenizer_10__call__;
      ((PyWrapperDescrObject *)wrapper)->d_base = &__pyx_wrapperbase_8srctools_10_tokenizer_9Tokenizer_10__call__;
    }
  }
  #endif
  if (__Pyx_SetVtable(__pyx_type_8srctools_10_tokenizer_Tokenizer.tp_dict, __pyx_vtabptr_8srctools_10_tokenizer_Tokenizer) < 0) __PYX_ERR(0, 60, __pyx_L1_error)
  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_Tokenizer, (PyObject *)&__pyx_type_8srctools_10_tokenizer_Tokenizer) < 0) __PYX_ERR(0, 60, __pyx_L1_error)
  __pyx_ptype_8srctools_10_tokenizer_Tokenizer = &__pyx_type_8srctools_10_tokenizer_Tokenizer;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer_NewlinesIter) < 0) __PYX_ERR(0, 554, __pyx_L1_error)
  __pyx_type_8srctools_10_tokenizer_NewlinesIter.tp_print = 0;
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer_NewlinesIter.tp_dictoffset && __pyx_type_8srctools_10_tokenizer_NewlinesIter.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer_NewlinesIter.tp_getattro = __Pyx_PyObject_GenericGetAttr;
  }
  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_NewlinesIter, (PyObject *)&__pyx_type_8srctools_10_tokenizer_NewlinesIter) < 0) __PYX_ERR(0, 554, __pyx_L1_error)
  __pyx_ptype_8srctools_10_tokenizer_NewlinesIter = &__pyx_type_8srctools_10_tokenizer_NewlinesIter;
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_modinit_type_import_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_import_code", 0);
  /*--- Type import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_variable_import_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_import_code", 0);
  /*--- Variable import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_import_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_import_code", 0);
  /*--- Function import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}


#if PY_MAJOR_VERSION < 3
#ifdef CYTHON_NO_PYINIT_EXPORT
#define __Pyx_PyMODINIT_FUNC void
#else
#define __Pyx_PyMODINIT_FUNC PyMODINIT_FUNC
#endif
#else
#ifdef CYTHON_NO_PYINIT_EXPORT
#define __Pyx_PyMODINIT_FUNC PyObject *
#else
#define __Pyx_PyMODINIT_FUNC PyMODINIT_FUNC
#endif
#endif


#if PY_MAJOR_VERSION < 3
__Pyx_PyMODINIT_FUNC init_tokenizer(void) CYTHON_SMALL_CODE; /*proto*/
__Pyx_PyMODINIT_FUNC init_tokenizer(void)
#else
__Pyx_PyMODINIT_FUNC PyInit__tokenizer(void) CYTHON_SMALL_CODE; /*proto*/
__Pyx_PyMODINIT_FUNC PyInit__tokenizer(void)
#if CYTHON_PEP489_MULTI_PHASE_INIT
{
  return PyModuleDef_Init(&__pyx_moduledef);
}
static CYTHON_SMALL_CODE int __Pyx_check_single_interpreter(void) {
    #if PY_VERSION_HEX >= 0x030700A1
    static PY_INT64_T main_interpreter_id = -1;
    PY_INT64_T current_id = PyInterpreterState_GetID(PyThreadState_Get()->interp);
    if (main_interpreter_id == -1) {
        main_interpreter_id = current_id;
        return (unlikely(current_id == -1)) ? -1 : 0;
    } else if (unlikely(main_interpreter_id != current_id))
    #else
    static PyInterpreterState *main_interpreter = NULL;
    PyInterpreterState *current_interpreter = PyThreadState_Get()->interp;
    if (!main_interpreter) {
        main_interpreter = current_interpreter;
    } else if (unlikely(main_interpreter != current_interpreter))
    #endif
    {
        PyErr_SetString(
            PyExc_ImportError,
            "Interpreter change detected - this module can only be loaded into one interpreter per process.");
        return -1;
    }
    return 0;
}
static CYTHON_SMALL_CODE int __Pyx_copy_spec_to_module(PyObject *spec, PyObject *moddict, const char* from_name, const char* to_name) {
    PyObject *value = PyObject_GetAttrString(spec, from_name);
    int result = 0;
    if (likely(value)) {
        result = PyDict_SetItemString(moddict, to_name, value);
        Py_DECREF(value);
    } else if (PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Clear();
    } else {
        result = -1;
    }
    return result;
}
static CYTHON_SMALL_CODE PyObject* __pyx_pymod_create(PyObject *spec, CYTHON_UNUSED PyModuleDef *def) {
    PyObject *module = NULL, *moddict, *modname;
    if (__Pyx_check_single_interpreter())
        return NULL;
    if (__pyx_m)
        return __Pyx_NewRef(__pyx_m);
    modname = PyObject_GetAttrString(spec, "name");
    if (unlikely(!modname)) goto bad;
    module = PyModule_NewObject(modname);
    Py_DECREF(modname);
    if (unlikely(!module)) goto bad;
    moddict = PyModule_GetDict(module);
    if (unlikely(!moddict)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "loader", "__loader__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "origin", "__file__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "parent", "__package__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "submodule_search_locations", "__path__") < 0)) goto bad;
    return module;
bad:
    Py_XDECREF(module);
    return NULL;
}


static CYTHON_SMALL_CODE int __pyx_pymod_exec__tokenizer(PyObject *__pyx_pyinit_module)
#endif
#endif
{
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannyDeclarations
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  if (__pyx_m) {
    if (__pyx_m == __pyx_pyinit_module) return 0;
    PyErr_SetString(PyExc_RuntimeError, "Module '_tokenizer' has already been imported. Re-initialisation is not supported.");
    return -1;
  }
  #elif PY_MAJOR_VERSION >= 3
  if (__pyx_m) return __Pyx_NewRef(__pyx_m);
  #endif
  #if CYTHON_REFNANNY
__Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
if (!__Pyx_RefNanny) {
  PyErr_Clear();
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
  if (!__Pyx_RefNanny)
      Py_FatalError("failed to import 'refnanny' module");
}
#endif
  __Pyx_RefNannySetupContext("__Pyx_PyMODINIT_FUNC PyInit__tokenizer(void)", 0);
  if (__Pyx_check_binary_version() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pxy_PyFrame_Initialize_Offsets
  __Pxy_PyFrame_Initialize_Offsets();
  #endif
  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_unicode = PyUnicode_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_unicode)) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pyx_CyFunction_USED
  if (__pyx_CyFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Coroutine_USED
  if (__pyx_Coroutine_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_AsyncGen_USED
  if (__pyx_AsyncGen_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_StopAsyncIteration_USED
  if (__pyx_StopAsyncIteration_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  /*--- Library function declarations ---*/
  /*--- Threads initialization code ---*/
  #if defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
  #ifdef WITH_THREAD /* Python build with threading support? */
  PyEval_InitThreads();
  #endif
  #endif
  /*--- Module creation code ---*/
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  __pyx_m = __pyx_pyinit_module;
  Py_INCREF(__pyx_m);
  #else
  #if PY_MAJOR_VERSION < 3
  __pyx_m = Py_InitModule4("_tokenizer", __pyx_methods, __pyx_k_Cython_version_of_the_Tokenizer, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
  #else
  __pyx_m = PyModule_Create(&__pyx_moduledef);
  #endif
  if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_d);
  __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
  #if CYTHON_COMPILING_IN_PYPY
  Py_INCREF(__pyx_b);
  #endif
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  /*--- Initialize various global constants etc. ---*/
  if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
  if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  if (__pyx_module_is_main_srctools___tokenizer) {
    if (PyObject_SetAttr(__pyx_m, __pyx_n_s_name_2, __pyx_n_s_main) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  }
  #if PY_MAJOR_VERSION >= 3
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
    if (!PyDict_GetItemString(modules, "srctools._tokenizer")) {
      if (unlikely(PyDict_SetItemString(modules, "srctools._tokenizer", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
    }
  }
  #endif
  /*--- Builtin init code ---*/
  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Constants init code ---*/
  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Global type/function init code ---*/
  (void)__Pyx_modinit_global_init_code();
  (void)__Pyx_modinit_variable_export_code();
  (void)__Pyx_modinit_function_export_code();
  if (unlikely(__Pyx_modinit_type_init_code() != 0)) goto __pyx_L1_error;
  (void)__Pyx_modinit_type_import_code();
  (void)__Pyx_modinit_variable_import_code();
  (void)__Pyx_modinit_function_import_code();
  /*--- Execution code ---*/
  #if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
  if (__Pyx_patch_abc() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif

  /* "srctools/_tokenizer.pyx":12
 * # On Python 3.6+, convert stuff to PathLike.
 * cdef object _conv_path
 * try:             # <<<<<<<<<<<<<<
 *     from os import fspath as _conv_path
 * except ImportError:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "srctools/_tokenizer.pyx":13
 * cdef object _conv_path
 * try:
 *     from os import fspath as _conv_path             # <<<<<<<<<<<<<<
 * except ImportError:
 *     # Default to just using str().
 */
      __pyx_t_4 = PyList_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 13, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_n_s_fspath);
      __Pyx_GIVEREF(__pyx_n_s_fspath);
      PyList_SET_ITEM(__pyx_t_4, 0, __pyx_n_s_fspath);
      __pyx_t_5 = __Pyx_Import(__pyx_n_s_os, __pyx_t_4, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 13, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = __Pyx_ImportFrom(__pyx_t_5, __pyx_n_s_fspath); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 13, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer__conv_path);
      __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer__conv_path, __pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "srctools/_tokenizer.pyx":12
 * # On Python 3.6+, convert stuff to PathLike.
 * cdef object _conv_path
 * try:             # <<<<<<<<<<<<<<
 *     from os import fspath as _conv_path
 * except ImportError:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L7_try_end;
    __pyx_L2_error:;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "srctools/_tokenizer.pyx":14
 * try:
 *     from os import fspath as _conv_path
 * except ImportError:             # <<<<<<<<<<<<<<
 *     # Default to just using str().
 *     _conv_path = None
 */
    __pyx_t_6 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_ImportError);
    if (__pyx_t_6) {
      __Pyx_AddTraceback("srctools._tokenizer", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_4, &__pyx_t_7) < 0) __PYX_ERR(0, 14, __pyx_L4_except_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GOTREF(__pyx_t_7);

      /* "srctools/_tokenizer.pyx":16
 * except ImportError:
 *     # Default to just using str().
 *     _conv_path = None             # <<<<<<<<<<<<<<
 * 
 * # Import the Token enum from the Python file, and cache references
 */
      __Pyx_INCREF(Py_None);
      __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer__conv_path);
      __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer__conv_path, Py_None);
      __Pyx_GIVEREF(Py_None);
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      goto __pyx_L3_exception_handled;
    }
    goto __pyx_L4_except_error;
    __pyx_L4_except_error:;

    /* "srctools/_tokenizer.pyx":12
 * # On Python 3.6+, convert stuff to PathLike.
 * cdef object _conv_path
 * try:             # <<<<<<<<<<<<<<
 *     from os import fspath as _conv_path
 * except ImportError:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L3_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    __pyx_L7_try_end:;
  }

  /* "srctools/_tokenizer.pyx":23
 * 
 * cdef object Token, TokenSyntaxError
 * from srctools.tokenizer import Token,  TokenSyntaxError             # <<<<<<<<<<<<<<
 * 
 * # Cdef-ed globals become static module vars, which aren't in the module
 */
  __pyx_t_7 = PyList_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 23, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_INCREF(__pyx_n_s_Token);
  __Pyx_GIVEREF(__pyx_n_s_Token);
  PyList_SET_ITEM(__pyx_t_7, 0, __pyx_n_s_Token);
  __Pyx_INCREF(__pyx_n_s_TokenSyntaxError);
  __Pyx_GIVEREF(__pyx_n_s_TokenSyntaxError);
  PyList_SET_ITEM(__pyx_t_7, 1, __pyx_n_s_TokenSyntaxError);
  __pyx_t_4 = __Pyx_Import(__pyx_n_s_srctools_tokenizer, __pyx_t_7, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 23, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_ImportFrom(__pyx_t_4, __pyx_n_s_Token); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 23, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_INCREF(__pyx_t_7);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_Token);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_Token, __pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_ImportFrom(__pyx_t_4, __pyx_n_s_TokenSyntaxError); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 23, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_INCREF(__pyx_t_7);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError, __pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":29
 * # lookup.
 * cdef:
 *     object STRING = Token.STRING             # <<<<<<<<<<<<<<
 *     object PAREN_ARGS = Token.PAREN_ARGS
 *     object PROP_FLAG = Token.PROP_FLAG   # [!flag]
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_STRING); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 29, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_STRING);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_STRING, __pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":30
 * cdef:
 *     object STRING = Token.STRING
 *     object PAREN_ARGS = Token.PAREN_ARGS             # <<<<<<<<<<<<<<
 *     object PROP_FLAG = Token.PROP_FLAG   # [!flag]
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_PAREN_ARGS); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS, __pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":31
 *     object STRING = Token.STRING
 *     object PAREN_ARGS = Token.PAREN_ARGS
 *     object PROP_FLAG = Token.PROP_FLAG   # [!flag]             # <<<<<<<<<<<<<<
 * 
 *     object EOF = Token.EOF
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_PROP_FLAG); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_PROP_FLAG);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_PROP_FLAG, __pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":33
 *     object PROP_FLAG = Token.PROP_FLAG   # [!flag]
 * 
 *     object EOF = Token.EOF             # <<<<<<<<<<<<<<
 *     object NEWLINE = Token.NEWLINE
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_EOF); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 33, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_EOF);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_EOF, __pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":34
 * 
 *     object EOF = Token.EOF
 *     object NEWLINE = Token.NEWLINE             # <<<<<<<<<<<<<<
 * 
 *     # Iterator that immediately raises StopIteration.
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_NEWLINE); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 34, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_NEWLINE);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_NEWLINE, __pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":37
 * 
 *     # Iterator that immediately raises StopIteration.
 *     object EMPTY_ITER = iter('')             # <<<<<<<<<<<<<<
 * 
 *     # Reuse a single tuple for these, since the value is constant.
 */
  __pyx_t_4 = PyObject_GetIter(__pyx_kp_u__2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 37, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_EMPTY_ITER);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_EMPTY_ITER, __pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":40
 * 
 *     # Reuse a single tuple for these, since the value is constant.
 *     tuple EOF_TUP = (Token.EOF, None)             # <<<<<<<<<<<<<<
 *     tuple NEWLINE_TUP = (Token.NEWLINE, '\n')
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_EOF); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 40, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 40, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_4);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  PyTuple_SET_ITEM(__pyx_t_7, 1, Py_None);
  __pyx_t_4 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_EOF_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_EOF_TUP, ((PyObject*)__pyx_t_7));
  __Pyx_GIVEREF(__pyx_t_7);
  __pyx_t_7 = 0;

  /* "srctools/_tokenizer.pyx":41
 *     # Reuse a single tuple for these, since the value is constant.
 *     tuple EOF_TUP = (Token.EOF, None)
 *     tuple NEWLINE_TUP = (Token.NEWLINE, '\n')             # <<<<<<<<<<<<<<
 * 
 *     tuple COLON_TUP = (Token.COLON, ':')
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_NEWLINE); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_7);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_7);
  __Pyx_INCREF(__pyx_kp_u__10);
  __Pyx_GIVEREF(__pyx_kp_u__10);
  PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_kp_u__10);
  __pyx_t_7 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP, ((PyObject*)__pyx_t_4));
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":43
 *     tuple NEWLINE_TUP = (Token.NEWLINE, '\n')
 * 
 *     tuple COLON_TUP = (Token.COLON, ':')             # <<<<<<<<<<<<<<
 *     tuple EQUALS_TUP = (Token.EQUALS, '=')
 *     tuple PLUS_TUP = (Token.PLUS, '+')
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_COLON); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 43, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 43, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_4);
  __Pyx_INCREF(__pyx_kp_u__15);
  __Pyx_GIVEREF(__pyx_kp_u__15);
  PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_kp_u__15);
  __pyx_t_4 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_COLON_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_COLON_TUP, ((PyObject*)__pyx_t_7));
  __Pyx_GIVEREF(__pyx_t_7);
  __pyx_t_7 = 0;

  /* "srctools/_tokenizer.pyx":44
 * 
 *     tuple COLON_TUP = (Token.COLON, ':')
 *     tuple EQUALS_TUP = (Token.EQUALS, '=')             # <<<<<<<<<<<<<<
 *     tuple PLUS_TUP = (Token.PLUS, '+')
 * 
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_EQUALS); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 44, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 44, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_7);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_7);
  __Pyx_INCREF(__pyx_kp_u__16);
  __Pyx_GIVEREF(__pyx_kp_u__16);
  PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_kp_u__16);
  __pyx_t_7 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_EQUALS_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_EQUALS_TUP, ((PyObject*)__pyx_t_4));
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":45
 *     tuple COLON_TUP = (Token.COLON, ':')
 *     tuple EQUALS_TUP = (Token.EQUALS, '=')
 *     tuple PLUS_TUP = (Token.PLUS, '+')             # <<<<<<<<<<<<<<
 * 
 *     tuple BRACE_OPEN_TUP = (Token.BRACE_OPEN, '{')
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_PLUS); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 45, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 45, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_4);
  __Pyx_INCREF(__pyx_kp_u__17);
  __Pyx_GIVEREF(__pyx_kp_u__17);
  PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_kp_u__17);
  __pyx_t_4 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_PLUS_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_PLUS_TUP, ((PyObject*)__pyx_t_7));
  __Pyx_GIVEREF(__pyx_t_7);
  __pyx_t_7 = 0;

  /* "srctools/_tokenizer.pyx":47
 *     tuple PLUS_TUP = (Token.PLUS, '+')
 * 
 *     tuple BRACE_OPEN_TUP = (Token.BRACE_OPEN, '{')             # <<<<<<<<<<<<<<
 *     tuple BRACE_CLOSE_TUP = (Token.BRACE_CLOSE, '}')
 * 
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACE_OPEN); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 47, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 47, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_7);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_7);
  __Pyx_INCREF(__pyx_kp_u__11);
  __Pyx_GIVEREF(__pyx_kp_u__11);
  PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_kp_u__11);
  __pyx_t_7 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP, ((PyObject*)__pyx_t_4));
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":48
 * 
 *     tuple BRACE_OPEN_TUP = (Token.BRACE_OPEN, '{')
 *     tuple BRACE_CLOSE_TUP = (Token.BRACE_CLOSE, '}')             # <<<<<<<<<<<<<<
 * 
 *     tuple BRACK_OPEN_TUP = (Token.BRACK_OPEN, '[')
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACE_CLOSE); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 48, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 48, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_4);
  __Pyx_INCREF(__pyx_kp_u__12);
  __Pyx_GIVEREF(__pyx_kp_u__12);
  PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_kp_u__12);
  __pyx_t_4 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP, ((PyObject*)__pyx_t_7));
  __Pyx_GIVEREF(__pyx_t_7);
  __pyx_t_7 = 0;

  /* "srctools/_tokenizer.pyx":50
 *     tuple BRACE_CLOSE_TUP = (Token.BRACE_CLOSE, '}')
 * 
 *     tuple BRACK_OPEN_TUP = (Token.BRACK_OPEN, '[')             # <<<<<<<<<<<<<<
 *     tuple BRACK_CLOSE_TUP = (Token.BRACK_CLOSE, ']')
 * 
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACK_OPEN); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_7);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_7);
  __Pyx_INCREF(__pyx_kp_u__13);
  __Pyx_GIVEREF(__pyx_kp_u__13);
  PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_kp_u__13);
  __pyx_t_7 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP, ((PyObject*)__pyx_t_4));
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":51
 * 
 *     tuple BRACK_OPEN_TUP = (Token.BRACK_OPEN, '[')
 *     tuple BRACK_CLOSE_TUP = (Token.BRACK_CLOSE, ']')             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACK_CLOSE); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 51, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 51, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_4);
  __Pyx_INCREF(__pyx_kp_u__14);
  __Pyx_GIVEREF(__pyx_kp_u__14);
  PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_kp_u__14);
  __pyx_t_4 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP, ((PyObject*)__pyx_t_7));
  __Pyx_GIVEREF(__pyx_t_7);
  __pyx_t_7 = 0;

  /* "srctools/_tokenizer.pyx":578
 * 
 * # Remove this class from the module, so it's not directly exposed.
 * del globals()['NewlinesIter']             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __Pyx_Globals(); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 578, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  if (unlikely(PyObject_DelItem(__pyx_t_7, __pyx_n_u_NewlinesIter) < 0)) __PYX_ERR(0, 578, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

  /* "srctools/_tokenizer.pyx":582
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None):             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */
  __pyx_t_7 = PyCFunction_NewEx(&__pyx_mdef_8srctools_10_tokenizer_1escape_text, NULL, __pyx_n_s_srctools__tokenizer); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 582, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_escape_text, __pyx_t_7) < 0) __PYX_ERR(0, 582, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

  /* "srctools/_tokenizer.pyx":1
 * #cython: language_level=3, embedsignature=True, auto_pickle=False             # <<<<<<<<<<<<<<
 * """Cython version of the Tokenizer class."""
 * cimport cython
 */
  __pyx_t_7 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_7) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

  /*--- Wrapped vars code ---*/

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_7);
  if (__pyx_m) {
    if (__pyx_d) {
      __Pyx_AddTraceback("init srctools._tokenizer", __pyx_clineno, __pyx_lineno, __pyx_filename);
    }
    Py_CLEAR(__pyx_m);
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init srctools._tokenizer");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  return (__pyx_m != NULL) ? 0 : -1;
  #elif PY_MAJOR_VERSION >= 3
  return __pyx_m;
  #else
  return;
  #endif
}

/* --- Runtime support code --- */
/* Refnanny */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule(modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, "RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

/* PyObjectGetAttrStr */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_getattr))
        return tp->tp_getattr(obj, PyString_AS_STRING(attr_name));
#endif
    return PyObject_GetAttr(obj, attr_name);
}
#endif

/* GetBuiltinName */
static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStr(__pyx_b, name);
    if (unlikely(!result)) {
        PyErr_Format(PyExc_NameError,
#if PY_MAJOR_VERSION >= 3
            "name '%U' is not defined", name);
#else
            "name '%.200s' is not defined", PyString_AS_STRING(name));
#endif
    }
    return result;
}

/* RaiseArgTupleInvalid */
static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

/* KeywordStringCheck */
static int __Pyx_CheckKeywordStrings(
    PyObject *kwdict,
    const char* function_name,
    int kw_allowed)
{
    PyObject* key = 0;
    Py_ssize_t pos = 0;
#if CYTHON_COMPILING_IN_PYPY
    if (!kw_allowed && PyDict_Next(kwdict, &pos, &key, 0))
        goto invalid_keyword;
    return 1;
#else
    while (PyDict_Next(kwdict, &pos, &key, 0)) {
        #if PY_MAJOR_VERSION < 3
        if (unlikely(!PyString_Check(key)))
        #endif
            if (unlikely(!PyUnicode_Check(key)))
                goto invalid_keyword_type;
    }
    if ((!kw_allowed) && unlikely(key))
        goto invalid_keyword;
    return 1;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    return 0;
#endif
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
    return 0;
}

/* RaiseDoubleKeywords */
static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        #if PY_MAJOR_VERSION >= 3
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
        #else
        "%s() got multiple values for keyword argument '%s'", func_name,
        PyString_AsString(kw_name));
        #endif
}

/* ParseKeywords */
static int __Pyx_ParseOptionalKeywords(
    PyObject *kwds,
    PyObject **argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject *key = 0, *value = 0;
    Py_ssize_t pos = 0;
    PyObject*** name;
    PyObject*** first_kw_arg = argnames + num_pos_args;
    while (PyDict_Next(kwds, &pos, &key, &value)) {
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            values[name-argnames] = value;
            continue;
        }
        name = first_kw_arg;
        #if PY_MAJOR_VERSION < 3
        if (likely(PyString_CheckExact(key)) || likely(PyString_Check(key))) {
            while (*name) {
                if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                        && _PyString_Eq(**name, key)) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    if ((**argname == key) || (
                            (CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**argname) == PyString_GET_SIZE(key))
                             && _PyString_Eq(**argname, key))) {
                        goto arg_passed_twice;
                    }
                    argname++;
                }
            }
        } else
        #endif
        if (likely(PyUnicode_Check(key))) {
            while (*name) {
                int cmp = (**name == key) ? 0 :
                #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                    (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
                #endif
                    PyUnicode_Compare(**name, key);
                if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                if (cmp == 0) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    int cmp = (**argname == key) ? 0 :
                    #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                        (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
                    #endif
                        PyUnicode_Compare(**argname, key);
                    if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                    if (cmp == 0) goto arg_passed_twice;
                    argname++;
                }
            }
        } else
            goto invalid_keyword_type;
        if (kwds2) {
            if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
        } else {
            goto invalid_keyword;
        }
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
bad:
    return -1;
}

/* PyObjectCall */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = func->ob_type->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyErrFetchRestore */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
}
#endif

/* RaiseException */
#if PY_MAJOR_VERSION < 3
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb,
                        CYTHON_UNUSED PyObject *cause) {
    __Pyx_PyThreadState_declare
    Py_XINCREF(type);
    if (!value || value == Py_None)
        value = NULL;
    else
        Py_INCREF(value);
    if (!tb || tb == Py_None)
        tb = NULL;
    else {
        Py_INCREF(tb);
        if (!PyTraceBack_Check(tb)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: arg 3 must be a traceback or None");
            goto raise_error;
        }
    }
    if (PyType_Check(type)) {
#if CYTHON_COMPILING_IN_PYPY
        if (!value) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#endif
        PyErr_NormalizeException(&type, &value, &tb);
    } else {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto raise_error;
        }
        value = type;
        type = (PyObject*) Py_TYPE(type);
        Py_INCREF(type);
        if (!PyType_IsSubtype((PyTypeObject *)type, (PyTypeObject *)PyExc_BaseException)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: exception class must be a subclass of BaseException");
            goto raise_error;
        }
    }
    __Pyx_PyThreadState_assign
    __Pyx_ErrRestore(type, value, tb);
    return;
raise_error:
    Py_XDECREF(value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
    return;
}
#else
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                int is_subclass = PyObject_IsSubclass(instance_class, type);
                if (!is_subclass) {
                    instance_class = NULL;
                } else if (unlikely(is_subclass == -1)) {
                    goto bad;
                } else {
                    type = instance_class;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
    if (cause) {
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
#if CYTHON_COMPILING_IN_PYPY
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(&tmp_type, &tmp_value, &tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#else
        PyThreadState *tstate = __Pyx_PyThreadState_Current;
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}
#endif

/* PyCFunctionFastCall */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject * __Pyx_PyCFunction_FastCall(PyObject *func_obj, PyObject **args, Py_ssize_t nargs) {
    PyCFunctionObject *func = (PyCFunctionObject*)func_obj;
    PyCFunction meth = PyCFunction_GET_FUNCTION(func);
    PyObject *self = PyCFunction_GET_SELF(func);
    int flags = PyCFunction_GET_FLAGS(func);
    assert(PyCFunction_Check(func));
    assert(METH_FASTCALL == (flags & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)));
    assert(nargs >= 0);
    assert(nargs == 0 || args != NULL);
    /* _PyCFunction_FastCallDict() must not be called with an exception set,
       because it may clear it (directly or indirectly) and so the
       caller loses its exception */
    assert(!PyErr_Occurred());
    if ((PY_VERSION_HEX < 0x030700A0) || unlikely(flags & METH_KEYWORDS)) {
        return (*((__Pyx_PyCFunctionFastWithKeywords)(void*)meth)) (self, args, nargs, NULL);
    } else {
        return (*((__Pyx_PyCFunctionFast)(void*)meth)) (self, args, nargs);
    }
}
#endif

/* PyFunctionFastCall */
#if CYTHON_FAST_PYCALL
static PyObject* __Pyx_PyFunction_FastCallNoKw(PyCodeObject *co, PyObject **args, Py_ssize_t na,
                                               PyObject *globals) {
    PyFrameObject *f;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;
    assert(globals != NULL);
    /* XXX Perhaps we should create a specialized
       PyFrame_New() that doesn't take locals, but does
       take builtins without sanity checking them.
       */
    assert(tstate != NULL);
    f = PyFrame_New(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = __Pyx_PyFrame_GetLocalsplus(f);
    for (i = 0; i < na; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    result = PyEval_EvalFrameEx(f,0);
    ++tstate->recursion_depth;
    Py_DECREF(f);
    --tstate->recursion_depth;
    return result;
}
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs) {
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *closure;
#if PY_MAJOR_VERSION >= 3
    PyObject *kwdefs;
#endif
    PyObject *kwtuple, **k;
    PyObject **d;
    Py_ssize_t nd;
    Py_ssize_t nk;
    PyObject *result;
    assert(kwargs == NULL || PyDict_Check(kwargs));
    nk = kwargs ? PyDict_Size(kwargs) : 0;
    if (Py_EnterRecursiveCall((char*)" while calling a Python object")) {
        return NULL;
    }
    if (
#if PY_MAJOR_VERSION >= 3
            co->co_kwonlyargcount == 0 &&
#endif
            likely(kwargs == NULL || nk == 0) &&
            co->co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) {
        if (argdefs == NULL && co->co_argcount == nargs) {
            result = __Pyx_PyFunction_FastCallNoKw(co, args, nargs, globals);
            goto done;
        }
        else if (nargs == 0 && argdefs != NULL
                 && co->co_argcount == Py_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            args = &PyTuple_GET_ITEM(argdefs, 0);
            result =__Pyx_PyFunction_FastCallNoKw(co, args, Py_SIZE(argdefs), globals);
            goto done;
        }
    }
    if (kwargs != NULL) {
        Py_ssize_t pos, i;
        kwtuple = PyTuple_New(2 * nk);
        if (kwtuple == NULL) {
            result = NULL;
            goto done;
        }
        k = &PyTuple_GET_ITEM(kwtuple, 0);
        pos = i = 0;
        while (PyDict_Next(kwargs, &pos, &k[i], &k[i+1])) {
            Py_INCREF(k[i]);
            Py_INCREF(k[i+1]);
            i += 2;
        }
        nk = i / 2;
    }
    else {
        kwtuple = NULL;
        k = NULL;
    }
    closure = PyFunction_GET_CLOSURE(func);
#if PY_MAJOR_VERSION >= 3
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
#endif
    if (argdefs != NULL) {
        d = &PyTuple_GET_ITEM(argdefs, 0);
        nd = Py_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
#if PY_MAJOR_VERSION >= 3
    result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, kwdefs, closure);
#else
    result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, closure);
#endif
    Py_XDECREF(kwtuple);
done:
    Py_LeaveRecursiveCall();
    return result;
}
#endif
#endif

/* PyObjectCallMethO */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = PyCFunction_GET_FUNCTION(func);
    self = PyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallOneArg */
#if CYTHON_COMPILING_IN_CPYTHON
static PyObject* __Pyx__PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_New(1);
    if (unlikely(!args)) return NULL;
    Py_INCREF(arg);
    PyTuple_SET_ITEM(args, 0, arg);
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, &arg, 1);
    }
#endif
    if (likely(PyCFunction_Check(func))) {
        if (likely(PyCFunction_GET_FLAGS(func) & METH_O)) {
            return __Pyx_PyObject_CallMethO(func, arg);
#if CYTHON_FAST_PYCCALL
        } else if (PyCFunction_GET_FLAGS(func) & METH_FASTCALL) {
            return __Pyx_PyCFunction_FastCall(func, &arg, 1);
#endif
        }
    }
    return __Pyx__PyObject_CallOneArg(func, arg);
}
#else
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_Pack(1, arg);
    if (unlikely(!args)) return NULL;
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
#endif

/* PyObjectCall2Args */
static CYTHON_UNUSED PyObject* __Pyx_PyObject_Call2Args(PyObject* function, PyObject* arg1, PyObject* arg2) {
    PyObject *args, *result = NULL;
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(function)) {
        PyObject *args[2] = {arg1, arg2};
        return __Pyx_PyFunction_FastCall(function, args, 2);
    }
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(function)) {
        PyObject *args[2] = {arg1, arg2};
        return __Pyx_PyCFunction_FastCall(function, args, 2);
    }
    #endif
    args = PyTuple_New(2);
    if (unlikely(!args)) goto done;
    Py_INCREF(arg1);
    PyTuple_SET_ITEM(args, 0, arg1);
    Py_INCREF(arg2);
    PyTuple_SET_ITEM(args, 1, arg2);
    Py_INCREF(function);
    result = __Pyx_PyObject_Call(function, args, NULL);
    Py_DECREF(args);
    Py_DECREF(function);
done:
    return result;
}

/* GetTopmostException */
#if CYTHON_USE_EXC_INFO_STACK
static _PyErr_StackItem *
__Pyx_PyErr_GetTopmostException(PyThreadState *tstate)
{
    _PyErr_StackItem *exc_info = tstate->exc_info;
    while ((exc_info->exc_type == NULL || exc_info->exc_type == Py_None) &&
           exc_info->previous_item != NULL)
    {
        exc_info = exc_info->previous_item;
    }
    return exc_info;
}
#endif

/* SaveResetException */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = __Pyx_PyErr_GetTopmostException(tstate);
    *type = exc_info->exc_type;
    *value = exc_info->exc_value;
    *tb = exc_info->exc_traceback;
    #else
    *type = tstate->exc_type;
    *value = tstate->exc_value;
    *tb = tstate->exc_traceback;
    #endif
    Py_XINCREF(*type);
    Py_XINCREF(*value);
    Py_XINCREF(*tb);
}
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_type = exc_info->exc_type;
    tmp_value = exc_info->exc_value;
    tmp_tb = exc_info->exc_traceback;
    exc_info->exc_type = type;
    exc_info->exc_value = value;
    exc_info->exc_traceback = tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = type;
    tstate->exc_value = value;
    tstate->exc_traceback = tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
#endif

/* PyErrExceptionMatches */
#if CYTHON_FAST_THREAD_STATE
static int __Pyx_PyErr_ExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        if (__Pyx_PyErr_GivenExceptionMatches(exc_type, PyTuple_GET_ITEM(tuple, i))) return 1;
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err) {
    PyObject *exc_type = tstate->curexc_type;
    if (exc_type == err) return 1;
    if (unlikely(!exc_type)) return 0;
    if (unlikely(PyTuple_Check(err)))
        return __Pyx_PyErr_ExceptionMatchesTuple(exc_type, err);
    return __Pyx_PyErr_GivenExceptionMatches(exc_type, err);
}
#endif

/* GetException */
#if CYTHON_FAST_THREAD_STATE
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb)
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb)
#endif
{
    PyObject *local_type, *local_value, *local_tb;
#if CYTHON_FAST_THREAD_STATE
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    local_type = tstate->curexc_type;
    local_value = tstate->curexc_value;
    local_tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
#else
    PyErr_Fetch(&local_type, &local_value, &local_tb);
#endif
    PyErr_NormalizeException(&local_type, &local_value, &local_tb);
#if CYTHON_FAST_THREAD_STATE
    if (unlikely(tstate->curexc_type))
#else
    if (unlikely(PyErr_Occurred()))
#endif
        goto bad;
    #if PY_MAJOR_VERSION >= 3
    if (local_tb) {
        if (unlikely(PyException_SetTraceback(local_value, local_tb) < 0))
            goto bad;
    }
    #endif
    Py_XINCREF(local_tb);
    Py_XINCREF(local_type);
    Py_XINCREF(local_value);
    *type = local_type;
    *value = local_value;
    *tb = local_tb;
#if CYTHON_FAST_THREAD_STATE
    #if CYTHON_USE_EXC_INFO_STACK
    {
        _PyErr_StackItem *exc_info = tstate->exc_info;
        tmp_type = exc_info->exc_type;
        tmp_value = exc_info->exc_value;
        tmp_tb = exc_info->exc_traceback;
        exc_info->exc_type = local_type;
        exc_info->exc_value = local_value;
        exc_info->exc_traceback = local_tb;
    }
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = local_type;
    tstate->exc_value = local_value;
    tstate->exc_traceback = local_tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#else
    PyErr_SetExcInfo(local_type, local_value, local_tb);
#endif
    return 0;
bad:
    *type = 0;
    *value = 0;
    *tb = 0;
    Py_XDECREF(local_type);
    Py_XDECREF(local_value);
    Py_XDECREF(local_tb);
    return -1;
}

/* JoinPyUnicode */
static PyObject* __Pyx_PyUnicode_Join(PyObject* value_tuple, Py_ssize_t value_count, Py_ssize_t result_ulength,
                                      CYTHON_UNUSED Py_UCS4 max_char) {
#if CYTHON_USE_UNICODE_INTERNALS && CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    PyObject *result_uval;
    int result_ukind;
    Py_ssize_t i, char_pos;
    void *result_udata;
#if CYTHON_PEP393_ENABLED
    result_uval = PyUnicode_New(result_ulength, max_char);
    if (unlikely(!result_uval)) return NULL;
    result_ukind = (max_char <= 255) ? PyUnicode_1BYTE_KIND : (max_char <= 65535) ? PyUnicode_2BYTE_KIND : PyUnicode_4BYTE_KIND;
    result_udata = PyUnicode_DATA(result_uval);
#else
    result_uval = PyUnicode_FromUnicode(NULL, result_ulength);
    if (unlikely(!result_uval)) return NULL;
    result_ukind = sizeof(Py_UNICODE);
    result_udata = PyUnicode_AS_UNICODE(result_uval);
#endif
    char_pos = 0;
    for (i=0; i < value_count; i++) {
        int ukind;
        Py_ssize_t ulength;
        void *udata;
        PyObject *uval = PyTuple_GET_ITEM(value_tuple, i);
        if (unlikely(__Pyx_PyUnicode_READY(uval)))
            goto bad;
        ulength = __Pyx_PyUnicode_GET_LENGTH(uval);
        if (unlikely(!ulength))
            continue;
        if (unlikely(char_pos + ulength < 0))
            goto overflow;
        ukind = __Pyx_PyUnicode_KIND(uval);
        udata = __Pyx_PyUnicode_DATA(uval);
        if (!CYTHON_PEP393_ENABLED || ukind == result_ukind) {
            memcpy((char *)result_udata + char_pos * result_ukind, udata, (size_t) (ulength * result_ukind));
        } else {
            #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030300F0 || defined(_PyUnicode_FastCopyCharacters)
            _PyUnicode_FastCopyCharacters(result_uval, char_pos, uval, 0, ulength);
            #else
            Py_ssize_t j;
            for (j=0; j < ulength; j++) {
                Py_UCS4 uchar = __Pyx_PyUnicode_READ(ukind, udata, j);
                __Pyx_PyUnicode_WRITE(result_ukind, result_udata, char_pos+j, uchar);
            }
            #endif
        }
        char_pos += ulength;
    }
    return result_uval;
overflow:
    PyErr_SetString(PyExc_OverflowError, "join() result is too long for a Python string");
bad:
    Py_DECREF(result_uval);
    return NULL;
#else
    result_ulength++;
    value_count++;
    return PyUnicode_Join(__pyx_empty_unicode, value_tuple);
#endif
}

/* GetItemIntUnicode */
static CYTHON_INLINE Py_UCS4 __Pyx_GetItemInt_Unicode_Fast(PyObject* ustring, Py_ssize_t i,
                                                           int wraparound, int boundscheck) {
    Py_ssize_t length;
    if (unlikely(__Pyx_PyUnicode_READY(ustring) < 0)) return (Py_UCS4)-1;
    if (wraparound | boundscheck) {
        length = __Pyx_PyUnicode_GET_LENGTH(ustring);
        if (wraparound & unlikely(i < 0)) i += length;
        if ((!boundscheck) || likely(__Pyx_is_valid_index(i, length))) {
            return __Pyx_PyUnicode_READ_CHAR(ustring, i);
        } else {
            PyErr_SetString(PyExc_IndexError, "string index out of range");
            return (Py_UCS4)-1;
        }
    } else {
        return __Pyx_PyUnicode_READ_CHAR(ustring, i);
    }
}

/* IterNext */
static PyObject *__Pyx_PyIter_Next2Default(PyObject* defval) {
    PyObject* exc_type;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    exc_type = __Pyx_PyErr_Occurred();
    if (unlikely(exc_type)) {
        if (!defval || unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration)))
            return NULL;
        __Pyx_PyErr_Clear();
        Py_INCREF(defval);
        return defval;
    }
    if (defval) {
        Py_INCREF(defval);
        return defval;
    }
    __Pyx_PyErr_SetNone(PyExc_StopIteration);
    return NULL;
}
static void __Pyx_PyIter_Next_ErrorNoIterator(PyObject *iterator) {
    PyErr_Format(PyExc_TypeError,
        "%.200s object is not an iterator", Py_TYPE(iterator)->tp_name);
}
static CYTHON_INLINE PyObject *__Pyx_PyIter_Next2(PyObject* iterator, PyObject* defval) {
    PyObject* next;
    iternextfunc iternext = Py_TYPE(iterator)->tp_iternext;
    if (likely(iternext)) {
#if CYTHON_USE_TYPE_SLOTS
        next = iternext(iterator);
        if (likely(next))
            return next;
        #if PY_VERSION_HEX >= 0x02070000
        if (unlikely(iternext == &_PyObject_NextNotImplemented))
            return NULL;
        #endif
#else
        next = PyIter_Next(iterator);
        if (likely(next))
            return next;
#endif
    } else if (CYTHON_USE_TYPE_SLOTS || unlikely(!PyIter_Check(iterator))) {
        __Pyx_PyIter_Next_ErrorNoIterator(iterator);
        return NULL;
    }
#if !CYTHON_USE_TYPE_SLOTS
    else {
        next = PyIter_Next(iterator);
        if (likely(next))
            return next;
    }
#endif
    return __Pyx_PyIter_Next2Default(defval);
}

/* CIntToDigits */
static const char DIGIT_PAIRS_10[2*10*10+1] = {
    "00010203040506070809"
    "10111213141516171819"
    "20212223242526272829"
    "30313233343536373839"
    "40414243444546474849"
    "50515253545556575859"
    "60616263646566676869"
    "70717273747576777879"
    "80818283848586878889"
    "90919293949596979899"
};
static const char DIGIT_PAIRS_8[2*8*8+1] = {
    "0001020304050607"
    "1011121314151617"
    "2021222324252627"
    "3031323334353637"
    "4041424344454647"
    "5051525354555657"
    "6061626364656667"
    "7071727374757677"
};
static const char DIGITS_HEX[2*16+1] = {
    "0123456789abcdef"
    "0123456789ABCDEF"
};

/* BuildPyUnicode */
static PyObject* __Pyx_PyUnicode_BuildFromAscii(Py_ssize_t ulength, char* chars, int clength,
                                                int prepend_sign, char padding_char) {
    PyObject *uval;
    Py_ssize_t uoffset = ulength - clength;
#if CYTHON_USE_UNICODE_INTERNALS
    Py_ssize_t i;
#if CYTHON_PEP393_ENABLED
    void *udata;
    uval = PyUnicode_New(ulength, 127);
    if (unlikely(!uval)) return NULL;
    udata = PyUnicode_DATA(uval);
#else
    Py_UNICODE *udata;
    uval = PyUnicode_FromUnicode(NULL, ulength);
    if (unlikely(!uval)) return NULL;
    udata = PyUnicode_AS_UNICODE(uval);
#endif
    if (uoffset > 0) {
        i = 0;
        if (prepend_sign) {
            __Pyx_PyUnicode_WRITE(PyUnicode_1BYTE_KIND, udata, 0, '-');
            i++;
        }
        for (; i < uoffset; i++) {
            __Pyx_PyUnicode_WRITE(PyUnicode_1BYTE_KIND, udata, i, padding_char);
        }
    }
    for (i=0; i < clength; i++) {
        __Pyx_PyUnicode_WRITE(PyUnicode_1BYTE_KIND, udata, uoffset+i, chars[i]);
    }
#else
    {
        uval = NULL;
        PyObject *sign = NULL, *padding = NULL;
        if (uoffset > 0) {
            prepend_sign = !!prepend_sign;
            if (uoffset > prepend_sign) {
                padding = PyUnicode_FromOrdinal(padding_char);
                if (likely(padding) && uoffset > prepend_sign + 1) {
                    PyObject *tmp;
                    PyObject *repeat = PyInt_FromSize_t(uoffset - prepend_sign);
                    if (unlikely(!repeat)) goto done_or_error;
                    tmp = PyNumber_Multiply(padding, repeat);
                    Py_DECREF(repeat);
                    Py_DECREF(padding);
                    padding = tmp;
                }
                if (unlikely(!padding)) goto done_or_error;
            }
            if (prepend_sign) {
                sign = PyUnicode_FromOrdinal('-');
                if (unlikely(!sign)) goto done_or_error;
            }
        }
        uval = PyUnicode_DecodeASCII(chars, clength, NULL);
        if (likely(uval) && padding) {
            PyObject *tmp = PyNumber_Add(padding, uval);
            Py_DECREF(uval);
            uval = tmp;
        }
        if (likely(uval) && sign) {
            PyObject *tmp = PyNumber_Add(sign, uval);
            Py_DECREF(uval);
            uval = tmp;
        }
done_or_error:
        Py_XDECREF(padding);
        Py_XDECREF(sign);
    }
#endif
    return uval;
}

/* CIntToPyUnicode */
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned short    uint16_t;
        #else
           typedef unsigned __int16  uint16_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_From_int(int value, Py_ssize_t width, char padding_char, char format_char) {
    char digits[sizeof(int)*3+2];
    char *dpos, *end = digits + sizeof(int)*3+2;
    const char *hex_digits = DIGITS_HEX;
    Py_ssize_t length, ulength;
    int prepend_sign, last_one_off;
    int remaining;
    const int neg_one = (int) ((int) 0 - (int) 1), const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
    if (format_char == 'X') {
        hex_digits += 16;
        format_char = 'x';
    }
    remaining = value;
    last_one_off = 0;
    dpos = end;
    do {
        int digit_pos;
        switch (format_char) {
        case 'o':
            digit_pos = abs((int)(remaining % (8*8)));
            remaining = (int) (remaining / (8*8));
            dpos -= 2;
            *(uint16_t*)dpos = ((uint16_t*)DIGIT_PAIRS_8)[digit_pos];
            last_one_off = (digit_pos < 8);
            break;
        case 'd':
            digit_pos = abs((int)(remaining % (10*10)));
            remaining = (int) (remaining / (10*10));
            dpos -= 2;
            *(uint16_t*)dpos = ((uint16_t*)DIGIT_PAIRS_10)[digit_pos];
            last_one_off = (digit_pos < 10);
            break;
        case 'x':
            *(--dpos) = hex_digits[abs((int)(remaining % 16))];
            remaining = (int) (remaining / 16);
            break;
        default:
            assert(0);
            break;
        }
    } while (unlikely(remaining != 0));
    if (last_one_off) {
        assert(*dpos == '0');
        dpos++;
    }
    length = end - dpos;
    ulength = length;
    prepend_sign = 0;
    if (!is_unsigned && value <= neg_one) {
        if (padding_char == ' ' || width <= length + 1) {
            *(--dpos) = '-';
            ++length;
        } else {
            prepend_sign = 1;
        }
        ++ulength;
    }
    if (width > ulength) {
        ulength = width;
    }
    if (ulength == 1) {
        return PyUnicode_FromOrdinal(*dpos);
    }
    return __Pyx_PyUnicode_BuildFromAscii(ulength, dpos, (int) length, prepend_sign, padding_char);
}

/* ArgTypeTest */
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact)
{
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    else if (exact) {
        #if PY_MAJOR_VERSION == 2
        if ((type == &PyBaseString_Type) && likely(__Pyx_PyBaseString_CheckExact(obj))) return 1;
        #endif
    }
    else {
        if (likely(__Pyx_TypeCheck(obj, type))) return 1;
    }
    PyErr_Format(PyExc_TypeError,
        "Argument '%.200s' has incorrect type (expected %.200s, got %.200s)",
        name, type->tp_name, Py_TYPE(obj)->tp_name);
    return 0;
}

/* BytesEquals */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY
    return PyObject_RichCompareBool(s1, s2, equals);
#else
    if (s1 == s2) {
        return (equals == Py_EQ);
    } else if (PyBytes_CheckExact(s1) & PyBytes_CheckExact(s2)) {
        const char *ps1, *ps2;
        Py_ssize_t length = PyBytes_GET_SIZE(s1);
        if (length != PyBytes_GET_SIZE(s2))
            return (equals == Py_NE);
        ps1 = PyBytes_AS_STRING(s1);
        ps2 = PyBytes_AS_STRING(s2);
        if (ps1[0] != ps2[0]) {
            return (equals == Py_NE);
        } else if (length == 1) {
            return (equals == Py_EQ);
        } else {
            int result;
#if CYTHON_USE_UNICODE_INTERNALS
            Py_hash_t hash1, hash2;
            hash1 = ((PyBytesObject*)s1)->ob_shash;
            hash2 = ((PyBytesObject*)s2)->ob_shash;
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                return (equals == Py_NE);
            }
#endif
            result = memcmp(ps1, ps2, (size_t)length);
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & PyBytes_CheckExact(s2)) {
        return (equals == Py_NE);
    } else if ((s2 == Py_None) & PyBytes_CheckExact(s1)) {
        return (equals == Py_NE);
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
#endif
}

/* UnicodeEquals */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY
    return PyObject_RichCompareBool(s1, s2, equals);
#else
#if PY_MAJOR_VERSION < 3
    PyObject* owned_ref = NULL;
#endif
    int s1_is_unicode, s2_is_unicode;
    if (s1 == s2) {
        goto return_eq;
    }
    s1_is_unicode = PyUnicode_CheckExact(s1);
    s2_is_unicode = PyUnicode_CheckExact(s2);
#if PY_MAJOR_VERSION < 3
    if ((s1_is_unicode & (!s2_is_unicode)) && PyString_CheckExact(s2)) {
        owned_ref = PyUnicode_FromObject(s2);
        if (unlikely(!owned_ref))
            return -1;
        s2 = owned_ref;
        s2_is_unicode = 1;
    } else if ((s2_is_unicode & (!s1_is_unicode)) && PyString_CheckExact(s1)) {
        owned_ref = PyUnicode_FromObject(s1);
        if (unlikely(!owned_ref))
            return -1;
        s1 = owned_ref;
        s1_is_unicode = 1;
    } else if (((!s2_is_unicode) & (!s1_is_unicode))) {
        return __Pyx_PyBytes_Equals(s1, s2, equals);
    }
#endif
    if (s1_is_unicode & s2_is_unicode) {
        Py_ssize_t length;
        int kind;
        void *data1, *data2;
        if (unlikely(__Pyx_PyUnicode_READY(s1) < 0) || unlikely(__Pyx_PyUnicode_READY(s2) < 0))
            return -1;
        length = __Pyx_PyUnicode_GET_LENGTH(s1);
        if (length != __Pyx_PyUnicode_GET_LENGTH(s2)) {
            goto return_ne;
        }
#if CYTHON_USE_UNICODE_INTERNALS
        {
            Py_hash_t hash1, hash2;
        #if CYTHON_PEP393_ENABLED
            hash1 = ((PyASCIIObject*)s1)->hash;
            hash2 = ((PyASCIIObject*)s2)->hash;
        #else
            hash1 = ((PyUnicodeObject*)s1)->hash;
            hash2 = ((PyUnicodeObject*)s2)->hash;
        #endif
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                goto return_ne;
            }
        }
#endif
        kind = __Pyx_PyUnicode_KIND(s1);
        if (kind != __Pyx_PyUnicode_KIND(s2)) {
            goto return_ne;
        }
        data1 = __Pyx_PyUnicode_DATA(s1);
        data2 = __Pyx_PyUnicode_DATA(s2);
        if (__Pyx_PyUnicode_READ(kind, data1, 0) != __Pyx_PyUnicode_READ(kind, data2, 0)) {
            goto return_ne;
        } else if (length == 1) {
            goto return_eq;
        } else {
            int result = memcmp(data1, data2, (size_t)(length * kind));
            #if PY_MAJOR_VERSION < 3
            Py_XDECREF(owned_ref);
            #endif
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & s2_is_unicode) {
        goto return_ne;
    } else if ((s2 == Py_None) & s1_is_unicode) {
        goto return_ne;
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        #if PY_MAJOR_VERSION < 3
        Py_XDECREF(owned_ref);
        #endif
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
return_eq:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_EQ);
return_ne:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_NE);
#endif
}

/* PyObjectFormatAndDecref */
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatSimpleAndDecref(PyObject* s, PyObject* f) {
    if (unlikely(!s)) return NULL;
    if (likely(PyUnicode_CheckExact(s))) return s;
    #if PY_MAJOR_VERSION < 3
    if (likely(PyString_CheckExact(s))) {
        PyObject *result = PyUnicode_FromEncodedObject(s, NULL, "strict");
        Py_DECREF(s);
        return result;
    }
    #endif
    return __Pyx_PyObject_FormatAndDecref(s, f);
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatAndDecref(PyObject* s, PyObject* f) {
    PyObject *result = PyObject_Format(s, f);
    Py_DECREF(s);
    return result;
}

/* RaiseTooManyValuesToUnpack */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
    PyErr_Format(PyExc_ValueError,
                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
}

/* RaiseNeedMoreValuesToUnpack */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
    PyErr_Format(PyExc_ValueError,
                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
                 index, (index == 1) ? "" : "s");
}

/* RaiseNoneIterError */
static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
}

/* SwapException */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_type = exc_info->exc_type;
    tmp_value = exc_info->exc_value;
    tmp_tb = exc_info->exc_traceback;
    exc_info->exc_type = *type;
    exc_info->exc_value = *value;
    exc_info->exc_traceback = *tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = *type;
    tstate->exc_value = *value;
    tstate->exc_traceback = *tb;
    #endif
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    PyErr_GetExcInfo(&tmp_type, &tmp_value, &tmp_tb);
    PyErr_SetExcInfo(*type, *value, *tb);
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#endif

/* PyObject_GenericGetAttrNoDict */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static PyObject *__Pyx_RaiseGenericGetAttributeError(PyTypeObject *tp, PyObject *attr_name) {
    PyErr_Format(PyExc_AttributeError,
#if PY_MAJOR_VERSION >= 3
                 "'%.50s' object has no attribute '%U'",
                 tp->tp_name, attr_name);
#else
                 "'%.50s' object has no attribute '%.400s'",
                 tp->tp_name, PyString_AS_STRING(attr_name));
#endif
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_GenericGetAttrNoDict(PyObject* obj, PyObject* attr_name) {
    PyObject *descr;
    PyTypeObject *tp = Py_TYPE(obj);
    if (unlikely(!PyString_Check(attr_name))) {
        return PyObject_GenericGetAttr(obj, attr_name);
    }
    assert(!tp->tp_dictoffset);
    descr = _PyType_Lookup(tp, attr_name);
    if (unlikely(!descr)) {
        return __Pyx_RaiseGenericGetAttributeError(tp, attr_name);
    }
    Py_INCREF(descr);
    #if PY_MAJOR_VERSION < 3
    if (likely(PyType_HasFeature(Py_TYPE(descr), Py_TPFLAGS_HAVE_CLASS)))
    #endif
    {
        descrgetfunc f = Py_TYPE(descr)->tp_descr_get;
        if (unlikely(f)) {
            PyObject *res = f(descr, obj, (PyObject *)tp);
            Py_DECREF(descr);
            return res;
        }
    }
    return descr;
}
#endif

/* SetVTable */
static int __Pyx_SetVtable(PyObject *dict, void *vtable) {
#if PY_VERSION_HEX >= 0x02070000
    PyObject *ob = PyCapsule_New(vtable, 0, 0);
#else
    PyObject *ob = PyCObject_FromVoidPtr(vtable, 0);
#endif
    if (!ob)
        goto bad;
    if (PyDict_SetItem(dict, __pyx_n_s_pyx_vtable, ob) < 0)
        goto bad;
    Py_DECREF(ob);
    return 0;
bad:
    Py_XDECREF(ob);
    return -1;
}

/* PyObject_GenericGetAttr */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static PyObject* __Pyx_PyObject_GenericGetAttr(PyObject* obj, PyObject* attr_name) {
    if (unlikely(Py_TYPE(obj)->tp_dictoffset)) {
        return PyObject_GenericGetAttr(obj, attr_name);
    }
    return __Pyx_PyObject_GenericGetAttrNoDict(obj, attr_name);
}
#endif

/* Import */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *empty_list = 0;
    PyObject *module = 0;
    PyObject *global_dict = 0;
    PyObject *empty_dict = 0;
    PyObject *list;
    #if PY_MAJOR_VERSION < 3
    PyObject *py_import;
    py_import = __Pyx_PyObject_GetAttrStr(__pyx_b, __pyx_n_s_import);
    if (!py_import)
        goto bad;
    #endif
    if (from_list)
        list = from_list;
    else {
        empty_list = PyList_New(0);
        if (!empty_list)
            goto bad;
        list = empty_list;
    }
    global_dict = PyModule_GetDict(__pyx_m);
    if (!global_dict)
        goto bad;
    empty_dict = PyDict_New();
    if (!empty_dict)
        goto bad;
    {
        #if PY_MAJOR_VERSION >= 3
        if (level == -1) {
            if (strchr(__Pyx_MODULE_NAME, '.')) {
                module = PyImport_ImportModuleLevelObject(
                    name, global_dict, empty_dict, list, 1);
                if (!module) {
                    if (!PyErr_ExceptionMatches(PyExc_ImportError))
                        goto bad;
                    PyErr_Clear();
                }
            }
            level = 0;
        }
        #endif
        if (!module) {
            #if PY_MAJOR_VERSION < 3
            PyObject *py_level = PyInt_FromLong(level);
            if (!py_level)
                goto bad;
            module = PyObject_CallFunctionObjArgs(py_import,
                name, global_dict, empty_dict, list, py_level, (PyObject *)NULL);
            Py_DECREF(py_level);
            #else
            module = PyImport_ImportModuleLevelObject(
                name, global_dict, empty_dict, list, level);
            #endif
        }
    }
bad:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(py_import);
    #endif
    Py_XDECREF(empty_list);
    Py_XDECREF(empty_dict);
    return module;
}

/* ImportFrom */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name) {
    PyObject* value = __Pyx_PyObject_GetAttrStr(module, name);
    if (unlikely(!value) && PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Format(PyExc_ImportError,
        #if PY_MAJOR_VERSION < 3
            "cannot import name %.230s", PyString_AS_STRING(name));
        #else
            "cannot import name %S", name);
        #endif
    }
    return value;
}

/* GetAttr */
static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *o, PyObject *n) {
#if CYTHON_USE_TYPE_SLOTS
#if PY_MAJOR_VERSION >= 3
    if (likely(PyUnicode_Check(n)))
#else
    if (likely(PyString_Check(n)))
#endif
        return __Pyx_PyObject_GetAttrStr(o, n);
#endif
    return PyObject_GetAttr(o, n);
}

/* Globals */
static PyObject* __Pyx_Globals(void) {
    Py_ssize_t i;
    PyObject *names;
    PyObject *globals = __pyx_d;
    Py_INCREF(globals);
    names = PyObject_Dir(__pyx_m);
    if (!names)
        goto bad;
    for (i = PyList_GET_SIZE(names)-1; i >= 0; i--) {
#if CYTHON_COMPILING_IN_PYPY
        PyObject* name = PySequence_ITEM(names, i);
        if (!name)
            goto bad;
#else
        PyObject* name = PyList_GET_ITEM(names, i);
#endif
        if (!PyDict_Contains(globals, name)) {
            PyObject* value = __Pyx_GetAttr(__pyx_m, name);
            if (!value) {
#if CYTHON_COMPILING_IN_PYPY
                Py_DECREF(name);
#endif
                goto bad;
            }
            if (PyDict_SetItem(globals, name, value) < 0) {
#if CYTHON_COMPILING_IN_PYPY
                Py_DECREF(name);
#endif
                Py_DECREF(value);
                goto bad;
            }
        }
#if CYTHON_COMPILING_IN_PYPY
        Py_DECREF(name);
#endif
    }
    Py_DECREF(names);
    return globals;
bad:
    Py_XDECREF(names);
    Py_XDECREF(globals);
    return NULL;
}

/* CLineInTraceback */
#ifndef CYTHON_CLINE_IN_TRACEBACK
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line) {
    PyObject *use_cline;
    PyObject *ptype, *pvalue, *ptraceback;
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject **cython_runtime_dict;
#endif
    if (unlikely(!__pyx_cython_runtime)) {
        return c_line;
    }
    __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
#if CYTHON_COMPILING_IN_CPYTHON
    cython_runtime_dict = _PyObject_GetDictPtr(__pyx_cython_runtime);
    if (likely(cython_runtime_dict)) {
        __PYX_PY_DICT_LOOKUP_IF_MODIFIED(
            use_cline, *cython_runtime_dict,
            __Pyx_PyDict_GetItemStr(*cython_runtime_dict, __pyx_n_s_cline_in_traceback))
    } else
#endif
    {
      PyObject *use_cline_obj = __Pyx_PyObject_GetAttrStr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback);
      if (use_cline_obj) {
        use_cline = PyObject_Not(use_cline_obj) ? Py_False : Py_True;
        Py_DECREF(use_cline_obj);
      } else {
        PyErr_Clear();
        use_cline = NULL;
      }
    }
    if (!use_cline) {
        c_line = 0;
        PyObject_SetAttr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback, Py_False);
    }
    else if (use_cline == Py_False || (use_cline != Py_True && PyObject_Not(use_cline) != 0)) {
        c_line = 0;
    }
    __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
    return c_line;
}
#endif

/* CodeObjectCache */
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = start + (end - start) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static PyCodeObject *__pyx_find_code_object(int code_line) {
    PyCodeObject* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = __pyx_code_cache.entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            __pyx_code_cache.entries = entries;
            __pyx_code_cache.max_count = 64;
            __pyx_code_cache.count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
        PyCodeObject* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_DECREF(tmp);
        return;
    }
    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
        int new_max = __pyx_code_cache.max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            __pyx_code_cache.entries, (size_t)new_max*sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        __pyx_code_cache.entries = entries;
        __pyx_code_cache.max_count = new_max;
    }
    for (i=__pyx_code_cache.count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    __pyx_code_cache.count++;
    Py_INCREF(code_object);
}

/* AddTraceback */
#include "compile.h"
#include "frameobject.h"
#include "traceback.h"
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyObject *py_srcfile = 0;
    PyObject *py_funcname = 0;
    #if PY_MAJOR_VERSION < 3
    py_srcfile = PyString_FromString(filename);
    #else
    py_srcfile = PyUnicode_FromString(filename);
    #endif
    if (!py_srcfile) goto bad;
    if (c_line) {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #else
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #endif
    }
    else {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromString(funcname);
        #else
        py_funcname = PyUnicode_FromString(funcname);
        #endif
    }
    if (!py_funcname) goto bad;
    py_code = __Pyx_PyCode_New(
        0,
        0,
        0,
        0,
        0,
        __pyx_empty_bytes, /*PyObject *code,*/
        __pyx_empty_tuple, /*PyObject *consts,*/
        __pyx_empty_tuple, /*PyObject *names,*/
        __pyx_empty_tuple, /*PyObject *varnames,*/
        __pyx_empty_tuple, /*PyObject *freevars,*/
        __pyx_empty_tuple, /*PyObject *cellvars,*/
        py_srcfile,   /*PyObject *filename,*/
        py_funcname,  /*PyObject *name,*/
        py_line,
        __pyx_empty_bytes  /*PyObject *lnotab*/
    );
    Py_DECREF(py_srcfile);
    Py_DECREF(py_funcname);
    return py_code;
bad:
    Py_XDECREF(py_srcfile);
    Py_XDECREF(py_funcname);
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    if (c_line) {
        c_line = __Pyx_CLineForTraceback(tstate, c_line);
    }
    py_code = __pyx_find_code_object(c_line ? -c_line : py_line);
    if (!py_code) {
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) goto bad;
        __pyx_insert_code_object(c_line ? -c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        tstate,            /*PyThreadState *tstate,*/
        py_code,           /*PyCodeObject *code,*/
        __pyx_d,    /*PyObject *globals,*/
        0                  /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value) {
    const int neg_one = (int) ((int) 0 - (int) 1), const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
    }
}

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
    const long neg_one = (long) ((long) 0 - (long) 1), const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
    }
}

/* PyUCS4InUnicode */
static int __Pyx_PyUnicodeBufferContainsUCS4_SP(Py_UNICODE* buffer, Py_ssize_t length, Py_UCS4 character) {
    Py_UNICODE high_val, low_val;
    Py_UNICODE* pos;
    high_val = (Py_UNICODE) (0xD800 | (((character - 0x10000) >> 10) & ((1<<10)-1)));
    low_val  = (Py_UNICODE) (0xDC00 | ( (character - 0x10000)        & ((1<<10)-1)));
    for (pos=buffer; pos < buffer+length-1; pos++) {
        if (unlikely((high_val == pos[0]) & (low_val == pos[1]))) return 1;
    }
    return 0;
}
static int __Pyx_PyUnicodeBufferContainsUCS4_BMP(Py_UNICODE* buffer, Py_ssize_t length, Py_UCS4 character) {
    Py_UNICODE uchar;
    Py_UNICODE* pos;
    uchar = (Py_UNICODE) character;
    for (pos=buffer; pos < buffer+length; pos++) {
        if (unlikely(uchar == pos[0])) return 1;
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_UnicodeContainsUCS4(PyObject* unicode, Py_UCS4 character) {
#if CYTHON_PEP393_ENABLED
    const int kind = PyUnicode_KIND(unicode);
    if (likely(kind != PyUnicode_WCHAR_KIND)) {
        Py_ssize_t i;
        const void* udata = PyUnicode_DATA(unicode);
        const Py_ssize_t length = PyUnicode_GET_LENGTH(unicode);
        for (i=0; i < length; i++) {
            if (unlikely(character == PyUnicode_READ(kind, udata, i))) return 1;
        }
        return 0;
    }
#endif
    if (Py_UNICODE_SIZE == 2 && unlikely(character > 65535)) {
        return __Pyx_PyUnicodeBufferContainsUCS4_SP(
            PyUnicode_AS_UNICODE(unicode),
            PyUnicode_GET_SIZE(unicode),
            character);
    } else {
        return __Pyx_PyUnicodeBufferContainsUCS4_BMP(
            PyUnicode_AS_UNICODE(unicode),
            PyUnicode_GET_SIZE(unicode),
            character);
    }
}

/* CIntFromPyVerify */
#define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 0)
#define __PYX_VERIFY_RETURN_INT_EXC(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 1)
#define __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, exc)\
    {\
        func_type value = func_value;\
        if (sizeof(target_type) < sizeof(func_type)) {\
            if (unlikely(value != (func_type) (target_type) value)) {\
                func_type zero = 0;\
                if (exc && unlikely(value == (func_type)-1 && PyErr_Occurred()))\
                    return (target_type) -1;\
                if (is_unsigned && unlikely(value < zero))\
                    goto raise_neg_overflow;\
                else\
                    goto raise_overflow;\
            }\
        }\
        return (target_type) value;\
    }

/* CIntFromPy */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *x) {
    const int neg_one = (int) ((int) 0 - (int) 1), const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(int) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case  1: __PYX_VERIFY_RETURN_INT(int, digit, digits[0])
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 2 * PyLong_SHIFT) {
                            return (int) (((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 3 * PyLong_SHIFT) {
                            return (int) (((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 4 * PyLong_SHIFT) {
                            return (int) (((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (int) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(int) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case -1: __PYX_VERIFY_RETURN_INT(int, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(int,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(int) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) ((((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) ((((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) ((((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(int) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            int val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (int) -1;
        }
    } else {
        int val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyInt_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

/* CIntFromPy */
static CYTHON_INLINE char __Pyx_PyInt_As_char(PyObject *x) {
    const char neg_one = (char) ((char) 0 - (char) 1), const_zero = (char) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(char) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(char, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (char) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (char) 0;
                case  1: __PYX_VERIFY_RETURN_INT(char, digit, digits[0])
                case 2:
                    if (8 * sizeof(char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) >= 2 * PyLong_SHIFT) {
                            return (char) (((((char)digits[1]) << PyLong_SHIFT) | (char)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) >= 3 * PyLong_SHIFT) {
                            return (char) (((((((char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) >= 4 * PyLong_SHIFT) {
                            return (char) (((((((((char)digits[3]) << PyLong_SHIFT) | (char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (char) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(char) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(char) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (char) 0;
                case -1: __PYX_VERIFY_RETURN_INT(char, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(char,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(char) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 2 * PyLong_SHIFT) {
                            return (char) (((char)-1)*(((((char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 2 * PyLong_SHIFT) {
                            return (char) ((((((char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(char) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 3 * PyLong_SHIFT) {
                            return (char) (((char)-1)*(((((((char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 3 * PyLong_SHIFT) {
                            return (char) ((((((((char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(char) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 4 * PyLong_SHIFT) {
                            return (char) (((char)-1)*(((((((((char)digits[3]) << PyLong_SHIFT) | (char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 4 * PyLong_SHIFT) {
                            return (char) ((((((((((char)digits[3]) << PyLong_SHIFT) | (char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(char) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(char) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            char val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (char) -1;
        }
    } else {
        char val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (char) -1;
        val = __Pyx_PyInt_As_char(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to char");
    return (char) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to char");
    return (char) -1;
}

/* CIntFromPy */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *x) {
    const long neg_one = (long) ((long) 0 - (long) 1), const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(long) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case  1: __PYX_VERIFY_RETURN_INT(long, digit, digits[0])
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 2 * PyLong_SHIFT) {
                            return (long) (((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 3 * PyLong_SHIFT) {
                            return (long) (((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 4 * PyLong_SHIFT) {
                            return (long) (((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (long) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(long) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case -1: __PYX_VERIFY_RETURN_INT(long, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(long,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(long) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) ((((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) ((((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) ((((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(long) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            long val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (long) -1;
        }
    } else {
        long val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyInt_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

/* FastTypeChecks */
#if CYTHON_COMPILING_IN_CPYTHON
static int __Pyx_InBases(PyTypeObject *a, PyTypeObject *b) {
    while (a) {
        a = a->tp_base;
        if (a == b)
            return 1;
    }
    return b == &PyBaseObject_Type;
}
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b) {
    PyObject *mro;
    if (a == b) return 1;
    mro = a->tp_mro;
    if (likely(mro)) {
        Py_ssize_t i, n;
        n = PyTuple_GET_SIZE(mro);
        for (i = 0; i < n; i++) {
            if (PyTuple_GET_ITEM(mro, i) == (PyObject *)b)
                return 1;
        }
        return 0;
    }
    return __Pyx_InBases(a, b);
}
#if PY_MAJOR_VERSION == 2
static int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject* exc_type2) {
    PyObject *exception, *value, *tb;
    int res;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&exception, &value, &tb);
    res = exc_type1 ? PyObject_IsSubclass(err, exc_type1) : 0;
    if (unlikely(res == -1)) {
        PyErr_WriteUnraisable(err);
        res = 0;
    }
    if (!res) {
        res = PyObject_IsSubclass(err, exc_type2);
        if (unlikely(res == -1)) {
            PyErr_WriteUnraisable(err);
            res = 0;
        }
    }
    __Pyx_ErrRestore(exception, value, tb);
    return res;
}
#else
static CYTHON_INLINE int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject *exc_type2) {
    int res = exc_type1 ? __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type1) : 0;
    if (!res) {
        res = __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type2);
    }
    return res;
}
#endif
static int __Pyx_PyErr_GivenExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    assert(PyExceptionClass_Check(exc_type));
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        PyObject *t = PyTuple_GET_ITEM(tuple, i);
        #if PY_MAJOR_VERSION < 3
        if (likely(exc_type == t)) return 1;
        #endif
        if (likely(PyExceptionClass_Check(t))) {
            if (__Pyx_inner_PyErr_GivenExceptionMatches2(exc_type, NULL, t)) return 1;
        } else {
        }
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject* exc_type) {
    if (likely(err == exc_type)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        if (likely(PyExceptionClass_Check(exc_type))) {
            return __Pyx_inner_PyErr_GivenExceptionMatches2(err, NULL, exc_type);
        } else if (likely(PyTuple_Check(exc_type))) {
            return __Pyx_PyErr_GivenExceptionMatchesTuple(err, exc_type);
        } else {
        }
    }
    return PyErr_GivenExceptionMatches(err, exc_type);
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *exc_type1, PyObject *exc_type2) {
    assert(PyExceptionClass_Check(exc_type1));
    assert(PyExceptionClass_Check(exc_type2));
    if (likely(err == exc_type1 || err == exc_type2)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, exc_type1, exc_type2);
    }
    return (PyErr_GivenExceptionMatches(err, exc_type1) || PyErr_GivenExceptionMatches(err, exc_type2));
}
#endif

/* CheckBinaryVersion */
static int __Pyx_check_binary_version(void) {
    char ctversion[4], rtversion[4];
    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compiletime version %s of module '%.100s' "
                      "does not match runtime version %s",
                      ctversion, __Pyx_MODULE_NAME, rtversion);
        return PyErr_WarnEx(NULL, message, 1);
    }
    return 0;
}

/* InitStrings */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
    while (t->p) {
        #if PY_MAJOR_VERSION < 3
        if (t->is_unicode) {
            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
        } else if (t->intern) {
            *t->p = PyString_InternFromString(t->s);
        } else {
            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
        }
        #else
        if (t->is_unicode | t->is_str) {
            if (t->intern) {
                *t->p = PyUnicode_InternFromString(t->s);
            } else if (t->encoding) {
                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
            } else {
                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
            }
        } else {
            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
        }
        #endif
        if (!*t->p)
            return -1;
        if (PyObject_Hash(*t->p) == -1)
            return -1;
        ++t;
    }
    return 0;
}

static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    return __Pyx_PyUnicode_FromStringAndSize(c_str, (Py_ssize_t)strlen(c_str));
}
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
#if !CYTHON_PEP393_ENABLED
static const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    char* defenc_c;
    PyObject* defenc = _PyUnicode_AsDefaultEncodedString(o, NULL);
    if (!defenc) return NULL;
    defenc_c = PyBytes_AS_STRING(defenc);
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    {
        char* end = defenc_c + PyBytes_GET_SIZE(defenc);
        char* c;
        for (c = defenc_c; c < end; c++) {
            if ((unsigned char) (*c) >= 128) {
                PyUnicode_AsASCIIString(o);
                return NULL;
            }
        }
    }
#endif
    *length = PyBytes_GET_SIZE(defenc);
    return defenc_c;
}
#else
static CYTHON_INLINE const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    if (unlikely(__Pyx_PyUnicode_READY(o) == -1)) return NULL;
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    if (likely(PyUnicode_IS_ASCII(o))) {
        *length = PyUnicode_GET_LENGTH(o);
        return PyUnicode_AsUTF8(o);
    } else {
        PyUnicode_AsASCIIString(o);
        return NULL;
    }
#else
    return PyUnicode_AsUTF8AndSize(o, length);
#endif
}
#endif
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
    if (
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
            __Pyx_sys_getdefaultencoding_not_ascii &&
#endif
            PyUnicode_Check(o)) {
        return __Pyx_PyUnicode_AsStringAndSize(o, length);
    } else
#endif
#if (!CYTHON_COMPILING_IN_PYPY) || (defined(PyByteArray_AS_STRING) && defined(PyByteArray_GET_SIZE))
    if (PyByteArray_Check(o)) {
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
    } else
#endif
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject* x) {
    int retval;
    if (unlikely(!x)) return -1;
    retval = __Pyx_PyObject_IsTrue(x);
    Py_DECREF(x);
    return retval;
}
static PyObject* __Pyx_PyNumber_IntOrLongWrongResultType(PyObject* result, const char* type_name) {
#if PY_MAJOR_VERSION >= 3
    if (PyLong_Check(result)) {
        if (PyErr_WarnFormat(PyExc_DeprecationWarning, 1,
                "__int__ returned non-int (type %.200s).  "
                "The ability to return an instance of a strict subclass of int "
                "is deprecated, and may be removed in a future version of Python.",
                Py_TYPE(result)->tp_name)) {
            Py_DECREF(result);
            return NULL;
        }
        return result;
    }
#endif
    PyErr_Format(PyExc_TypeError,
                 "__%.4s__ returned non-%.4s (type %.200s)",
                 type_name, type_name, Py_TYPE(result)->tp_name);
    Py_DECREF(result);
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x) {
#if CYTHON_USE_TYPE_SLOTS
  PyNumberMethods *m;
#endif
  const char *name = NULL;
  PyObject *res = NULL;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_Check(x) || PyLong_Check(x)))
#else
  if (likely(PyLong_Check(x)))
#endif
    return __Pyx_NewRef(x);
#if CYTHON_USE_TYPE_SLOTS
  m = Py_TYPE(x)->tp_as_number;
  #if PY_MAJOR_VERSION < 3
  if (m && m->nb_int) {
    name = "int";
    res = m->nb_int(x);
  }
  else if (m && m->nb_long) {
    name = "long";
    res = m->nb_long(x);
  }
  #else
  if (likely(m && m->nb_int)) {
    name = "int";
    res = m->nb_int(x);
  }
  #endif
#else
  if (!PyBytes_CheckExact(x) && !PyUnicode_CheckExact(x)) {
    res = PyNumber_Int(x);
  }
#endif
  if (likely(res)) {
#if PY_MAJOR_VERSION < 3
    if (unlikely(!PyInt_Check(res) && !PyLong_Check(res))) {
#else
    if (unlikely(!PyLong_CheckExact(res))) {
#endif
        return __Pyx_PyNumber_IntOrLongWrongResultType(res, name);
    }
  }
  else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_TypeError,
                    "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_CheckExact(b))) {
    if (sizeof(Py_ssize_t) >= sizeof(long))
        return PyInt_AS_LONG(b);
    else
        return PyInt_AsSsize_t(b);
  }
#endif
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_USE_PYLONG_INTERNALS
    const digit* digits = ((PyLongObject*)b)->ob_digit;
    const Py_ssize_t size = Py_SIZE(b);
    if (likely(__Pyx_sst_abs(size) <= 1)) {
        ival = likely(size) ? digits[0] : 0;
        if (size == -1) ival = -ival;
        return ival;
    } else {
      switch (size) {
         case 2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
      }
    }
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyInt_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b) {
  return b ? __Pyx_NewRef(Py_True) : __Pyx_NewRef(Py_False);
}
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
    return PyInt_FromSize_t(ival);
}


#endif /* Py_PYTHON_H */
